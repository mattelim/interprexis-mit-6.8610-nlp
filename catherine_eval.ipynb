{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of art related words\n",
    "words = ['abstract',\n",
    " 'aesthetic',\n",
    " 'acrylic',\n",
    " 'artistry',\n",
    " 'animation',\n",
    " 'brushwork',\n",
    " 'canvas',\n",
    " 'ceramics',\n",
    " 'collage',\n",
    " 'color',\n",
    " 'composition',\n",
    " 'creativity',\n",
    " 'culture',\n",
    " 'design',\n",
    " 'drawing',\n",
    " 'easel',\n",
    " 'expression',\n",
    " 'fresco',\n",
    " 'gallery',\n",
    " 'graffiti',\n",
    " 'hue',\n",
    " 'illustration',\n",
    " 'impressionism',\n",
    " 'ink',\n",
    " 'installation',\n",
    " 'landscape',\n",
    " 'masterpiece',\n",
    " 'medium',\n",
    " 'mural',\n",
    " 'museum',\n",
    " 'oil',\n",
    " 'palette',\n",
    " 'pastel',\n",
    " 'perspective',\n",
    " 'photography',\n",
    " 'pigment',\n",
    " 'portrait',\n",
    " 'realism',\n",
    " 'sculpture',\n",
    " 'sketch',\n",
    " 'still life',\n",
    " 'surrealism',\n",
    " 'texture',\n",
    " 'tone',\n",
    " 'watercolor',\n",
    " 'abstract expressionism',\n",
    " 'art deco',\n",
    " 'baroque',\n",
    " 'byzantine',\n",
    " 'carving',\n",
    " 'chiaroscuro',\n",
    " 'cubism',\n",
    " 'dadaism',\n",
    " 'etching',\n",
    " 'expressionism',\n",
    " 'fauvism',\n",
    " 'genre',\n",
    " 'gouache',\n",
    " 'harmony',\n",
    " 'impression',\n",
    " 'juxtaposition',\n",
    " 'kinetic',\n",
    " 'line',\n",
    " 'minimalism',\n",
    " 'modernism',\n",
    " 'neoclassicism',\n",
    " 'ornament',\n",
    " 'perspective',\n",
    " 'pop art',\n",
    " 'post-impressionism',\n",
    " 'realism',\n",
    " 'renaissance',\n",
    " 'rococo',\n",
    " 'romanticism',\n",
    " 'satire',\n",
    " 'shade',\n",
    " 'silhouette',\n",
    " 'symmetry',\n",
    " 'tapestry',\n",
    " 'tempera',\n",
    " \"trompe l'oeil\",\n",
    " 'urban art',\n",
    " 'vanguard',\n",
    " 'veneer',\n",
    " 'vignette',\n",
    " 'whimsical',\n",
    " 'xenography',\n",
    " 'yield',\n",
    " 'zenith',\n",
    " 'zest',\n",
    " 'fresco',\n",
    " 'impasto',\n",
    " 'montage',\n",
    " 'opus',\n",
    " 'palette knife',\n",
    " 'quattrocento',\n",
    " 'relief',\n",
    " 'stipple',\n",
    " 'underpainting',\n",
    " 'varnish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "# https://huggingface.co/distilbert-base-uncased\n",
    "# https://huggingface.co/docs/transformers/v4.35.0/en/model_doc/distilbert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding for each class\n",
    "# ❗️ note: I am averaging the embeddings for each word in the class\n",
    "# ❓ question: are we interested in the final contextual embedding for each class? currently, we're looking at the final hidden state.\n",
    "embeddings = []\n",
    "for i in range(len(words)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(words[i])).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]\n",
    "    # skip the first token, which is the [CLS] token, and skip the last token, which is the [SEP] token\n",
    "    # average the rest of the tokens\n",
    "    embeddings.append(last_hidden_states[0][1:-1].mean(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# round each val in embedding to 3 decimal places\n",
    "embeddings = [list(np.around(np.array(e),3)) for e in embeddings]\n",
    "\n",
    "# create string of all classes and their embeddings & save to text file\n",
    "# ❗️ note: only taking first 10 axes for now due to context window length\n",
    "with open(\"output.txt\", \"w\") as text_file:\n",
    "    for i in range(len(words)):\n",
    "        class_str = f\"{words[i]}: {embeddings[i][:10]}\\n\"\n",
    "        text_file.write(class_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aesthetic</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acrylic</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.777</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.548</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artistry</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      0      1      2      3      4      5      6      7      8  \\\n",
       "0   abstract  0.286  0.395 -0.382 -0.242  0.407  0.010 -0.199  0.060  0.203   \n",
       "1  aesthetic  0.249  0.566 -0.123 -0.117  0.271  0.083  0.036 -0.069  0.083   \n",
       "2    acrylic  0.217  0.234 -0.019  0.087  0.777 -0.107 -0.655  0.548 -0.061   \n",
       "3   artistry  0.147  0.263 -0.044 -0.078  0.660  0.147 -0.043 -0.021 -0.120   \n",
       "4  animation -0.006  0.449 -0.484  0.105  0.504  0.228  0.095  0.199 -0.532   \n",
       "\n",
       "   ...    758    759    760    761    762    763    764    765    766    767  \n",
       "0  ...  0.734 -0.119  0.476  0.058  0.239 -0.068  0.101  0.026  0.260 -0.127  \n",
       "1  ...  0.516  0.024  0.273 -0.004  0.114 -0.206  0.080  0.043  0.187  0.201  \n",
       "2  ...  0.254 -0.524  0.176  0.345  0.337 -0.254 -0.499 -0.021  0.162  0.142  \n",
       "3  ...  0.639 -0.331  0.187  0.041 -0.143 -0.029  0.110 -0.205  0.363 -0.308  \n",
       "4  ...  0.550 -0.206  0.477  0.005  0.140 -0.114  0.244 -0.032  0.513  0.498  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert embeddings to pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(embeddings)\n",
    "df.insert(0, 'word', words)\n",
    "\n",
    "# sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>0.486683</td>\n",
       "      <td>-0.490754</td>\n",
       "      <td>-0.152763</td>\n",
       "      <td>-0.189744</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>-0.045004</td>\n",
       "      <td>-0.449067</td>\n",
       "      <td>0.400238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338893</td>\n",
       "      <td>0.285846</td>\n",
       "      <td>0.473819</td>\n",
       "      <td>0.261603</td>\n",
       "      <td>0.072235</td>\n",
       "      <td>0.110902</td>\n",
       "      <td>0.214545</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.164329</td>\n",
       "      <td>-0.366919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aesthetic</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>0.693705</td>\n",
       "      <td>-0.122333</td>\n",
       "      <td>0.118093</td>\n",
       "      <td>-0.364103</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.313501</td>\n",
       "      <td>-0.634146</td>\n",
       "      <td>0.257720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.550416</td>\n",
       "      <td>-0.044700</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>-0.209932</td>\n",
       "      <td>-0.148496</td>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.329205</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.183879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acrylic</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.291768</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.560130</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>-0.094256</td>\n",
       "      <td>-0.740656</td>\n",
       "      <td>0.251076</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388931</td>\n",
       "      <td>-0.463460</td>\n",
       "      <td>-0.292465</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.293454</td>\n",
       "      <td>-0.238722</td>\n",
       "      <td>-0.876364</td>\n",
       "      <td>0.197110</td>\n",
       "      <td>-0.032064</td>\n",
       "      <td>0.084803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artistry</td>\n",
       "      <td>0.055990</td>\n",
       "      <td>0.326877</td>\n",
       "      <td>-0.009957</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>-0.565280</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194845</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>-0.264368</td>\n",
       "      <td>0.225738</td>\n",
       "      <td>-0.790068</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.230909</td>\n",
       "      <td>-0.182663</td>\n",
       "      <td>0.370741</td>\n",
       "      <td>-0.670865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>-0.128236</td>\n",
       "      <td>0.552058</td>\n",
       "      <td>-0.635846</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>-0.065385</td>\n",
       "      <td>0.399116</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>-0.249641</td>\n",
       "      <td>-0.472684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.124884</td>\n",
       "      <td>0.476373</td>\n",
       "      <td>0.149789</td>\n",
       "      <td>-0.151242</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.474545</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.671343</td>\n",
       "      <td>0.682620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word         0         1         2         3         4         5  \\\n",
       "0   abstract  0.223359  0.486683 -0.490754 -0.152763 -0.189744  0.078056   \n",
       "1  aesthetic  0.178808  0.693705 -0.122333  0.118093 -0.364103  0.185567   \n",
       "2    acrylic  0.140277  0.291768  0.025605  0.560130  0.284615 -0.094256   \n",
       "3   artistry  0.055990  0.326877 -0.009957  0.202600  0.134615  0.279823   \n",
       "4  animation -0.128236  0.552058 -0.635846  0.599133 -0.065385  0.399116   \n",
       "\n",
       "          6         7         8  ...       758       759       760       761  \\\n",
       "0 -0.045004 -0.449067  0.400238  ...  0.338893  0.285846  0.473819  0.261603   \n",
       "1  0.313501 -0.634146  0.257720  ...  0.008340  0.550416 -0.044700  0.130802   \n",
       "2 -0.740656  0.251076  0.086698  ... -0.388931 -0.463460 -0.292465  0.867089   \n",
       "3  0.192982 -0.565280  0.016627  ...  0.194845 -0.106383 -0.264368  0.225738   \n",
       "4  0.403509 -0.249641 -0.472684  ...  0.059894  0.124884  0.476373  0.149789   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.072235  0.110902  0.214545  0.294118  0.164329 -0.366919  \n",
       "1 -0.209932 -0.148496  0.176364  0.329205  0.018036  0.183879  \n",
       "2  0.293454 -0.238722 -0.876364  0.197110 -0.032064  0.084803  \n",
       "3 -0.790068  0.184211  0.230909 -0.182663  0.370741 -0.670865  \n",
       "4 -0.151242  0.024436  0.474545  0.174407  0.671343  0.682620  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize each column to be between -1 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df.iloc[:,1:] = scaler.fit_transform(df.iloc[:,1:])\n",
    "\n",
    "# sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpreting axes with chatgpt\n",
    "\n",
    "I uploaded the csv generated above and used the following prompt:\n",
    "```\n",
    "This CSV contains a list of words and their embeddings (each column after the word represents an axis in the embedding. \n",
    "\n",
    "By carefully comparing and considering the embedding values for each word, please interpret the likely linguistic feature that each embedding axis encodes. This interpretation must be consistent across all the words and correspond to their respective positive, zero, or negative embedding values.  You might consider analyzing the top 10 words with values close to -1, the top 10 words with values close to 0 (median), and the top 10 words with values close to 1 to generate your interpretation. \n",
    "\n",
    "Please phrase your interpretation using 3 words like: negative vs positive, small vs large, etc (some contrast with \"vs\" should be present). You should only have one interpretation per axis.\n",
    "\n",
    "For each axis, also include a confidence score of how confident you are in your interpretation of each axis.\n",
    "\n",
    "For each axis, the output should look like this: {<interpretation>:<interpretation confidence score>} (e.g., {\"positive vs. negative\": 0.6}) Remember <interpretation> should only have 3 words, including \"vs\".\n",
    "\n",
    "Let's start with the first axis. Remember to format your output as requested above as a python dictionary.\n",
    "```\n",
    "\n",
    "Then repeated to get 3 interpretations for the first 10 axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretations of first 10 axes:  \n",
    "# each dict item is formatted as {<interpretation>: <confidence score>}\n",
    "axis_0 = {\"traditional vs. modern\": 0.7, \"traditional vs. modern\": 0.6, \"technique vs. medium\": 0.6}\n",
    "axis_1 = {\"classic vs. diverse\": 0.65, \"detail vs. abstract\": 0.6, \"classical vs. modern\": 0.65}\n",
    "axis_2 = {\"abstract vs. concrete\": 0.6, \"complex vs. simple\": 0.6, \"abstract vs. tangible\": 0.6}\n",
    "axis_3 = {\"formal vs. playful\": 0.65, \"static vs. dynamic\": 0.6, \"formal vs. playful\": 0.65}\n",
    "axis_4 = {\"serious vs. vibrant\": 0.65, \"concrete vs. expressive\": 0.6, \"realistic vs. expressive\": 0.6}\n",
    "axis_5 = {\"innovative vs. traditional\": 0.7, \"abstract vs. concrete\": 0.6, \"avant-garde vs. conventional\": 0.65}\n",
    "axis_6 = {\"material vs. conceptual\": 0.65, \"playful vs. serious\": 0.6, \"traditional vs. modern\": 0.65}\n",
    "axis_7 = {\"modern vs. historical\": 0.7, \"modern vs. classical\": 0.6, \"contemporary vs. historical\": 0.65}\n",
    "axis_8 = {\"innovative vs. fundamental\": 0.65, \"visual vs. conceptual\": 0.6, \"innovative vs. foundational\": 0.65}\n",
    "axis_9 = {\"modern vs. classical\": 0.7, \"innovative vs. traditional\": 0.6, \"modern vs. classical\": 0.65}\n",
    "\n",
    "# concatenate all axes into one list\n",
    "all_axes = [axis_0, axis_1, axis_2, axis_3, axis_4, axis_5, axis_6, axis_7, axis_8, axis_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'mean': 0.6, 'median': 0.6, 'stdev': 0.0}, 1: {'mean': 0.633, 'median': 0.65, 'stdev': 0.029}, 2: {'mean': 0.6, 'median': 0.6, 'stdev': 0.0}, 3: {'mean': 0.625, 'median': 0.625, 'stdev': 0.035}, 4: {'mean': 0.617, 'median': 0.6, 'stdev': 0.029}, 5: {'mean': 0.65, 'median': 0.65, 'stdev': 0.05}, 6: {'mean': 0.633, 'median': 0.65, 'stdev': 0.029}, 7: {'mean': 0.65, 'median': 0.65, 'stdev': 0.05}, 8: {'mean': 0.633, 'median': 0.65, 'stdev': 0.029}, 9: {'mean': 0.625, 'median': 0.625, 'stdev': 0.035}}\n"
     ]
    }
   ],
   "source": [
    "# compute descriptive stats for each axis' confidence scores\n",
    "# store in dict where key is axis number and value is dict of descriptive stats\n",
    "import statistics\n",
    "\n",
    "axes_stats = {}\n",
    "for i in range(len(all_axes)):\n",
    "    axis = all_axes[i]\n",
    "    mean = statistics.mean(axis.values())\n",
    "    median = statistics.median(axis.values())\n",
    "    stdev = statistics.stdev(axis.values())\n",
    "\n",
    "    # round each val to 3 decimal places\n",
    "    mean = round(mean, 3)\n",
    "    median = round(median, 3)\n",
    "    stdev = round(stdev, 3)\n",
    "\n",
    "    # store in dict\n",
    "    axes_stats[i] = {\"mean\": mean, \"median\": median, \"stdev\": stdev}\n",
    "\n",
    "print(axes_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6266666666666667\n",
      "median: 0.6375\n",
      "stdev: 0.017137976669804756\n"
     ]
    }
   ],
   "source": [
    "# overall mean, median, and stdev of all axes' confidence scores\n",
    "mean = statistics.mean([statistics.mean(axis.values()) for axis in all_axes])\n",
    "median = statistics.median([statistics.median(axis.values()) for axis in all_axes])\n",
    "stdev = statistics.stdev([statistics.stdev(axis.values()) for axis in all_axes])\n",
    "\n",
    "# print overall mean, median, and stdev\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"median: {median}\")\n",
    "print(f\"stdev: {stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- decent mean confidence\n",
    "- low stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyzing interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then asked chatgpt to assess how similar the 3 interpretations were for each axis and create a summary interpretation. Again, I asked it to do this 3 times to see how reliable the results were.\n",
    "\n",
    "```\n",
    "Below I will provide interpretations and confidence scores for axes in high dimensional word embeddings. Each axis has 3 potential interpretations + corresponding confidence scores. For each axis, please assign a qualitative similarity rating from 1-10 to how similar the interpretations are (1: not at all similar, 10: identical). Then summarize the three interpretations into a single interpretation per axis by considering the confidence scores, similarities between the interpretations, the most common interpretations, etc. This summary interpretation does not have to be one of the original three interpretations word for word, but it can be. Keep the words in the same relative order, as the first word in the interpretation represents what negative embedding values stand for in the axis, while the second word after vs. represents what positive embedding values stand for.\n",
    "\n",
    "Your final answer for each axis should be a python dict formatted as follows: {<interpretation>: <similarity rating>}. As before, each interpretation should consist of exactly 3 words (including \"vs\"). And the similarity rating should just be the number from 1-10.\n",
    "\n",
    "Here are the axis interpretations:\n",
    "# insert here\n",
    "\n",
    "Remember to format your answer for each axis as a python dict as requested above. You should not need to write code do this, please just do this qualitatively. Also make sure there's no duplicate interpretations.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final axes dict\n",
    "axis_0 = {\"traditional vs. modern\": [4,8,7]}\n",
    "axis_1 = {\"classic vs. modern\": [5,6,4]}\n",
    "axis_2 = {\"abstract vs. concrete\": [8,9,8]}\n",
    "axis_3 = {\"formal vs. playful\": [7,9,8]}\n",
    "axis_4 = {\"serious vs. expressive\": [6,7,5]}\n",
    "axis_5 = {\"innovative vs. traditional\": [7,9,6]}\n",
    "axis_6 = {\"traditional vs. conceptual\": [5,5,4]}\n",
    "axis_7 = {\"modern vs. historical\": [9,9,9]}\n",
    "axis_8 = {\"innovative vs. foundational\": [7,8,7]}\n",
    "axis_9 = {\"modern vs. traditional\": [9,9,8]}\n",
    "\n",
    "# concatenate all axes into one list\n",
    "all_axes = [axis_0, axis_1, axis_2, axis_3, axis_4, axis_5, axis_6, axis_7, axis_8, axis_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'mean': 6.333, 'median': 7, 'stdev': 2.082}, 1: {'mean': 5, 'median': 5, 'stdev': 1.0}, 2: {'mean': 8.333, 'median': 8, 'stdev': 0.577}, 3: {'mean': 8, 'median': 8, 'stdev': 1.0}, 4: {'mean': 6, 'median': 6, 'stdev': 1.0}, 5: {'mean': 7.333, 'median': 7, 'stdev': 1.528}, 6: {'mean': 4.667, 'median': 5, 'stdev': 0.577}, 7: {'mean': 9, 'median': 9, 'stdev': 0.0}, 8: {'mean': 7.333, 'median': 7, 'stdev': 0.577}, 9: {'mean': 8.667, 'median': 9, 'stdev': 0.577}}\n",
      "mean: 7.066666666666666\n",
      "median: 7.0\n",
      "stdev: 0.581747475245294\n"
     ]
    }
   ],
   "source": [
    "# compute descriptive stats for each axis' confidence scores\n",
    "# store in dict where key is axis number and value is dict of descriptive stats\n",
    "axes_stats = {}\n",
    "for i in range(len(all_axes)):\n",
    "    axis = all_axes[i]\n",
    "    # value is a list of confidence scores\n",
    "    mean = statistics.mean(list(axis.values())[0])\n",
    "    median = statistics.median(list(axis.values())[0])\n",
    "    stdev = statistics.stdev(list(axis.values())[0])\n",
    "\n",
    "    # round each val to 3 decimal places\n",
    "    mean = round(mean, 3)\n",
    "    median = round(median, 3)\n",
    "    stdev = round(stdev, 3)\n",
    "\n",
    "    # store in dict\n",
    "    axes_stats[i] = {\"mean\": mean, \"median\": median, \"stdev\": stdev}\n",
    "\n",
    "print(axes_stats)\n",
    "\n",
    "# overall mean, median, and stdev of all axes' confidence scores\n",
    "mean = statistics.mean([statistics.mean(list(axis.values())[0]) for axis in all_axes])\n",
    "median = statistics.median([statistics.median(list(axis.values())[0]) for axis in all_axes])\n",
    "stdev = statistics.stdev([statistics.stdev(list(axis.values())[0]) for axis in all_axes])\n",
    "\n",
    "# print overall mean, median, and stdev\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"median: {median}\")\n",
    "print(f\"stdev: {stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- decently high mean similarity rating\n",
    "- stdev seems reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todos\n",
    "- generate synthetic embeddings using interpretations\n",
    "- compare to original"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946d8ab810ccf0fda35d8421fe75059925cdc2acab76b2b4a2b82ec2be7a9b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
