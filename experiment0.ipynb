{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer + BERT → Data-processing → OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing an environment like conda is recommended. This notebook last ran on Python 3.8.18 without issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# load in coco classes from 'coco-classes.json'\n",
    "import json\n",
    "with open('coco-classes.json') as f:\n",
    "  coco_classes = json.load(f)\n",
    "print(coco_classes)\n",
    "print(len(coco_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person. bicycle. car. motorcycle. airplane. bus. train. truck. boat. traffic light. fire hydrant. stop sign. parking meter. bench. bird. cat. dog. horse. sheep. cow. elephant. bear. zebra. giraffe. backpack. umbrella. handbag. tie. suitcase. frisbee. skis. snowboard. sports ball. kite. baseball bat. baseball glove. skateboard. surfboard. tennis racket. bottle. wine glass. cup. fork. knife. spoon. bowl. banana. apple. sandwich. orange. broccoli. carrot. hot dog. pizza. donut. cake. chair. couch. potted plant. bed. dining table. toilet. tv. laptop. mouse. remote. keyboard. cell phone. microwave. oven. toaster. sink. refrigerator. book. clock. vase. scissors. teddy bear. hair drier. toothbrush\n"
     ]
    }
   ],
   "source": [
    "# concatenate all classes into a single string\n",
    "coco_classes_string = '. '.join(coco_classes)\n",
    "print(coco_classes_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(coco_classes_string, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2711,  1012, 10165,  1012,  2482,  1012,  9055,  1012, 13297,\n",
      "          1012,  3902,  1012,  3345,  1012,  4744,  1012,  4049,  1012,  4026,\n",
      "          2422,  1012,  2543, 26018,  3372,  1012,  2644,  3696,  1012,  5581,\n",
      "          8316,  1012,  6847,  1012,  4743,  1012,  4937,  1012,  3899,  1012,\n",
      "          3586,  1012,  8351,  1012, 11190,  1012, 10777,  1012,  4562,  1012,\n",
      "         29145,  1012, 21025, 27528,  7959,  1012, 13383,  1012, 12977,  1012,\n",
      "          2192, 16078,  1012,  5495,  1012, 15940,  1012, 10424,  2483, 11306,\n",
      "          1012,  8301,  2015,  1012,  4586,  6277,  1012,  2998,  3608,  1012,\n",
      "         20497,  1012,  3598,  7151,  1012,  3598, 15913,  1012, 17260,  6277,\n",
      "          1012, 14175,  6277,  1012,  5093, 14513,  3388,  1012,  5835,  1012,\n",
      "          4511,  3221,  1012,  2452,  1012,  9292,  1012,  5442,  1012, 15642,\n",
      "          1012,  4605,  1012, 15212,  1012,  6207,  1012, 11642,  1012,  4589,\n",
      "          1012, 22953, 21408,  3669,  1012, 25659,  1012,  2980,  3899,  1012,\n",
      "         10733,  1012,  2123,  4904,  1012,  9850,  1012,  3242,  1012,  6411,\n",
      "          1012,  8962,  3064,  3269,  1012,  2793,  1012,  7759,  2795,  1012,\n",
      "         11848,  1012,  2694,  1012, 12191,  1012,  8000,  1012,  6556,  1012,\n",
      "          9019,  1012,  3526,  3042,  1012, 18302,  1012, 17428,  1012, 15174,\n",
      "          2121,  1012,  7752,  1012, 18097,  1012,  2338,  1012,  5119,  1012,\n",
      "         18781,  1012, 25806,  1012, 11389,  4562,  1012,  2606,  2852,  3771,\n",
      "          1012, 11868, 18623,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "BaseModelOutput(last_hidden_state=tensor([[[-0.3174, -0.2624,  0.0163,  ...,  0.1824,  0.3389,  0.2700],\n",
      "         [-0.2841, -0.1373,  0.1585,  ..., -0.0062,  0.3030, -0.2764],\n",
      "         [-0.7931, -0.3655,  0.1455,  ...,  0.6724,  0.6181, -0.3034],\n",
      "         ...,\n",
      "         [ 0.5140,  0.1448,  0.2343,  ..., -0.1523,  0.0748,  0.1150],\n",
      "         [ 0.4363,  0.0545, -0.0705,  ..., -0.1296, -0.0864, -0.5054],\n",
      "         [ 1.1169,  0.3222, -0.5750,  ...,  0.4223, -0.1397, -0.0382]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([1, 194, 768])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(outputs)\n",
    "print(last_hidden_states.shape)   # last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of inputs string:  torch.Size([1, 194])\n",
      "0: 101: [CLS]\n",
      "1: 2711: person\n",
      "2: 1012: .\n",
      "3: 10165: bicycle\n",
      "4: 1012: .\n",
      "5: 2482: car\n",
      "6: 1012: .\n",
      "7: 9055: motorcycle\n",
      "8: 1012: .\n",
      "9: 13297: airplane\n",
      "10: 1012: .\n",
      "11: 3902: bus\n",
      "12: 1012: .\n",
      "13: 3345: train\n",
      "14: 1012: .\n",
      "15: 4744: truck\n",
      "16: 1012: .\n",
      "17: 4049: boat\n",
      "18: 1012: .\n",
      "19: 4026: traffic\n",
      "20: 2422: light\n",
      "21: 1012: .\n",
      "22: 2543: fire\n",
      "23: 26018: hydra\n",
      "24: 3372: ##nt\n",
      "25: 1012: .\n",
      "26: 2644: stop\n",
      "27: 3696: sign\n",
      "28: 1012: .\n",
      "29: 5581: parking\n",
      "30: 8316: meter\n",
      "31: 1012: .\n",
      "32: 6847: bench\n",
      "33: 1012: .\n",
      "34: 4743: bird\n",
      "35: 1012: .\n",
      "36: 4937: cat\n",
      "37: 1012: .\n",
      "38: 3899: dog\n",
      "39: 1012: .\n",
      "40: 3586: horse\n",
      "41: 1012: .\n",
      "42: 8351: sheep\n",
      "43: 1012: .\n",
      "44: 11190: cow\n",
      "45: 1012: .\n",
      "46: 10777: elephant\n",
      "47: 1012: .\n",
      "48: 4562: bear\n",
      "49: 1012: .\n",
      "50: 29145: zebra\n",
      "51: 1012: .\n",
      "52: 21025: gi\n",
      "53: 27528: ##raf\n",
      "54: 7959: ##fe\n",
      "55: 1012: .\n",
      "56: 13383: backpack\n",
      "57: 1012: .\n",
      "58: 12977: umbrella\n",
      "59: 1012: .\n",
      "60: 2192: hand\n",
      "61: 16078: ##bag\n",
      "62: 1012: .\n",
      "63: 5495: tie\n",
      "64: 1012: .\n",
      "65: 15940: suitcase\n",
      "66: 1012: .\n",
      "67: 10424: fr\n",
      "68: 2483: ##is\n",
      "69: 11306: ##bee\n",
      "70: 1012: .\n",
      "71: 8301: ski\n",
      "72: 2015: ##s\n",
      "73: 1012: .\n",
      "74: 4586: snow\n",
      "75: 6277: ##board\n",
      "76: 1012: .\n",
      "77: 2998: sports\n",
      "78: 3608: ball\n",
      "79: 1012: .\n",
      "80: 20497: kite\n",
      "81: 1012: .\n",
      "82: 3598: baseball\n",
      "83: 7151: bat\n",
      "84: 1012: .\n",
      "85: 3598: baseball\n",
      "86: 15913: glove\n",
      "87: 1012: .\n",
      "88: 17260: skate\n",
      "89: 6277: ##board\n",
      "90: 1012: .\n",
      "91: 14175: surf\n",
      "92: 6277: ##board\n",
      "93: 1012: .\n",
      "94: 5093: tennis\n",
      "95: 14513: rack\n",
      "96: 3388: ##et\n",
      "97: 1012: .\n",
      "98: 5835: bottle\n",
      "99: 1012: .\n",
      "100: 4511: wine\n",
      "101: 3221: glass\n",
      "102: 1012: .\n",
      "103: 2452: cup\n",
      "104: 1012: .\n",
      "105: 9292: fork\n",
      "106: 1012: .\n",
      "107: 5442: knife\n",
      "108: 1012: .\n",
      "109: 15642: spoon\n",
      "110: 1012: .\n",
      "111: 4605: bowl\n",
      "112: 1012: .\n",
      "113: 15212: banana\n",
      "114: 1012: .\n",
      "115: 6207: apple\n",
      "116: 1012: .\n",
      "117: 11642: sandwich\n",
      "118: 1012: .\n",
      "119: 4589: orange\n",
      "120: 1012: .\n",
      "121: 22953: bro\n",
      "122: 21408: ##cco\n",
      "123: 3669: ##li\n",
      "124: 1012: .\n",
      "125: 25659: carrot\n",
      "126: 1012: .\n",
      "127: 2980: hot\n",
      "128: 3899: dog\n",
      "129: 1012: .\n",
      "130: 10733: pizza\n",
      "131: 1012: .\n",
      "132: 2123: don\n",
      "133: 4904: ##ut\n",
      "134: 1012: .\n",
      "135: 9850: cake\n",
      "136: 1012: .\n",
      "137: 3242: chair\n",
      "138: 1012: .\n",
      "139: 6411: couch\n",
      "140: 1012: .\n",
      "141: 8962: pot\n",
      "142: 3064: ##ted\n",
      "143: 3269: plant\n",
      "144: 1012: .\n",
      "145: 2793: bed\n",
      "146: 1012: .\n",
      "147: 7759: dining\n",
      "148: 2795: table\n",
      "149: 1012: .\n",
      "150: 11848: toilet\n",
      "151: 1012: .\n",
      "152: 2694: tv\n",
      "153: 1012: .\n",
      "154: 12191: laptop\n",
      "155: 1012: .\n",
      "156: 8000: mouse\n",
      "157: 1012: .\n",
      "158: 6556: remote\n",
      "159: 1012: .\n",
      "160: 9019: keyboard\n",
      "161: 1012: .\n",
      "162: 3526: cell\n",
      "163: 3042: phone\n",
      "164: 1012: .\n",
      "165: 18302: microwave\n",
      "166: 1012: .\n",
      "167: 17428: oven\n",
      "168: 1012: .\n",
      "169: 15174: toast\n",
      "170: 2121: ##er\n",
      "171: 1012: .\n",
      "172: 7752: sink\n",
      "173: 1012: .\n",
      "174: 18097: refrigerator\n",
      "175: 1012: .\n",
      "176: 2338: book\n",
      "177: 1012: .\n",
      "178: 5119: clock\n",
      "179: 1012: .\n",
      "180: 18781: vase\n",
      "181: 1012: .\n",
      "182: 25806: scissors\n",
      "183: 1012: .\n",
      "184: 11389: teddy\n",
      "185: 4562: bear\n",
      "186: 1012: .\n",
      "187: 2606: hair\n",
      "188: 2852: dr\n",
      "189: 3771: ##ier\n",
      "190: 1012: .\n",
      "191: 11868: tooth\n",
      "192: 18623: ##brush\n",
      "193: 102: [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of inputs string: \", inputs['input_ids'].shape)\n",
    "\n",
    "# print index, token, and matching token id\n",
    "for i in range(len(inputs['input_ids'][0])):\n",
    "    print(f'{i}: {inputs[\"input_ids\"][0][i]}: {tokenizer.decode([inputs[\"input_ids\"][0][i]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 768])\n"
     ]
    }
   ],
   "source": [
    "class_embeddings = []  # should have 80 elements\n",
    "\n",
    "# initialize a variable with tensor of zeros with shape (1, 768)\n",
    "current_class_embedding = []\n",
    "\n",
    "# ❗️ Making the assumption that the mean of the token embeddings of the word is the word embedding\n",
    "\n",
    "# Do a for loop over the tokenized input\n",
    "for i in range(len(inputs['input_ids'][0])):\n",
    "  current_token = inputs['input_ids'][0][i]\n",
    "  # get the hidden state of the current token\n",
    "  hidden_state = last_hidden_states[0][i]\n",
    "  # if token is [CLS] then skip\n",
    "  if current_token == 101:\n",
    "    continue\n",
    "  # if token is '.' or [SEP] then average the current_class_embedding along the 768 dim and append it to class_embeddings\n",
    "  elif current_token == 1012  or current_token == 102:\n",
    "    current_class_embedding = torch.stack(current_class_embedding)\n",
    "    # if current_class_embedding is dimension 1, then add a dimension to it\n",
    "    if len(current_class_embedding.shape) == 1:\n",
    "      current_class_embedding = current_class_embedding.unsqueeze(0)\n",
    "    class_embeddings.append(torch.mean(current_class_embedding, dim=0))\n",
    "    current_class_embedding = []\n",
    "  # else concatenate the current_class_embedding and the current token's hidden state\n",
    "  else:\n",
    "    current_class_embedding.append(hidden_state)\n",
    "\n",
    "class_embeddings = torch.stack(class_embeddings)\n",
    "print(class_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (A) One slice in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80])\n",
      "80\n",
      "{'person': -0.284, 'bicycle': 0.556, 'car': 0.397, 'motorcycle': 0.64, 'airplane': 0.222, 'bus': 0.115, 'train': 0.386, 'truck': 0.255, 'boat': 0.442, 'traffic light': 0.184, 'fire hydrant': -0.011, 'stop sign': 0.023, 'parking meter': 0.034, 'bench': 0.004, 'bird': 0.079, 'cat': -0.253, 'dog': -0.037, 'horse': 0.06, 'sheep': -0.105, 'cow': 0.007, 'elephant': -0.166, 'bear': -0.127, 'zebra': 0.18, 'giraffe': -0.069, 'backpack': 0.276, 'umbrella': 0.015, 'handbag': -0.123, 'tie': 0.459, 'suitcase': 0.074, 'frisbee': -0.44, 'skis': -0.192, 'snowboard': 0.06, 'sports ball': -0.174, 'kite': 0.126, 'baseball bat': -0.205, 'baseball glove': -0.17, 'skateboard': 0.158, 'surfboard': 0.225, 'tennis racket': 0.11, 'bottle': 0.146, 'wine glass': 0.153, 'cup': -0.302, 'fork': 0.089, 'knife': -0.091, 'spoon': -0.2, 'bowl': -0.163, 'banana': -0.295, 'apple': -0.398, 'sandwich': -0.006, 'orange': -0.513, 'broccoli': -0.399, 'carrot': -0.638, 'hot dog': -0.263, 'pizza': -0.273, 'donut': -0.293, 'cake': 0.094, 'chair': -0.112, 'couch': -0.051, 'potted plant': 0.11, 'bed': 0.058, 'dining table': -0.146, 'toilet': 0.01, 'tv': 0.073, 'laptop': -0.227, 'mouse': -0.349, 'remote': -0.174, 'keyboard': -0.497, 'cell phone': 0.036, 'microwave': 0.082, 'oven': 0.183, 'toaster': -0.147, 'sink': 0.173, 'refrigerator': 0.197, 'book': 0.194, 'clock': 0.365, 'vase': 0.159, 'scissors': 0.446, 'teddy bear': 0.436, 'hair drier': 0.047, 'toothbrush': 0.475}\n"
     ]
    }
   ],
   "source": [
    "def dict_of_slice_n(class_embeddings, n):\n",
    "  # Get the nth slice across all class embeddings\n",
    "  slice_n = class_embeddings[:, n]\n",
    "  print(slice_n.shape)\n",
    "  # Create a dictionary with the coco classes as keys and the corresponding index of slice as values\n",
    "  class_embeddings_dict = {}\n",
    "  for i in range(len(coco_classes)):\n",
    "    # reduce the precision of the slice to 3 decimal places\n",
    "    class_embeddings_dict[coco_classes[i]] = round(slice_n[i].item(), 3)\n",
    "    # original precision:\n",
    "    # class_embeddings_dict[coco_classes[i]] = slice_0[i].item()\n",
    "  return class_embeddings_dict\n",
    "\n",
    "slice_dict = dict_of_slice_n(class_embeddings, 0)\n",
    "print(len(slice_dict))\n",
    "print(slice_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (B) Multiple slices, list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 5])\n",
      "6\n",
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "[-0.284, 0.556, 0.397, 0.64, 0.222, 0.115, 0.386, 0.255, 0.442, 0.184, -0.011, 0.023, 0.034, 0.004, 0.079, -0.253, -0.037, 0.06, -0.105, 0.007, -0.166, -0.127, 0.18, -0.069, 0.276, 0.015, -0.123, 0.459, 0.074, -0.44, -0.192, 0.06, -0.174, 0.126, -0.205, -0.17, 0.158, 0.225, 0.11, 0.146, 0.153, -0.302, 0.089, -0.091, -0.2, -0.163, -0.295, -0.398, -0.006, -0.513, -0.399, -0.638, -0.263, -0.273, -0.293, 0.094, -0.112, -0.051, 0.11, 0.058, -0.146, 0.01, 0.073, -0.227, -0.349, -0.174, -0.497, 0.036, 0.082, 0.183, -0.147, 0.173, 0.197, 0.194, 0.365, 0.159, 0.446, 0.436, 0.047, 0.475]\n",
      "[-0.137, -0.046, -0.128, 0.034, -0.075, -0.357, -0.174, 0.025, 0.007, 0.085, 0.072, 0.003, 0.002, 0.182, 0.195, -0.144, 0.144, 0.149, 0.208, 0.114, 0.305, 0.228, 0.061, -0.051, 0.019, 0.32, -0.124, -0.444, -0.052, -0.04, 0.086, 0.119, -0.04, -0.201, 0.152, 0.026, -0.114, -0.03, -0.091, -0.004, 0.334, 0.015, 0.041, -0.093, 0.105, -0.038, -0.013, -0.009, -0.42, -0.367, -0.78, -0.263, -0.08, -0.184, -0.502, -0.212, 0.02, 0.209, -0.34, -0.061, -0.013, -0.108, -0.272, -0.008, 0.015, 0.172, 0.317, -0.049, 0.511, 0.392, 0.179, 0.186, 0.361, 0.197, 0.311, 0.297, -0.031, 0.383, -0.066, 0.1]\n",
      "[0.159, 0.093, 0.218, 0.11, -0.053, 0.064, 0.075, 0.292, 0.19, 0.271, 0.181, 0.159, 0.348, -0.066, -0.161, -0.112, -0.272, -0.327, -0.353, -0.444, -0.36, -0.378, -0.495, -0.272, -0.015, -0.199, 0.126, 0.168, -0.074, 0.149, 0.14, 0.285, 0.121, -0.129, -0.084, -0.019, 0.307, 0.247, 0.254, 0.186, 0.007, 0.088, 0.101, -0.039, -0.051, 0.229, -0.124, 0.119, 0.187, 0.053, 0.443, 0.086, 0.231, 0.094, 0.268, 0.175, 0.283, 0.316, 0.102, 0.344, 0.186, 0.235, 0.177, 0.176, 0.21, 0.135, 0.327, 0.254, 0.144, -0.026, -0.008, 0.043, 0.077, 0.212, 0.076, 0.044, 0.006, 0.092, 0.298, 0.082]\n",
      "[-0.072, 0.014, -0.02, -0.039, 0.026, 0.165, 0.07, -0.062, 0.055, 0.086, 0.241, 0.064, 0.107, -0.122, -0.277, -0.241, -0.196, -0.214, -0.237, -0.218, -0.22, -0.413, -0.138, 0.104, -0.266, -0.263, -0.023, -0.064, -0.16, 0.008, 0.022, -0.142, -0.152, -0.248, -0.208, -0.259, -0.033, -0.063, -0.035, -0.184, -0.059, -0.231, -0.35, -0.319, -0.186, -0.12, -0.132, -0.196, -0.141, -0.209, 0.077, -0.145, 0.074, -0.329, 0.042, -0.169, -0.106, -0.155, 0.454, -0.011, -0.053, -0.114, -0.243, -0.149, -0.216, -0.196, -0.278, -0.181, -0.361, -0.2, -0.014, -0.229, -0.263, -0.219, -0.168, -0.266, -0.201, -0.149, 0.126, 0.052]\n",
      "[-0.051, 0.283, 0.19, 0.296, 0.368, 0.024, 0.111, 0.016, 0.156, 0.56, 0.608, 0.661, 0.622, 0.083, 0.35, 0.105, 0.14, -0.183, -0.099, -0.147, 0.02, 0.062, -0.029, 0.243, 0.222, 0.414, 0.388, 0.43, 0.16, 0.614, 0.087, 0.321, -0.182, -0.153, 0.144, 0.244, 0.199, 0.288, 0.269, 0.017, 0.533, 0.067, 0.204, 0.079, -0.062, 0.017, -0.191, 0.556, 0.194, 0.574, 0.514, 0.31, 0.558, -0.235, 0.349, -0.122, -0.015, 0.17, 0.732, 0.058, 0.789, 0.023, 0.109, 0.663, 0.725, 0.247, 0.469, 0.851, 0.121, 0.159, 0.107, 0.115, 0.111, 0.388, 0.325, -0.055, 0.162, 0.107, 0.217, 0.532]\n"
     ]
    }
   ],
   "source": [
    "# Get the first n slice across all class embeddings\n",
    "select_n = 5\n",
    "slice_0 = class_embeddings[:, :select_n]\n",
    "# print(slice_0)\n",
    "print(slice_0.shape)\n",
    "\n",
    "# Convert to python list\n",
    "slice_0 = slice_0.T.tolist()\n",
    "# reduce the precision of the slice to 3 decimal places\n",
    "for i in range(len(slice_0)):\n",
    "  slice_0[i] = [round(value, 3) for value in slice_0[i]]\n",
    "# print(slice_0)\n",
    "# print(len(slice_0))\n",
    "\n",
    "# Prepend the list with the coco classes\n",
    "slice_0.insert(0, coco_classes)\n",
    "# print(slice_0)\n",
    "print(len(slice_0))\n",
    "\n",
    "# print each row of the list in new line\n",
    "for row in slice_0:\n",
    "  print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be better to just use the GUI. If we want to directly manipulate the outputs we may need to do some precise prompt engineering. OpenAI has a JSON feature that we could look into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from requests>=2.20->openai) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from requests>=2.20->openai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mattelim/miniforge3/envs/6861/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "# install OpenAI api\n",
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = \"your api key here\"\n",
    "\n",
    "import openai\n",
    "openai.api_key = my_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"There are 6 dimensions.\\n\\nRow 1: 3D shape. The values for this dimension vary significantly across the labels, indicating that it encodes information about the three-dimensional shape of the objects.\\nRow 2: Mobility. The values for this dimension are mostly positive, suggesting that it encodes information about the mobility or movement associated with the objects.\\nRow 3: Edibility. The values for this dimension are a mix of positive and negative, but they are generally low, indicating that it encodes information about the edibility of the objects.\\nRow 4: Size. The values for this dimension range from negative to positive, suggesting that it encodes information about the size or scale of the objects.\\nRow 5: Consumer goods. The values for this dimension are mostly negative, indicating that it encodes information about whether the objects are commonly used consumer goods.\\nRow 6: Natural vs. Man-made. The values for this dimension vary significantly across the labels, suggesting that it encodes information about whether the objects are natural or man-made.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"For the following lists, the first list contains words that have been put into DistilBERT – let us call this a label. Each of the subsequent lists contains the embedding value from DistilBERT for one dimension (out of 768) across the labels. By comparing the values for each label for each list, please interpret the likely concepts that each list, that is the dimension/axis of the embedding, encodes. Each of the 50 rows should encode a different concept. \\n\\n First, count the number of lists excluding the first (the labels list) and report on the number. \\n '''There are <N> dimensions''' \\n\\n Then, the main output should take this form for row 'n', from 'Row 1' to 'Row N': \\n '''Row n: <encoded concept>. <one sentence rationale for interpretation>''' \\n\\n {slice_0}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "\n",
    "# log the stringified output into a txt file by appending it to the end of the file\n",
    "with open(\"output.txt\", \"a\") as f:\n",
    "  f.write(str(completion.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6861",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
