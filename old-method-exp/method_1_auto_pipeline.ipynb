{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install OpenAI api\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded.\n"
     ]
    }
   ],
   "source": [
    "# load api key from secrets.json\n",
    "try:\n",
    "    with open(\"secrets.json\") as f:\n",
    "        secrets = json.load(f)\n",
    "    my_api_key = secrets[\"openai\"]\n",
    "    print(\"API key loaded.\")\n",
    "    openai.api_key = my_api_key\n",
    "except FileNotFoundError:\n",
    "    print(\"Secrets file not found. YOU NEED THEM TO RUN THIS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key = openai.api_key)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# CUSTOMIZE HERE\n",
    "data_gen_model = \"gpt-3.5-turbo\"\n",
    "interpreter_model = \"gpt-4\"\n",
    "num_words = 120\n",
    "category = \"music\"\n",
    "num_axes_to_sample = 10\n",
    "num_interpretations_per_axis = 3\n",
    "bucket_size = 20\n",
    "num_synth_embeddings = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "response = client.chat.completions.create(\n",
    "      model=data_gen_model,\n",
    "      messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are an expert transformer embeddings labeller.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Please list {num_words} words related to {category}. Please format your response as a python list. Do not assign the list to a variable name.\"}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acoustic', 'album', 'artist', 'bass', 'beat', 'billboard', 'bpm', 'chart', 'chord', 'classical', 'composer', 'concert', 'country', 'dance', 'dj', 'drum', 'electric', 'genre', 'guitar', 'harmony', 'hip-hop', 'instrument', 'jazz', 'lyrics', 'melody', 'metal', 'musician', 'notes', 'opera', 'orchestra', 'piano', 'pop', 'rap', 'record', 'reggae', 'rhythm', 'rock', 'singer', 'song', 'sound', 'songwriter', 'studio', 'symphony', 'tempo', 'verse', 'vocal', 'vocals', 'acapella', 'arrangement', 'audience', 'ballad,band', 'baritone', 'bassoon', 'beatbox', 'brass', 'cadence', 'cajun', 'cello', 'chorus', 'clarinet', 'composer', 'concert', 'conductor', 'crescendo', 'decrescendo', 'disco', 'duet', 'dynamics', 'ensemble', 'falsetto', 'flute', 'folk', 'funk', 'gig', 'glissando', 'groove', 'harmonica', 'headphones', 'horn', 'improvisation', 'interval', 'jingle', 'live', 'lyrics', 'mandolin', 'marimba', 'metronome', 'microphone', 'mixer', 'modulation', 'movement', 'mp3', 'music', 'musical', 'note', 'octave', 'orchestra', 'overdub', 'phrase', 'piccolo', 'pitch', 'podcast', 'pop,progression', 'quartet', 'radio', 'recital', 'remix', 'rest', 'rhythm', 'rock', 'saxophone', 'score', 'sheet', 'sitar', 'solo', 'soprano', 'soul', 'sound', 'speaker', 'staccato', 'stereo', 'streaming', 'strings', 'synthesizer', 'talkbox', 'techno', 'timbre', 'trombone', 'trumpet', 'tuba', 'ukulele', 'viola', 'violin', 'vocal', 'waltz', 'whistle', 'woodwind', 'xylophone', 'youtube']\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "words_str = response.choices[0].message.content\n",
    "# print(words_str)\n",
    "\n",
    "# convert string into list\n",
    "cleaned_string = re.sub(r'([\\n\\'])', '', words_str)\n",
    "words = cleaned_string.strip(\"][\").split(', ')\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# create train and test sets by randomly sampling 80-20 split\n",
    "\n",
    "split_point = round(0.8 * len(words))\n",
    "# print(split_point)\n",
    "\n",
    "train_words = words[:split_point]\n",
    "test_words = words[split_point:]\n",
    "\n",
    "print(len(train_words))\n",
    "print(len(test_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "# https://huggingface.co/distilbert-base-uncased\n",
    "# https://huggingface.co/docs/transformers/v4.35.0/en/model_doc/distilbert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "\n",
    "def get_embeddings(tokenizer, model, words):\n",
    "    # get embedding for each class\n",
    "    # ❗️ note: I am averaging the embeddings for each word in the class\n",
    "    # ❓ question: are we interested in the final contextual embedding for each class? currently, we're looking at the final hidden state.\n",
    "    embeddings = []\n",
    "    for i in range(len(words)):\n",
    "        input_ids = torch.tensor(tokenizer.encode(words[i])).unsqueeze(0)\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # skip the first token, which is the [CLS] token, and skip the last token, which is the [SEP] token\n",
    "        # average the rest of the tokens\n",
    "        embeddings.append(last_hidden_states[0][1:-1].mean(dim=0).tolist())\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings for train and test set\n",
    "\n",
    "train_embeddings = get_embeddings(tokenizer, model, train_words)\n",
    "test_embeddings = get_embeddings(tokenizer, model, test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "768\n",
      "28\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(len(train_embeddings))\n",
    "print(len(train_embeddings[0]))\n",
    "\n",
    "print(len(test_embeddings))\n",
    "print(len(test_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert embeddings to df and save as csv\n",
    "def process_embeddings(scaler, words, embeddings, prefix):\n",
    "    # round to 3 decimal places\n",
    "    embeddings = [list(np.around(np.array(e),3)) for e in embeddings]\n",
    "\n",
    "    # convert embeddings to pandas dataframe\n",
    "    df = pd.DataFrame(embeddings)\n",
    "    df.insert(0, 'word', words)\n",
    "\n",
    "    # normalize each column to be between -1 and 1\n",
    "    df.iloc[:,1:] = scaler.fit_transform(df.iloc[:,1:])\n",
    "\n",
    "    # save to csv\n",
    "    df.to_csv(f\"{prefix}_output.csv\", index=False)\n",
    "\n",
    "    return embeddings, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process train/test embeddings\n",
    "train_embeddings, train_df = process_embeddings(scaler, train_words, train_embeddings, \"train\")\n",
    "test_embeddings, test_df = process_embeddings(scaler, test_words, test_embeddings, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acoustic</td>\n",
       "      <td>-0.144756</td>\n",
       "      <td>-0.170021</td>\n",
       "      <td>0.258300</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>-0.134048</td>\n",
       "      <td>0.152404</td>\n",
       "      <td>-0.079646</td>\n",
       "      <td>-0.294946</td>\n",
       "      <td>0.183733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706708</td>\n",
       "      <td>-0.372419</td>\n",
       "      <td>0.505285</td>\n",
       "      <td>-0.190319</td>\n",
       "      <td>-0.043559</td>\n",
       "      <td>-0.597720</td>\n",
       "      <td>-0.163916</td>\n",
       "      <td>-0.161987</td>\n",
       "      <td>-0.494118</td>\n",
       "      <td>-0.236585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>album</td>\n",
       "      <td>0.024205</td>\n",
       "      <td>-0.278279</td>\n",
       "      <td>-0.221053</td>\n",
       "      <td>-0.331002</td>\n",
       "      <td>0.226542</td>\n",
       "      <td>-0.240424</td>\n",
       "      <td>0.122124</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.212781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843994</td>\n",
       "      <td>-0.679604</td>\n",
       "      <td>0.473573</td>\n",
       "      <td>-0.084708</td>\n",
       "      <td>-0.367933</td>\n",
       "      <td>-0.167752</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.241901</td>\n",
       "      <td>0.762745</td>\n",
       "      <td>-0.403659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artist</td>\n",
       "      <td>-0.111533</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>-0.392713</td>\n",
       "      <td>-0.426573</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.075795</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.669866</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744150</td>\n",
       "      <td>-0.853014</td>\n",
       "      <td>0.198732</td>\n",
       "      <td>0.229923</td>\n",
       "      <td>-0.149212</td>\n",
       "      <td>-0.026059</td>\n",
       "      <td>-0.381738</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.374510</td>\n",
       "      <td>-0.307317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bass</td>\n",
       "      <td>0.353583</td>\n",
       "      <td>-0.374046</td>\n",
       "      <td>-0.308502</td>\n",
       "      <td>-0.198135</td>\n",
       "      <td>-0.617962</td>\n",
       "      <td>-0.075795</td>\n",
       "      <td>-0.212389</td>\n",
       "      <td>-0.156750</td>\n",
       "      <td>-0.435004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932917</td>\n",
       "      <td>-0.060281</td>\n",
       "      <td>-0.061311</td>\n",
       "      <td>-0.282728</td>\n",
       "      <td>0.208526</td>\n",
       "      <td>-0.114007</td>\n",
       "      <td>-0.526953</td>\n",
       "      <td>0.090713</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>-0.565854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beat</td>\n",
       "      <td>0.161841</td>\n",
       "      <td>-0.283831</td>\n",
       "      <td>0.331174</td>\n",
       "      <td>-0.310023</td>\n",
       "      <td>0.328418</td>\n",
       "      <td>0.126324</td>\n",
       "      <td>0.576991</td>\n",
       "      <td>-0.436980</td>\n",
       "      <td>0.236020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258970</td>\n",
       "      <td>0.298101</td>\n",
       "      <td>-0.196617</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.805375</td>\n",
       "      <td>0.495114</td>\n",
       "      <td>-0.680968</td>\n",
       "      <td>0.049676</td>\n",
       "      <td>-0.498039</td>\n",
       "      <td>-0.512195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word         0         1         2         3         4         5  \\\n",
       "0  acoustic -0.144756 -0.170021  0.258300  0.433566 -0.134048  0.152404   \n",
       "1     album  0.024205 -0.278279 -0.221053 -0.331002  0.226542 -0.240424   \n",
       "2    artist -0.111533  0.548924 -0.392713 -0.426573  0.048257  0.075795   \n",
       "3      bass  0.353583 -0.374046 -0.308502 -0.198135 -0.617962 -0.075795   \n",
       "4      beat  0.161841 -0.283831  0.331174 -0.310023  0.328418  0.126324   \n",
       "\n",
       "          6         7         8  ...       758       759       760       761  \\\n",
       "0 -0.079646 -0.294946  0.183733  ...  0.706708 -0.372419  0.505285 -0.190319   \n",
       "1  0.122124 -0.667306  0.212781  ...  0.843994 -0.679604  0.473573 -0.084708   \n",
       "2 -0.200000 -0.669866  0.514887  ...  0.744150 -0.853014  0.198732  0.229923   \n",
       "3 -0.212389 -0.156750 -0.435004  ...  0.932917 -0.060281 -0.061311 -0.282728   \n",
       "4  0.576991 -0.436980  0.236020  ...  0.258970  0.298101 -0.196617  0.544554   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.043559 -0.597720 -0.163916 -0.161987 -0.494118 -0.236585  \n",
       "1 -0.367933 -0.167752  0.247525  0.241901  0.762745 -0.403659  \n",
       "2 -0.149212 -0.026059 -0.381738  0.051836  0.374510 -0.307317  \n",
       "3  0.208526 -0.114007 -0.526953  0.090713  0.364706 -0.565854  \n",
       "4  0.805375  0.495114 -0.680968  0.049676 -0.498039 -0.512195  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>score</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>-0.342930</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.495812</td>\n",
       "      <td>-0.412883</td>\n",
       "      <td>0.356256</td>\n",
       "      <td>-0.604858</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605825</td>\n",
       "      <td>-0.512322</td>\n",
       "      <td>0.788372</td>\n",
       "      <td>0.648725</td>\n",
       "      <td>0.479821</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.401947</td>\n",
       "      <td>-0.478705</td>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sheet</td>\n",
       "      <td>0.862216</td>\n",
       "      <td>-0.251482</td>\n",
       "      <td>-0.060886</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>-0.090452</td>\n",
       "      <td>-0.273495</td>\n",
       "      <td>-0.226361</td>\n",
       "      <td>-0.125506</td>\n",
       "      <td>0.096601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596117</td>\n",
       "      <td>0.258106</td>\n",
       "      <td>-0.465116</td>\n",
       "      <td>0.059490</td>\n",
       "      <td>0.374439</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>-0.883171</td>\n",
       "      <td>-0.059625</td>\n",
       "      <td>-0.222651</td>\n",
       "      <td>0.587429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sitar</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.856089</td>\n",
       "      <td>-0.901316</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>-0.831045</td>\n",
       "      <td>0.352436</td>\n",
       "      <td>-0.183806</td>\n",
       "      <td>-0.232558</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.509728</td>\n",
       "      <td>0.067442</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>-0.067265</td>\n",
       "      <td>0.262594</td>\n",
       "      <td>-0.952712</td>\n",
       "      <td>0.223169</td>\n",
       "      <td>-0.214929</td>\n",
       "      <td>-0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solo</td>\n",
       "      <td>0.106534</td>\n",
       "      <td>-0.055038</td>\n",
       "      <td>-0.252768</td>\n",
       "      <td>0.048246</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>-0.554919</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>-0.348837</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045396</td>\n",
       "      <td>0.672093</td>\n",
       "      <td>-0.331445</td>\n",
       "      <td>0.284753</td>\n",
       "      <td>0.095391</td>\n",
       "      <td>-0.426982</td>\n",
       "      <td>0.083475</td>\n",
       "      <td>-0.619048</td>\n",
       "      <td>-0.337143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soprano</td>\n",
       "      <td>-0.215909</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>-0.182657</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.780570</td>\n",
       "      <td>0.296727</td>\n",
       "      <td>0.232092</td>\n",
       "      <td>-0.196761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>-0.255512</td>\n",
       "      <td>-0.151163</td>\n",
       "      <td>-0.436261</td>\n",
       "      <td>-0.551570</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.452017</td>\n",
       "      <td>-0.226576</td>\n",
       "      <td>0.503218</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word         0         1         2         3         4         5  \\\n",
       "0    score  0.225852 -0.342930  0.025830  0.074561  0.495812 -0.412883   \n",
       "1    sheet  0.862216 -0.251482 -0.060886  0.412281 -0.090452 -0.273495   \n",
       "2    sitar  0.568182 -1.000000 -0.856089 -0.901316  0.633166 -0.831045   \n",
       "3     solo  0.106534 -0.055038 -0.252768  0.048246  0.085427  0.066526   \n",
       "4  soprano -0.215909  0.126164 -0.182657 -1.000000 -0.780570  0.296727   \n",
       "\n",
       "          6         7         8  ...       758       759       760       761  \\\n",
       "0  0.356256 -0.604858  0.674419  ...  0.605825 -0.512322  0.788372  0.648725   \n",
       "1 -0.226361 -0.125506  0.096601  ...  0.596117  0.258106 -0.465116  0.059490   \n",
       "2  0.352436 -0.183806 -0.232558  ... -1.000000  0.509728  0.067442  0.382436   \n",
       "3 -0.554919  0.057490 -0.348837  ...  1.000000 -0.045396  0.672093 -0.331445   \n",
       "4  0.232092 -0.196761  1.000000  ...  0.475728 -0.255512 -0.151163 -0.436261   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.479821  0.035370  0.401947 -0.478705  0.727156  0.720000  \n",
       "1  0.374439  0.016077 -0.883171 -0.059625 -0.222651  0.587429  \n",
       "2 -0.067265  0.262594 -0.952712  0.223169 -0.214929 -0.714286  \n",
       "3  0.284753  0.095391 -0.426982  0.083475 -0.619048 -0.337143  \n",
       "4 -0.551570 -1.000000 -0.452017 -0.226576  0.503218 -1.000000  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpreting axes with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt helpers\n",
    "system_instructions = \"\"\"\n",
    "You are an expert word embedding axis interpreter who only outputs results in the form: {<interpretation>:<interpretation confidence score>}. \n",
    "\n",
    "You will be given a dataframe as input, where the first column is a list of words, \n",
    "and the second column is a list of numbers between -1 and 1. The numbers represent the embedding value of the word along a particular axis.\n",
    "\n",
    "By carefully comparing and considering the embedding values for each word, please interpret the likely linguistic feature that this \n",
    "embedding axis encodes. This interpretation must be consistent across all the words and correspond to their respective positive, zero, \n",
    "or negative embedding values.  You might consider analyzing the top 10 words with values close to -1, the top 10 words with values \n",
    "close to 0 (median), and the top 10 words with values close to 1 to generate your interpretation. \n",
    "\n",
    "Please phrase your interpretation like: \"negative sentiment vs positive sentiment\", \"small, blue objects vs large, red objects\", \n",
    "etc (some contrast with \"vs\" should be present). Only include one interpretation per axis. Please use descriptive, \n",
    "contrastive phrases in your interpretations.\n",
    "\n",
    "For each axis, also include a confidence score of how confident you are in your interpretation of that axis. \n",
    "\n",
    "For each axis, the output should look like this exactly: {<interpretation>:<interpretation confidence score>} (e.g., \n",
    "{\"positive sentiment vs. negative sentiment\": 0.6}) Remember each <interpretation> should include 1 instance of \"vs\".\n",
    "\n",
    "Remember to format your output for each axis as requested above as a python dictionary. DO NOT EXPLAIN YOUR ANSWER OR OUTPUT ANYTHING \n",
    "EXCEPT THE FINAL DICTIONARY. \n",
    "\"\"\"\n",
    "\n",
    "helper_function = \"\"\"\n",
    "Use the code below to help with your interpretations.\n",
    "\n",
    "# Function to analyze an axis and derive interpretation\n",
    "def analyze_axis(axis_index):\n",
    "    axis_name = df.columns[axis_index]\n",
    "\n",
    "    # Find top 10 words close to -1, 0, and 1 for this axis\n",
    "    top_neg = df.nsmallest(10, axis_name)[['word', axis_name]]\n",
    "    top_zero = df.iloc[(df[axis_name]-0).abs().argsort()[:10]][['word', axis_name]]\n",
    "    top_pos = df.nlargest(10, axis_name)[['word', axis_name]]\n",
    "\n",
    "    return top_neg, top_zero, top_pos\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = system_instructions + helper_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n",
      "Round 2:\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n",
      "Round 3:\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create array of dicts to store interpretations of each axis\n",
    "all_axes = []\n",
    "\n",
    "# initialize empty dict for each axis\n",
    "for i in range(num_axes_to_sample):\n",
    "    all_axes.append({})\n",
    "    \n",
    "# ask model to analyze specified number of axes \n",
    "# repeat to generate multiple interpretations for each axis\n",
    "for n in range(num_interpretations_per_axis):\n",
    "  print(f\"Round {n+1}:\")\n",
    "  for i in range(num_axes_to_sample):\n",
    "      # get corresponding columns from dataframe\n",
    "      df_subset = train_df[[\"word\", i]]\n",
    "      \n",
    "      response = client.chat.completions.create(\n",
    "            model=interpreter_model,\n",
    "            messages=[\n",
    "              {\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": f\"Here is the dataframe for axis {i}:\\n{df_subset.to_string(index=False)}\\n\\n\"},\n",
    "            ]\n",
    "          )\n",
    "\n",
    "      interpretation = response.choices[0].message.content\n",
    "      cleaned_string = re.sub(r'([\\\"])', '', interpretation)\n",
    "      res = cleaned_string.strip(\"{}\").split(': ')\n",
    "\n",
    "      # add interpretation + confidence score to axis dict\n",
    "      all_axes[i][res[0]] = float(res[1])\n",
    "      print(\"Axis\", i, \"done.\")\n",
    "      # break\n",
    "  print()\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis 0: {'Traditional, acoustic music vs. Modern, electronic music': 0.8, 'complex, classical musical terms vs simple, modern music terms': 0.8, 'Traditional or acoustic music vs. modern or electronic music': 0.8}\n",
      "Axis 1: {'professional classical musicians vs. popular music performers': 0.8, 'individual performers vs ensemble performance': 0.8, \"performer's perspective vs audience's perspective\": 0.85}\n",
      "Axis 2: {'electronic music production vs. traditional music performance': 0.75, 'modern, electronic music vs traditional, classical music': 0.85, 'music production/technical terms vs. music genres and roles': 0.8}\n",
      "Axis 3: {'traditional musical elements vs. modern musical elements': 0.85, 'traditional vs. modern music elements': 0.8, 'non-electronic/digital music elements vs. electronic/digital music elements': 0.75}\n",
      "Axis 4: {'instrumental music vs. vocal music': 0.7, 'physical aspects of sound production vs performative and popular music aspects': 0.85, 'live performance vs. studio recording': 0.85}\n",
      "Axis 5: {'vocal and harmonious terms vs. genre and recording related terms': 0.85, 'live performance vs. studio recording': 0.8, 'Electronic music genres vs. Acoustic instruments': 0.8}\n",
      "Axis 6: {'non-rhythmic musical features vs. rhythmic musical features': 0.8, 'instruments or music-related terms associated with slow, calm, traditional genres or concepts vs. terms associated with fast, energetic, modern genres or concepts': 0.85, 'static, instrumental music vs dynamic, vocal music': 0.85}\n",
      "Axis 7: {'traditional music vs electronic music': 0.85, 'modern music forms vs. traditional music forms': 0.85, 'traditional, acoustic musical elements vs electronic, modern musical elements': 0.85}\n",
      "Axis 8: {'classical music terms vs modern music terms': 0.85, 'Traditional vs. Modern Music Formats': 0.85, 'Non-electronic, classic aspects of music vs. Electronic, modern aspects of music': 0.8}\n",
      "Axis 9: {'non-instrumental music aspects vs instrumental music aspects': 0.8, 'instrument complexity vs rhythmic complexity': 0.8, 'acoustic properties vs electronic properties': 0.75}\n"
     ]
    }
   ],
   "source": [
    "with open(\"interpretations.txt\", \"w\") as f:\n",
    "    for i in range(len(all_axes)):\n",
    "        output_str = f\"Axis {i}: {all_axes[i]}\"\n",
    "        print(output_str)\n",
    "        # also save to file\n",
    "        f.write(output_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'mean': 0.8, 'median': 0.8, 'stdev': 0.0}, 1: {'mean': 0.817, 'median': 0.8, 'stdev': 0.029}, 2: {'mean': 0.8, 'median': 0.8, 'stdev': 0.05}, 3: {'mean': 0.8, 'median': 0.8, 'stdev': 0.05}, 4: {'mean': 0.8, 'median': 0.85, 'stdev': 0.087}, 5: {'mean': 0.817, 'median': 0.8, 'stdev': 0.029}, 6: {'mean': 0.833, 'median': 0.85, 'stdev': 0.029}, 7: {'mean': 0.85, 'median': 0.85, 'stdev': 0.0}, 8: {'mean': 0.833, 'median': 0.85, 'stdev': 0.029}, 9: {'mean': 0.783, 'median': 0.8, 'stdev': 0.029}}\n"
     ]
    }
   ],
   "source": [
    "# compute descriptive stats for each axis' confidence scores\n",
    "# store in dict where key is axis number and value is dict of descriptive stats\n",
    "import statistics\n",
    "\n",
    "axes_stats = {}\n",
    "for i in range(len(all_axes)):\n",
    "    axis = all_axes[i]\n",
    "    mean = statistics.mean(axis.values())\n",
    "    median = statistics.median(axis.values())\n",
    "    stdev = statistics.stdev(axis.values())\n",
    "\n",
    "    # round each val to 3 decimal places\n",
    "    mean = round(mean, 3)\n",
    "    median = round(median, 3)\n",
    "    stdev = round(stdev, 3)\n",
    "\n",
    "    # store in dict\n",
    "    axes_stats[i] = {\"mean\": mean, \"median\": median, \"stdev\": stdev}\n",
    "\n",
    "print(axes_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8133333333333334\n",
      "median: 0.8\n",
      "stdev: 0.025198172728761126\n"
     ]
    }
   ],
   "source": [
    "# overall mean, median, and stdev of all axes' confidence scores\n",
    "mean = statistics.mean([statistics.mean(axis.values()) for axis in all_axes])\n",
    "median = statistics.median([statistics.median(axis.values()) for axis in all_axes])\n",
    "stdev = statistics.stdev([statistics.stdev(axis.values()) for axis in all_axes])\n",
    "\n",
    "# print overall mean, median, and stdev\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"median: {median}\")\n",
    "print(f\"stdev: {stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- mean confidence increased!!\n",
    "- but slightly higher stdev (old version: 0.017), still pretty good though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyzing interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt helpers\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert word embedding axis interpreter.\n",
    "\n",
    "Below I will provide interpretations and confidence scores for one axis in high dimensional word embeddings. \n",
    "Each axis has 3 potential interpretations + corresponding confidence scores. \n",
    "For each axis, summarize the three interpretations into a single interpretation per axis \n",
    "by considering the confidence scores, similarities between the interpretations, the most common interpretations, etc. \n",
    "This summary interpretation does not have to be one of the original three interpretations word for word, but it can be. \n",
    "Keep the contrasting phrases in the same relative order, as the first phrase in the interpretation represents what \n",
    "negative embedding values stand for in the axis, while the second  phrase after vs. represents what positive embedding values stand for.\n",
    "\n",
    "As before, each interpretation should consist of two descriptive, contrastive phrases separated by \"vs\". \n",
    "DO NOT EXPLAIN YOUR ANSWER OR OUTPUT ANYTHING EXCEPT THE FINAL SUMMARY INTERPRETATION.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_2 = \"\"\"\n",
    "You are an expert word embedding axis interpreter who only answers all prompts with a single number between 1-10.\n",
    "\n",
    "Below I will provide interpretations and confidence scores for one axis in high dimensional word embeddings. \n",
    "Each axis has 3 potential interpretations + corresponding confidence scores. \n",
    "For each axis, please assign a qualitative similarity rating from 1-10 to how similar the interpretations are \n",
    "(1: not at all similar, 10: identical).\n",
    "\n",
    "DO NOT EXPLAIN YOUR ANSWER OR OUTPUT ANYTHING EXCEPT THE FINAL SIMILARITY RATING.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n"
     ]
    }
   ],
   "source": [
    "# store final interpretations in list\n",
    "final_axes = []\n",
    "\n",
    "# initialize empty dict for each axis\n",
    "for i in range(num_axes_to_sample):\n",
    "    final_axes.append({})\n",
    "\n",
    "# summarize interpretations into one per axis\n",
    "for i in range(num_axes_to_sample):\n",
    "      # get summary interpretation\n",
    "      \n",
    "      response = client.chat.completions.create(\n",
    "            model=interpreter_model,\n",
    "            messages=[\n",
    "              {\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": f\"Here are the three interpretations for axis {i}:\\n{all_axes[i]}\\n\\n\"},\n",
    "            ]\n",
    "          )\n",
    "\n",
    "      interpretation = response.choices[0].message.content\n",
    "      # print(interpretation)\n",
    "\n",
    "      rating_list = []\n",
    "      for t in range(num_interpretations_per_axis):\n",
    "        response = client.chat.completions.create(\n",
    "              model=data_gen_model,\n",
    "              messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt_2},\n",
    "                {\"role\": \"user\", \"content\": f\"Here are the three interpretations for axis {i}:\\n{all_axes[i]}\\n\\n\"},\n",
    "              ]\n",
    "            )\n",
    "\n",
    "        rating = float(response.choices[0].message.content)\n",
    "        rating_list.append(rating)\n",
    "\n",
    "      # add summary interpretation + ratings to final axes list\n",
    "      final_axes[i][interpretation] = rating_list\n",
    "      print(\"Axis\", i, \"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Traditional, acoustic music vs. Modern, electronic music': [8.0, 7.0, 10.0]}, {'professional classical musicians vs. popular ensemble music performance from an audiences perspective': [9.5, 10.0, 8.2]}, {'electronic music production vs. traditional music performance': [6.5, 7.7, 9.5]}, {'traditional/non-electronic music elements vs. modern/electronic music elements': [9.5, 10.0, 10.0]}, {'instrumental music vs. vocal and popular performance aspects': [7.8, 8.0, 8.5]}, {'Vocal and harmonious terms vs. genre, recording, and instrument-related terms': [8.3, 8.3, 10.0]}, {'slow, calm, non-rhythmic, traditional/instrumental music features vs. fast, energetic, rhythmic, modern/vocal music features': [8.5, 7.6, 10.0]}, {'traditional, acoustic music vs electronic, modern music': [10.0, 9.0, 7.0]}, {'classical, non-electronic aspects of music vs. modern, electronic aspects of music': [10.0, 10.0, 7.5]}, {'non-instrumental and acoustic aspects of music vs instrumental, rhythmic and electronic aspects of music': [6.7, 7.75, 8.5]}]\n"
     ]
    }
   ],
   "source": [
    "# clean keys in final_axes\n",
    "for dict in final_axes:\n",
    "    key = list(dict.keys())[0]\n",
    "    cleaned_string = re.sub(r'([\\n\\'])', '', key)\n",
    "    dict[cleaned_string] = dict.pop(key)\n",
    "\n",
    "print(final_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'mean': 8.333, 'median': 8.0, 'stdev': 1.528}, 1: {'mean': 9.233, 'median': 9.5, 'stdev': 0.929}, 2: {'mean': 7.9, 'median': 7.7, 'stdev': 1.51}, 3: {'mean': 9.833, 'median': 10.0, 'stdev': 0.289}, 4: {'mean': 8.1, 'median': 8.0, 'stdev': 0.361}, 5: {'mean': 8.867, 'median': 8.3, 'stdev': 0.981}, 6: {'mean': 8.7, 'median': 8.5, 'stdev': 1.212}, 7: {'mean': 8.667, 'median': 9.0, 'stdev': 1.528}, 8: {'mean': 9.167, 'median': 10.0, 'stdev': 1.443}, 9: {'mean': 7.65, 'median': 7.75, 'stdev': 0.904}}\n",
      "mean: 8.645\n",
      "median: 8.4\n",
      "stdev: 0.46438227656945974\n"
     ]
    }
   ],
   "source": [
    "# compute descriptive stats for each axis' confidence scores\n",
    "# store in dict where key is axis number and value is dict of descriptive stats\n",
    "axes_stats = {}\n",
    "for i in range(len(final_axes)):\n",
    "    axis = final_axes[i]\n",
    "    # value is a list of confidence scores\n",
    "    mean = statistics.mean(list(axis.values())[0])\n",
    "    median = statistics.median(list(axis.values())[0])\n",
    "    stdev = statistics.stdev(list(axis.values())[0])\n",
    "\n",
    "    # round each val to 3 decimal places\n",
    "    mean = round(mean, 3)\n",
    "    median = round(median, 3)\n",
    "    stdev = round(stdev, 3)\n",
    "\n",
    "    # store in dict\n",
    "    axes_stats[i] = {\"mean\": mean, \"median\": median, \"stdev\": stdev}\n",
    "\n",
    "print(axes_stats)\n",
    "\n",
    "# overall mean, median, and stdev of all axes' confidence scores\n",
    "mean = statistics.mean([statistics.mean(list(axis.values())[0]) for axis in final_axes])\n",
    "median = statistics.median([statistics.median(list(axis.values())[0]) for axis in final_axes])\n",
    "stdev = statistics.stdev([statistics.stdev(list(axis.values())[0]) for axis in final_axes])\n",
    "\n",
    "# print overall mean, median, and stdev\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"median: {median}\")\n",
    "print(f\"stdev: {stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- slightly higher mean similarity rating (8.65 vs. 7.6 from before), seems pretty good\n",
    "- stdev is a bit higher than before, but not too bad (0.46 vs 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Traditional, acoustic music vs. Modern, electronic music', 'professional classical musicians vs. popular ensemble music performance from an audiences perspective', 'electronic music production vs. traditional music performance', 'traditional/non-electronic music elements vs. modern/electronic music elements', 'instrumental music vs. vocal and popular performance aspects', 'Vocal and harmonious terms vs. genre, recording, and instrument-related terms', 'slow, calm, non-rhythmic, traditional/instrumental music features vs. fast, energetic, rhythmic, modern/vocal music features', 'traditional, acoustic music vs electronic, modern music', 'classical, non-electronic aspects of music vs. modern, electronic aspects of music', 'non-instrumental and acoustic aspects of music vs instrumental, rhythmic and electronic aspects of music']\n"
     ]
    }
   ],
   "source": [
    "# extract interpretations from axes\n",
    "interpretations = []\n",
    "for axis in final_axes:\n",
    "    interpretations.append(list(axis.keys())[0])\n",
    "\n",
    "# sanity check\n",
    "print(interpretations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I asked chatgpt to assign scores for each axis, and repeated this 3 times.\n",
    "\n",
    "```\n",
    "For each criteria in this list: {list}\n",
    "\n",
    "assign a score to each word in this list:\n",
    "# insert here\n",
    "\n",
    "(should be a float) between -1 and 1 based on the current criteria. Note that each criteria consists of two contrastive phrases, x and y, formatted like: {x vs. y}. Scores closer to -1 indicate the word is more correlated to {x}, while scores closer to 1 indicate the word is more correlated to {y}. Scores closer to 0 indicate that the word is more neutral with respect to the criteria, falls in between the extremes, or isn't really related to either {x} or {y}. You don't need to justify your scores, just provide the numbers.\n",
    "\n",
    "For each criteria, your output should be a python list of scores (length = 100, because there are 100 words). Print each criteria on a line followed by its corresponding list like this on another line: \n",
    "\n",
    "{criteria}:\n",
    "[score 1, score 2, ...]. \n",
    "\n",
    "You should not need code to perform this task, just assign scores qualitatively. Don't print anything else except for the list of scores, and don't format anything as code.\n",
    "\n",
    "Please start with the first criteria: {criteria}. Only do one criteria at a time.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt helpers\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an expert word sense scorer who answers all prompts by outputting a single python list of {len(train_words)} scores that looks\n",
    "exactly like this: [score 1, score 2, ...].\n",
    "\n",
    "For the given criteria and list, please assign a score to each word in the list. Each score should be a float between -1 and 1 \n",
    "based on the current criteria. Note that each criteria consists of two contrastive phrases, x and y, \n",
    "formatted like: x vs. y. Scores closer to -1 indicate the word is more correlated to x, while scores closer to 1 indicate the word\n",
    "is more correlated to y. Scores closer to 0 indicate that the word is more neutral with respect to the criteria, \n",
    "falls in between the extremes, or isn't really related to either x or y. You don't need to justify your scores, just provide the numbers.\n",
    "\n",
    "Your output should be a python list of scores (length = {len(train_words)}, because there are {len(train_words)} words). \n",
    "It should look like this: [score 1, score 2, ...].\n",
    "\n",
    "You should not need code to perform this task, just assign scores qualitatively. \n",
    "DO NOT EXPLAIN YOUR ANSWER OR OUTPUT ANYTHING EXCEPT THE FINAL LIST OF SCORES.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get synethic embeddings\n",
    "def assign_values(words, interpretations):\n",
    "    # store final interpretations in list\n",
    "  value_list = []\n",
    "\n",
    "  # initialize empty list for each axis\n",
    "  for i in range(num_axes_to_sample):\n",
    "      # get list for this axis\n",
    "\n",
    "      # store results in list\n",
    "      axis_list = []\n",
    "\n",
    "      # iterate through words by bucket size \n",
    "      for j in range(0, len(words), bucket_size):\n",
    "        # get bucket of words\n",
    "        bucket = words[j:j+bucket_size]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "              model=data_gen_model,\n",
    "              messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Here is the criteria for axis {i}:\\n{interpretations[i]}\\n\\n and here is the list of words:\\n{bucket}\\n\\n\"},\n",
    "              ]\n",
    "            )\n",
    "\n",
    "        values = response.choices[0].message.content\n",
    "\n",
    "        # convert string list representation to list\n",
    "        cleaned_string = re.sub(r'([\\[\\]\\n])', '', values)\n",
    "        new_values = cleaned_string.split(\", \")\n",
    "\n",
    "        # convert each value to float\n",
    "        final_values = [float(val) for val in new_values]\n",
    "\n",
    "        # add to axis list\n",
    "        axis_list.extend(final_values)\n",
    "\n",
    "      # crop to length of train_words\n",
    "      axis_list = axis_list[:len(train_words)]\n",
    "      # print(axis_list)\n",
    "      # print(len(axis_list))\n",
    "\n",
    "      # append to larger list\n",
    "      value_list.append(axis_list)\n",
    "      print(\"Axis\", i, \"done.\")\n",
    "      # break\n",
    "  return value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running round 1\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n",
      "running round 2\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get specified number of synthetic embeddings\n",
    "all_synth_embeddings = []\n",
    "\n",
    "for i in range(num_synth_embeddings):\n",
    "    print(f\"running round {i+1}\")\n",
    "    val_list = assign_values(train_words, interpretations)\n",
    "    all_synth_embeddings.append(val_list)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syn_stats(embeddings, words):\n",
    "    # for every group of k axes, calculate the mean and standard deviation for each value in the list\n",
    "    # store in dict\n",
    "    axis_dict = {}\n",
    "\n",
    "    # initialize the dict for each axis \n",
    "    for i in range(num_axes_to_sample):\n",
    "        axis_dict[f\"axis{i}\"] = {\"mean\": [], \"std\": []}\n",
    "\n",
    "        # each group of k axes represents the k interpretations of one axis\n",
    "\n",
    "        # group interpretations by word\n",
    "        list_of_vals = []\n",
    "        for w in range(len(words)):\n",
    "            # get all interpretations for one word\n",
    "            word_interps = []\n",
    "            for j in range(num_synth_embeddings):\n",
    "                word_interps.append(embeddings[j][i][w])\n",
    "\n",
    "            # add to list of vals\n",
    "            list_of_vals.append(word_interps)\n",
    "\n",
    "        # get k interpretations of one axis\n",
    "        axis_dict[f\"axis{i}\"][\"mean\"] = [statistics.mean(list_of_vals[j]) for j in range(len(words))]\n",
    "        axis_dict[f\"axis{i}\"][\"std\"] = [statistics.stdev(list_of_vals[j]) for j in range(len(words))]\n",
    "        \n",
    "    return axis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "axis_dict = get_syn_stats(all_synth_embeddings, train_words)\n",
    "\n",
    "print(len(axis_dict[\"axis0\"][\"std\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round each value in mean lists to 3 decimal places\n",
    "# and only save mean std values\n",
    "for axis in axis_dict:\n",
    "    axis_dict[axis][\"mean\"] = [round(val, 3) for val in axis_dict[axis][\"mean\"]]\n",
    "    axis_dict[axis][\"std\"] = statistics.mean(axis_dict[axis][\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3161276938412831\n"
     ]
    }
   ],
   "source": [
    "# print overall mean std\n",
    "print(statistics.mean([axis_dict[axis][\"std\"] for axis in axis_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: still some variability (all values fall between -1 and 1)\n",
    "- mean sd did decrease a bit (before: 0.41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparing old and generated embeddings for first 10 axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acoustic</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>album</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artist</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bass</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beat</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     0     1     2     3     4     5     6     7     8     9\n",
       "0  acoustic -0.10  0.30  0.35  0.00 -0.05  0.25 -0.70  0.45 -0.25  0.05\n",
       "1     album -0.05 -0.10  0.00  0.00  0.00 -0.25 -0.10  0.05  0.00 -0.20\n",
       "2    artist -0.20  0.05  0.15 -0.05  0.15  0.00  0.00  0.25 -0.10  0.10\n",
       "3      bass  0.05 -0.15 -0.15 -0.10 -0.20 -0.50 -0.30 -0.35  0.00 -0.55\n",
       "4      beat -0.10 -0.15 -0.25 -0.55 -0.15 -0.50 -0.15 -0.45  0.00 -0.60"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with columns 0-9\n",
    "df_llm = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# use mean values to populate dataframe; column numbers are the axis numbers\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    df_llm[axis] = axis_dict[axis_title][\"mean\"]\n",
    "\n",
    "# add words as first column\n",
    "df_llm.insert(0, \"word\", train_words)\n",
    "\n",
    "df_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'axis0': {'mean_diff': 0.3834353100133831, 'std_diff': 0.3068747087577499}, 'axis1': {'mean_diff': 0.3784155772705391, 'std_diff': 0.29937707658114926}, 'axis2': {'mean_diff': 0.36003027318816794, 'std_diff': 0.2982734560627241}, 'axis3': {'mean_diff': 0.48865473865473863, 'std_diff': 0.36044274952704647}, 'axis4': {'mean_diff': 0.3307272419872956, 'std_diff': 0.2567127672336318}, 'axis5': {'mean_diff': 0.37780531142389334, 'std_diff': 0.2883311285010431}, 'axis6': {'mean_diff': 0.4754444710196923, 'std_diff': 0.3459609463588012}, 'axis7': {'mean_diff': 0.4103156899702005, 'std_diff': 0.33156065647709504}, 'axis8': {'mean_diff': 0.48841259560213807, 'std_diff': 0.3706576337002312}, 'axis9': {'mean_diff': 0.4594126450509429, 'std_diff': 0.31977482812308317}}\n"
     ]
    }
   ],
   "source": [
    "# compare values in each column (axis) of df_llm to original dataframe df\n",
    "# store mean difference and std for each axis\n",
    "\n",
    "# initialize dict to store mean difference and std for each axis\n",
    "axis_diff_dict = {}\n",
    "\n",
    "# initialize dict for each axis\n",
    "for i in range(10):\n",
    "    axis_diff_dict[f\"axis{i}\"] = {\"mean_diff\": [], \"std_diff\": []}\n",
    "\n",
    "# for each axis, calculate mean difference and std\n",
    "for axis in range(len(axis_diff_dict)):\n",
    "    diffs = [abs(df_llm[axis][i] - train_df[axis][i]) for i in range(len(df_llm))]\n",
    "    mean_diff = statistics.mean(diffs)\n",
    "    std_diff = statistics.stdev(diffs)\n",
    "\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"mean_diff\"] = mean_diff\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"std_diff\"] = std_diff\n",
    "\n",
    "# print results\n",
    "print(axis_diff_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean diff: 0.41526538541809915 (uncertainty: 0.21)\n",
      "std of diffs: 0.3177965951322555 (uncertainty: 0.16)\n"
     ]
    }
   ],
   "source": [
    "# print overall mean difference\n",
    "overall_mean = statistics.mean([axis_diff_dict[axis][\"mean_diff\"] for axis in axis_diff_dict])\n",
    "mean_uncertainty = overall_mean / 2\n",
    "print(f\"mean diff: {overall_mean} (uncertainty: {mean_uncertainty:.2f})\")\n",
    "\n",
    "# print overall mean std\n",
    "overall_std = statistics.mean([axis_diff_dict[axis][\"std_diff\"] for axis in axis_diff_dict])\n",
    "std_uncertainty = overall_std / 2\n",
    "print(f\"std of diffs: {overall_std} (uncertainty: {std_uncertainty:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here mean + std of diffs decreased a bit (before: mean = 0.51, std = 0.36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cosine similarity function\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare cosine similarity of original and synthesized embeddings\n",
    "# ❓ question: should we be comparing by axis or word?\n",
    "\n",
    "# try columns first (by axis)\n",
    "# compute cosine similarity for each axis in df_llm and df\n",
    "# store in list\n",
    "axis_cos_sim_list = []\n",
    "\n",
    "# also try by word (row)\n",
    "# compute cosine similarity for each word in df_llm and df\n",
    "# store in list \n",
    "word_cos_sim_list = []\n",
    "\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    axis_cos_sim = cosine_similarity([df_llm[axis]], [train_df[axis]])\n",
    "    axis_cos_sim = axis_cos_sim[0][0]\n",
    "    axis_cos_sim_list.append(axis_cos_sim)\n",
    "\n",
    "for word in range(len(df_llm)):\n",
    "    # crop rows in df to 10 dimensions\n",
    "    word_cos_sim = cosine_similarity([df_llm.iloc[word][1:]], [train_df.iloc[word][1:11]])\n",
    "    word_cos_sim = word_cos_sim[0][0]\n",
    "    word_cos_sim_list.append(word_cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02975583067635356, 0.08594999254554996, 0.13766498382046113, -0.15096478516055253, 0.31379792499593867, 0.4543792572602663, 0.09704635401583447, 0.17915383212662028, -0.2022047594947824, -0.11502251659196361]\n",
      "[-0.004400368579769479, 0.2501986181068107, -0.4664805658857885, -0.04312731849018198, 0.26724210926520536, 0.29536922277703126, 0.3839853418020965, -0.2719131214541242, 0.21490925314836437, -0.27541500256841384, -0.09636583294926382, 0.4626836007276771, 0.23860263429396172, 0.15535655672268664, -0.07074930393380285, 0.352182558207205, -0.3948802911317597, 0.1511842843732408, -0.15568275912390778, 0.7326600986249735, 0.10242485630918342, 0.39877759227068343, 0.08484800421425578, -0.01829869863838149, -0.5143439173357303, 0.3524210759294392, 0.5991440102648053, -0.12643413279692509, 0.5522818662839164, 0.1204758239680385, 0.0594343015946515, -0.5838579953012957, 0.10465224254190522, 0.5746353935384705, -0.15656761472906325, 0.04064768465046662, 0.10593704348457518, -0.15193324088301643, -0.17648237935495314, -0.247664734191513, -0.023535962654984425, -0.6720800080421537, 0.5235198960342278, 0.07696261373150307, -0.11726897591204395, 0.15182672320092466, 0.30604954816138463, -0.24954747015124962, 0.24767367762532957, -0.49074152603063986, 0.3480563065299758, -0.08905722424399387, 0.40023062245450874, 0.2803542478552952, 0.6881060421922341, 0.5385180471706889, -0.12738125889115964, 0.5927077356704334, 0.11224392767021545, 0.21469764817452364, -0.47452626259997494, 0.4679528496351549, -0.05102384365130831, 0.16130905122857034, 0.11294952593130915, 0.0893565163457974, 0.010363605779883517, 0.31114022097164057, -0.019587038762654826, 0.1836512546301455, 0.31218181920568083, 0.057268248293753675, 0.17679129508657018, 0.46262081007355293, 0.046725960022076164, -0.2822138392071291, 0.48497085170184645, -0.28204628191904774, 0.4607821879134526, -0.1266091017233361, 0.3293920816032335, -0.2729688450679478, -0.40808909407396243, -0.0822276293223765, 0.20543498866603374, -0.08712537087795023, 0.016805928645905653, -0.23226178777842588, 0.20750231170055303, -0.0632879997856322, -0.0019265046870291845, 0.2883437207945364, -0.03107416005762724, 0.10373216602379867, 0.0052865905006396164, 0.2431304384204407, 0.1454764512037064, -0.44693735746087593, 0.26581327631320945, 0.14180143700193001, 0.32991464187779795, 0.41982797015881135, -0.19526232821165446, 0.11861280511200833, 0.8045420272892483, 0.12382091335721022, 0.5807187033398412, 0.2604013009791949, -0.4454158876741984, 0.22337543101037932, 0.3259202328328313]\n"
     ]
    }
   ],
   "source": [
    "# see results\n",
    "print(axis_cos_sim_list)\n",
    "print(word_cos_sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis cos sim avg: 0.07700444528410187\n",
      "word cos sim avg: 0.09488401609987736\n"
     ]
    }
   ],
   "source": [
    "# take average of each list\n",
    "axis_cos_sim_avg = statistics.mean(axis_cos_sim_list)\n",
    "word_cos_sim_avg = statistics.mean(word_cos_sim_list)\n",
    "\n",
    "# print results\n",
    "print(f\"axis cos sim avg: {axis_cos_sim_avg}\")\n",
    "print(f\"word cos sim avg: {word_cos_sim_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis cos sim max: 0.4543792572602663\n",
      "axis cos sim min: -0.2022047594947824\n",
      "axis cos sim std: 0.20850756994268055\n",
      "word cos sim max: 0.8045420272892483\n",
      "word cos sim min: -0.6720800080421537\n",
      "word cos sim std: 0.304059082329833\n"
     ]
    }
   ],
   "source": [
    "# also print max, min, and std\n",
    "print(f\"axis cos sim max: {max(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim min: {min(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim std: {statistics.stdev(axis_cos_sim_list)}\")\n",
    "\n",
    "print(f\"word cos sim max: {max(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim min: {min(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim std: {statistics.stdev(word_cos_sim_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: oof, still not very good 😅 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running round 1\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n",
      "running round 2\n",
      "Axis 0 done.\n",
      "Axis 1 done.\n",
      "Axis 2 done.\n",
      "Axis 3 done.\n",
      "Axis 4 done.\n",
      "Axis 5 done.\n",
      "Axis 6 done.\n",
      "Axis 7 done.\n",
      "Axis 8 done.\n",
      "Axis 9 done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# values assigned by chatgpt\n",
    "# generated vals for each axis\n",
    "\n",
    "# get specified number of synthetic embeddings\n",
    "test_synth_embeddings = []\n",
    "\n",
    "for i in range(num_synth_embeddings):\n",
    "    print(f\"running round {i+1}\")\n",
    "    val_list = assign_values(test_words, interpretations)\n",
    "    test_synth_embeddings.append(val_list)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "axis_dict = get_syn_stats(test_synth_embeddings, test_words)\n",
    "\n",
    "print(len(axis_dict[\"axis0\"][\"std\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3868884245634967\n"
     ]
    }
   ],
   "source": [
    "# round each value in mean lists to 3 decimal places\n",
    "# and only save mean std values\n",
    "for axis in axis_dict:\n",
    "    axis_dict[axis][\"mean\"] = [round(val, 3) for val in axis_dict[axis][\"mean\"]]\n",
    "    axis_dict[axis][\"std\"] = statistics.mean(axis_dict[axis][\"std\"])\n",
    "\n",
    "# print overall mean std\n",
    "print(statistics.mean([axis_dict[axis][\"std\"] for axis in axis_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slightly larger std than training data (0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>score</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sheet</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sitar</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solo</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soprano</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word     0     1     2     3     4     5     6     7     8     9\n",
       "0    score  0.10 -0.75  0.10  0.15 -0.25 -0.50 -0.40 -0.65 -0.45  0.75\n",
       "1    sheet  0.15 -0.70  0.15  0.20 -0.40 -0.35 -0.35 -0.55 -0.40  0.05\n",
       "2    sitar -0.85 -0.65 -0.45 -0.70  0.70 -0.65 -0.40 -0.45 -0.45  0.20\n",
       "3     solo -0.25 -0.60  0.25  0.10  0.10 -0.40 -0.55 -0.45 -0.20  0.60\n",
       "4  soprano -0.30 -0.55  0.30  0.05  0.10  0.35 -0.75 -0.50 -0.30 -0.30"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare original test embeddings to the generated embeddings\n",
    "# create dataframe with columns 0-9\n",
    "df_test_llm = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# use mean values to populate dataframe; column numbers are the axis numbers\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    df_test_llm[axis] = axis_dict[axis_title][\"mean\"]\n",
    "\n",
    "# add words as first column\n",
    "df_test_llm.insert(0, \"word\", test_words)\n",
    "\n",
    "df_test_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'axis0': {'mean_diff': 0.44193384740259745, 'std_diff': 0.3327981109254907}, 'axis1': {'mean_diff': 0.5870630216523527, 'std_diff': 0.4526205713541023}, 'axis2': {'mean_diff': 0.3681931997891407, 'std_diff': 0.30379226058366227}, 'axis3': {'mean_diff': 0.3804354636591479, 'std_diff': 0.2646289116551178}, 'axis4': {'mean_diff': 0.5968951902368987, 'std_diff': 0.46006520127885964}, 'axis5': {'mean_diff': 0.4280189319656057, 'std_diff': 0.36696967321111135}, 'axis6': {'mean_diff': 0.47674307545367717, 'std_diff': 0.3401465996655138}, 'axis7': {'mean_diff': 0.44510555234239446, 'std_diff': 0.36893521591314427}, 'axis8': {'mean_diff': 0.5182820086889854, 'std_diff': 0.3574508303125172}, 'axis9': {'mean_diff': 0.45993772105182223, 'std_diff': 0.3477532782865477}}\n"
     ]
    }
   ],
   "source": [
    "# compare values in each column (axis) of df_llm to original dataframe df\n",
    "# store mean difference and std for each axis\n",
    "\n",
    "# initialize dict to store mean difference and std for each axis\n",
    "axis_diff_dict = {}\n",
    "\n",
    "# initialize dict for each axis\n",
    "for i in range(10):\n",
    "    axis_diff_dict[f\"axis{i}\"] = {\"mean_diff\": [], \"std_diff\": []}\n",
    "\n",
    "# for each axis, calculate mean difference and std\n",
    "for axis in range(len(axis_diff_dict)):\n",
    "    diffs = [abs(df_test_llm[axis][i] - test_df[axis][i]) for i in range(len(df_test_llm))]\n",
    "    mean_diff = statistics.mean(diffs)\n",
    "    std_diff = statistics.stdev(diffs)\n",
    "\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"mean_diff\"] = mean_diff\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"std_diff\"] = std_diff\n",
    "\n",
    "# print results\n",
    "print(axis_diff_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean diff: 0.4702608012242622 (uncertainty: 0.24)\n",
      "std of diffs: 0.3595160653186067 (uncertainty: 0.18)\n"
     ]
    }
   ],
   "source": [
    "# print overall mean difference\n",
    "overall_mean = statistics.mean([axis_diff_dict[axis][\"mean_diff\"] for axis in axis_diff_dict])\n",
    "mean_uncertainty = overall_mean / 2\n",
    "print(f\"mean diff: {overall_mean} (uncertainty: {mean_uncertainty:.2f})\")\n",
    "\n",
    "# print overall mean std\n",
    "overall_std = statistics.mean([axis_diff_dict[axis][\"std_diff\"] for axis in axis_diff_dict])\n",
    "std_uncertainty = overall_std / 2\n",
    "print(f\"std of diffs: {overall_std} (uncertainty: {std_uncertainty:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat higher mean and std oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try cosine similarity too\n",
    "# compare cosine similarity of original and synthesized embeddings\n",
    "# ❓ question: should we be comparing by axis or word?\n",
    "\n",
    "# try columns first (by axis)\n",
    "# compute cosine similarity for each axis in df_llm and df\n",
    "# store in list\n",
    "axis_cos_sim_list = []\n",
    "\n",
    "# also try by word (row)\n",
    "# compute cosine similarity for each word in df_llm and df\n",
    "# store in list \n",
    "word_cos_sim_list = []\n",
    "\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    axis_cos_sim = cosine_similarity([df_test_llm[axis]], [test_df[axis]])\n",
    "    axis_cos_sim = axis_cos_sim[0][0]\n",
    "    axis_cos_sim_list.append(axis_cos_sim)\n",
    "\n",
    "for word in range(len(df_test_llm)):\n",
    "    # crop rows in df to 10 dimensions\n",
    "    word_cos_sim = cosine_similarity([df_test_llm.iloc[word][1:]], [test_df.iloc[word][1:11]])\n",
    "    word_cos_sim = word_cos_sim[0][0]\n",
    "    word_cos_sim_list.append(word_cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis cos sim avg: 0.12703245501373045\n",
      "word cos sim avg: 0.16730261575463778\n",
      "axis cos sim max: 0.48311087013454246\n",
      "axis cos sim min: -0.11996968397324612\n",
      "axis cos sim std: 0.21334053719117219\n",
      "word cos sim max: 0.7346214693984381\n",
      "word cos sim min: -0.41310226979474285\n",
      "word cos sim std: 0.30696717689788283\n"
     ]
    }
   ],
   "source": [
    "# take average of each list\n",
    "axis_cos_sim_avg = statistics.mean(axis_cos_sim_list)\n",
    "word_cos_sim_avg = statistics.mean(word_cos_sim_list)\n",
    "\n",
    "# print results\n",
    "print(f\"axis cos sim avg: {axis_cos_sim_avg}\")\n",
    "print(f\"word cos sim avg: {word_cos_sim_avg}\")\n",
    "\n",
    "# also print max, min, and std\n",
    "print(f\"axis cos sim max: {max(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim min: {min(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim std: {statistics.stdev(axis_cos_sim_list)}\")\n",
    "\n",
    "print(f\"word cos sim max: {max(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim min: {min(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim std: {statistics.stdev(word_cos_sim_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm... yeah the cosine similarity is not great"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946d8ab810ccf0fda35d8421fe75059925cdc2acab76b2b4a2b82ec2be7a9b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
