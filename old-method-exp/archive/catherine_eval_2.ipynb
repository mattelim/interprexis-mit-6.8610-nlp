{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of art related words (generated by chatgpt)\n",
    "words = ['abstract',\n",
    " 'aesthetic',\n",
    " 'acrylic',\n",
    " 'artistry',\n",
    " 'animation',\n",
    " 'brushwork',\n",
    " 'canvas',\n",
    " 'ceramics',\n",
    " 'collage',\n",
    " 'color',\n",
    " 'composition',\n",
    " 'creativity',\n",
    " 'culture',\n",
    " 'design',\n",
    " 'drawing',\n",
    " 'easel',\n",
    " 'expression',\n",
    " 'fresco',\n",
    " 'gallery',\n",
    " 'graffiti',\n",
    " 'hue',\n",
    " 'illustration',\n",
    " 'impressionism',\n",
    " 'ink',\n",
    " 'installation',\n",
    " 'landscape',\n",
    " 'masterpiece',\n",
    " 'medium',\n",
    " 'mural',\n",
    " 'museum',\n",
    " 'oil',\n",
    " 'palette',\n",
    " 'pastel',\n",
    " 'perspective',\n",
    " 'photography',\n",
    " 'pigment',\n",
    " 'portrait',\n",
    " 'realism',\n",
    " 'sculpture',\n",
    " 'sketch',\n",
    " 'still life',\n",
    " 'surrealism',\n",
    " 'texture',\n",
    " 'tone',\n",
    " 'watercolor',\n",
    " 'abstract expressionism',\n",
    " 'art deco',\n",
    " 'baroque',\n",
    " 'byzantine',\n",
    " 'carving',\n",
    " 'chiaroscuro',\n",
    " 'cubism',\n",
    " 'dadaism',\n",
    " 'etching',\n",
    " 'expressionism',\n",
    " 'fauvism',\n",
    " 'genre',\n",
    " 'gouache',\n",
    " 'harmony',\n",
    " 'impression',\n",
    " 'juxtaposition',\n",
    " 'kinetic',\n",
    " 'line',\n",
    " 'minimalism',\n",
    " 'modernism',\n",
    " 'neoclassicism',\n",
    " 'ornament',\n",
    " 'perspective',\n",
    " 'pop art',\n",
    " 'post-impressionism',\n",
    " 'realism',\n",
    " 'renaissance',\n",
    " 'rococo',\n",
    " 'romanticism',\n",
    " 'satire',\n",
    " 'shade',\n",
    " 'silhouette',\n",
    " 'symmetry',\n",
    " 'tapestry',\n",
    " 'tempera',\n",
    " \"trompe l'oeil\",\n",
    " 'urban art',\n",
    " 'vanguard',\n",
    " 'veneer',\n",
    " 'vignette',\n",
    " 'whimsical',\n",
    " 'xenography',\n",
    " 'yield',\n",
    " 'zenith',\n",
    " 'zest',\n",
    " 'fresco',\n",
    " 'impasto',\n",
    " 'montage',\n",
    " 'opus',\n",
    " 'palette knife',\n",
    " 'quattrocento',\n",
    " 'relief',\n",
    " 'stipple',\n",
    " 'underpainting',\n",
    " 'varnish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "# https://huggingface.co/distilbert-base-uncased\n",
    "# https://huggingface.co/docs/transformers/v4.35.0/en/model_doc/distilbert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding for each class\n",
    "# ❗️ note: I am averaging the embeddings for each word in the class\n",
    "# ❓ question: are we interested in the final contextual embedding for each class? currently, we're looking at the final hidden state.\n",
    "embeddings = []\n",
    "for i in range(len(words)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(words[i])).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]\n",
    "    # skip the first token, which is the [CLS] token, and skip the last token, which is the [SEP] token\n",
    "    # average the rest of the tokens\n",
    "    embeddings.append(last_hidden_states[0][1:-1].mean(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# round each val in embedding to 3 decimal places\n",
    "embeddings = [list(np.around(np.array(e),3)) for e in embeddings]\n",
    "\n",
    "# create string of all classes and their embeddings & save to text file\n",
    "# ❗️ note: only taking first 10 axes for now due to context window length\n",
    "with open(\"output.txt\", \"w\") as text_file:\n",
    "    for i in range(len(words)):\n",
    "        class_str = f\"{words[i]}: {embeddings[i][:10]}\\n\"\n",
    "        text_file.write(class_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aesthetic</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acrylic</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.777</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.548</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artistry</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      0      1      2      3      4      5      6      7      8  \\\n",
       "0   abstract  0.286  0.395 -0.382 -0.242  0.407  0.010 -0.199  0.060  0.203   \n",
       "1  aesthetic  0.249  0.566 -0.123 -0.117  0.271  0.083  0.036 -0.069  0.083   \n",
       "2    acrylic  0.217  0.234 -0.019  0.087  0.777 -0.107 -0.655  0.548 -0.061   \n",
       "3   artistry  0.147  0.263 -0.044 -0.078  0.660  0.147 -0.043 -0.021 -0.120   \n",
       "4  animation -0.006  0.449 -0.484  0.105  0.504  0.228  0.095  0.199 -0.532   \n",
       "\n",
       "   ...    758    759    760    761    762    763    764    765    766    767  \n",
       "0  ...  0.734 -0.119  0.476  0.058  0.239 -0.068  0.101  0.026  0.260 -0.127  \n",
       "1  ...  0.516  0.024  0.273 -0.004  0.114 -0.206  0.080  0.043  0.187  0.201  \n",
       "2  ...  0.254 -0.524  0.176  0.345  0.337 -0.254 -0.499 -0.021  0.162  0.142  \n",
       "3  ...  0.639 -0.331  0.187  0.041 -0.143 -0.029  0.110 -0.205  0.363 -0.308  \n",
       "4  ...  0.550 -0.206  0.477  0.005  0.140 -0.114  0.244 -0.032  0.513  0.498  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert embeddings to pandas dataframe\n",
    "df = pd.DataFrame(embeddings)\n",
    "df.insert(0, 'word', words)\n",
    "\n",
    "# sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>0.486683</td>\n",
       "      <td>-0.490754</td>\n",
       "      <td>-0.152763</td>\n",
       "      <td>-0.189744</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>-0.045004</td>\n",
       "      <td>-0.449067</td>\n",
       "      <td>0.400238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338893</td>\n",
       "      <td>0.285846</td>\n",
       "      <td>0.473819</td>\n",
       "      <td>0.261603</td>\n",
       "      <td>0.072235</td>\n",
       "      <td>0.110902</td>\n",
       "      <td>0.214545</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.164329</td>\n",
       "      <td>-0.366919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aesthetic</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>0.693705</td>\n",
       "      <td>-0.122333</td>\n",
       "      <td>0.118093</td>\n",
       "      <td>-0.364103</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.313501</td>\n",
       "      <td>-0.634146</td>\n",
       "      <td>0.257720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.550416</td>\n",
       "      <td>-0.044700</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>-0.209932</td>\n",
       "      <td>-0.148496</td>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.329205</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.183879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acrylic</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.291768</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.560130</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>-0.094256</td>\n",
       "      <td>-0.740656</td>\n",
       "      <td>0.251076</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388931</td>\n",
       "      <td>-0.463460</td>\n",
       "      <td>-0.292465</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.293454</td>\n",
       "      <td>-0.238722</td>\n",
       "      <td>-0.876364</td>\n",
       "      <td>0.197110</td>\n",
       "      <td>-0.032064</td>\n",
       "      <td>0.084803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artistry</td>\n",
       "      <td>0.055990</td>\n",
       "      <td>0.326877</td>\n",
       "      <td>-0.009957</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>-0.565280</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194845</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>-0.264368</td>\n",
       "      <td>0.225738</td>\n",
       "      <td>-0.790068</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.230909</td>\n",
       "      <td>-0.182663</td>\n",
       "      <td>0.370741</td>\n",
       "      <td>-0.670865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>-0.128236</td>\n",
       "      <td>0.552058</td>\n",
       "      <td>-0.635846</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>-0.065385</td>\n",
       "      <td>0.399116</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>-0.249641</td>\n",
       "      <td>-0.472684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.124884</td>\n",
       "      <td>0.476373</td>\n",
       "      <td>0.149789</td>\n",
       "      <td>-0.151242</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.474545</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.671343</td>\n",
       "      <td>0.682620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word         0         1         2         3         4         5  \\\n",
       "0   abstract  0.223359  0.486683 -0.490754 -0.152763 -0.189744  0.078056   \n",
       "1  aesthetic  0.178808  0.693705 -0.122333  0.118093 -0.364103  0.185567   \n",
       "2    acrylic  0.140277  0.291768  0.025605  0.560130  0.284615 -0.094256   \n",
       "3   artistry  0.055990  0.326877 -0.009957  0.202600  0.134615  0.279823   \n",
       "4  animation -0.128236  0.552058 -0.635846  0.599133 -0.065385  0.399116   \n",
       "\n",
       "          6         7         8  ...       758       759       760       761  \\\n",
       "0 -0.045004 -0.449067  0.400238  ...  0.338893  0.285846  0.473819  0.261603   \n",
       "1  0.313501 -0.634146  0.257720  ...  0.008340  0.550416 -0.044700  0.130802   \n",
       "2 -0.740656  0.251076  0.086698  ... -0.388931 -0.463460 -0.292465  0.867089   \n",
       "3  0.192982 -0.565280  0.016627  ...  0.194845 -0.106383 -0.264368  0.225738   \n",
       "4  0.403509 -0.249641 -0.472684  ...  0.059894  0.124884  0.476373  0.149789   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.072235  0.110902  0.214545  0.294118  0.164329 -0.366919  \n",
       "1 -0.209932 -0.148496  0.176364  0.329205  0.018036  0.183879  \n",
       "2  0.293454 -0.238722 -0.876364  0.197110 -0.032064  0.084803  \n",
       "3 -0.790068  0.184211  0.230909 -0.182663  0.370741 -0.670865  \n",
       "4 -0.151242  0.024436  0.474545  0.174407  0.671343  0.682620  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize each column to be between -1 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df.iloc[:,1:] = scaler.fit_transform(df.iloc[:,1:])\n",
    "\n",
    "# sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpreting axes with chatgpt\n",
    "\n",
    "Goal: try more detailed interpretations this time, instead of just 3 words (x vs. y)\n",
    "\n",
    "I uploaded the csv generated above and used the following prompt:\n",
    "```\n",
    "This CSV contains a list of words and their embeddings (each column after the word represents an axis in the embedding. \n",
    "\n",
    "By carefully comparing and considering the embedding values for each word, please interpret the likely linguistic feature that each embedding axis encodes. This interpretation must be consistent across all the words and correspond to their respective positive, zero, or negative embedding values.  You might consider analyzing the top 10 words with values close to -1, the top 10 words with values close to 0 (median), and the top 10 words with values close to 1 to generate your interpretation. \n",
    "\n",
    "Please phrase your interpretation like: \"negative sentiment vs positive sentiment\", \"small, blue objects vs large, red objects\", etc (some contrast with \"vs\" should be present). You should only have one interpretation per axis. Please use descriptive, contrastive phrases in your interpretations. Try to have unique interpretations for each axis too.\n",
    "\n",
    "For each axis, also include a confidence score of how confident you are in your interpretation of each axis. This does not need to be the same for each axis.\n",
    "\n",
    "For each axis, the output should look like this: {<interpretation>:<interpretation confidence score>} (e.g., {\"positive sentiment vs. negative sentiment\": 0.6}) Remember each <interpretation> should include \"vs\".\n",
    "\n",
    "Start with the first axis, then repeat the same process for the remaining 9 axes, one at a time. Remember to format your output for each axis as requested above as a python dictionary. Each axis should yield 1 dictionary with a interpretation + confidence score, for a total of 10 dictionaries. DO NOT OUTPUT ANYTHING EXCEPT THE FINAL 10 DICTIONARIES.\n",
    "\n",
    "Use the code below to help with your interpretations.\n",
    "\n",
    "# Function to analyze an axis and derive interpretation\n",
    "def analyze_axis(axis_index):\n",
    "    axis_name = df.columns[axis_index]\n",
    "\n",
    "    # Find top 10 words close to -1, 0, and 1 for this axis\n",
    "    top_neg = df.nsmallest(10, axis_name)[['word', axis_name]]\n",
    "    top_zero = df.iloc[(df[axis_name]-0).abs().argsort()[:10]][['word', axis_name]]\n",
    "    top_pos = df.nlargest(10, axis_name)[['word', axis_name]]\n",
    "\n",
    "    return top_neg, top_zero, top_pos\n",
    "```\n",
    "\n",
    "❗️ note: seems chatgpt's limit is 9 axes at a time (if using csv at least haha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretations of first 10 axes:  \n",
    "# each dict item is formatted as {<interpretation>: <confidence score>}\n",
    "axis_0 = {\"traditional art mediums vs modern urban art forms\": 0.7, \"traditional, classical art forms vs modern, contemporary art practices\": 0.6, \"traditional or classical art forms and techniques vs. modern or physical art mediums and spaces\": 0.8}\n",
    "axis_1 = {\"minimalist and abstract art forms vs detailed and realistic art forms\": 0.65, \"basic artistic elements, traditional styles vs specific art movements, modern mediums\": 0.7, \"linear, detailed, and classic artistic styles vs. bold, expressive, and modern art movements\": 0.75}\n",
    "axis_2 = {\"avant-garde and abstract art vs classical and traditional art\": 0.75, \"unconventional, abstract, ancient styles vs classical, well-defined, precise art elements\": 0.8, \"abstract, unconventional art forms vs. classical, technique-focused art styles\": 0.8}\n",
    "axis_3 = {\"whimsical and creative art vs structured and formal art\": 0.7, \"traditional, structured, historical art styles vs creative, innovative, modern art techniques\": 0.7, \"structured, formal artistic elements vs. imaginative, creative artistic expressions\": 0.7}\n",
    "axis_4 = {\"romantic and expressive art vs satirical and kinetic art\": 0.65, \"grounded, realistic art concepts vs abstract, expressive art styles\": 0.8, \"realistic, serious art forms vs. vibrant, expressive art styles\": 0.75}\n",
    "axis_5 = {\"abstract and cubist art vs detailed and tonal art\": 0.7, \"abstract, emotionally expressive art vs fundamental, technical aspects of art\": 0.75, \"abstract, modernist art movements vs. concrete, traditional art elements\": 0.7}\n",
    "axis_6 = {\"photographic and surreal art vs traditional painting mediums\": 0.65, \"traditional, fundamental art tools and techniques vs modern, innovative artistic methods\": 0.8, \"physical art mediums and tools vs. conceptual and abstract art elements\": 0.65}\n",
    "axis_7 = {\"classic and colorful art vs modern and monochromatic art\": 0.6, \"modern, innovative art forms vs classical, traditional art techniques and materials\": 0.75, \"modern art techniques and spaces vs. traditional artistic styles and techniques\": 0.7}\n",
    "axis_8 = {\"expressive and vibrant art vs structured and subdued art\": 0.65, \"established, mainstream art concepts vs artistic creation process, individual expression\": 0.7, \"contemporary, urban art styles vs. classic, time-honored art forms\": 0.75}\n",
    "axis_9 = {\"modern and institutional art vs classic and personal art\": 0.6, \"innovative, experimental art movements vs traditional, historical, institutional art concepts\": 0.7, \"modernist and abstract art movements vs. physical art spaces and classic art\": 0.65}\n",
    "\n",
    "# concatenate all axes into one list\n",
    "all_axes = [axis_0, axis_1, axis_2, axis_3, axis_4, axis_5, axis_6, axis_7, axis_8, axis_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'mean': 0.7, 'median': 0.7, 'stdev': 0.1}, 1: {'mean': 0.7, 'median': 0.7, 'stdev': 0.05}, 2: {'mean': 0.783, 'median': 0.8, 'stdev': 0.029}, 3: {'mean': 0.7, 'median': 0.7, 'stdev': 0.0}, 4: {'mean': 0.733, 'median': 0.75, 'stdev': 0.076}, 5: {'mean': 0.717, 'median': 0.7, 'stdev': 0.029}, 6: {'mean': 0.7, 'median': 0.65, 'stdev': 0.087}, 7: {'mean': 0.683, 'median': 0.7, 'stdev': 0.076}, 8: {'mean': 0.7, 'median': 0.7, 'stdev': 0.05}, 9: {'mean': 0.65, 'median': 0.65, 'stdev': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "# compute descriptive stats for each axis' confidence scores\n",
    "# store in dict where key is axis number and value is dict of descriptive stats\n",
    "import statistics\n",
    "\n",
    "axes_stats = {}\n",
    "for i in range(len(all_axes)):\n",
    "    axis = all_axes[i]\n",
    "    mean = statistics.mean(axis.values())\n",
    "    median = statistics.median(axis.values())\n",
    "    stdev = statistics.stdev(axis.values())\n",
    "\n",
    "    # round each val to 3 decimal places\n",
    "    mean = round(mean, 3)\n",
    "    median = round(median, 3)\n",
    "    stdev = round(stdev, 3)\n",
    "\n",
    "    # store in dict\n",
    "    axes_stats[i] = {\"mean\": mean, \"median\": median, \"stdev\": stdev}\n",
    "\n",
    "print(axes_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7066666666666667\n",
      "median: 0.7\n",
      "stdev: 0.03055518982121737\n"
     ]
    }
   ],
   "source": [
    "# overall mean, median, and stdev of all axes' confidence scores\n",
    "mean = statistics.mean([statistics.mean(axis.values()) for axis in all_axes])\n",
    "median = statistics.median([statistics.median(axis.values()) for axis in all_axes])\n",
    "stdev = statistics.stdev([statistics.stdev(axis.values()) for axis in all_axes])\n",
    "\n",
    "# print overall mean, median, and stdev\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"median: {median}\")\n",
    "print(f\"stdev: {stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- mean confidence increased\n",
    "- but slightly higher stdev (old version: 0.017), still pretty good though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyzing interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then asked chatgpt to assess how similar the 3 interpretations were for each axis and create a summary interpretation. Again, I asked it to do this 3 times to see how reliable the results were.\n",
    "\n",
    "```\n",
    "Below I will provide interpretations and confidence scores for axes in high dimensional word embeddings. Each axis has 3 potential interpretations + corresponding confidence scores. For each axis, please assign a qualitative similarity rating from 1-10 to how similar the interpretations are (1: not at all similar, 10: identical). Then summarize the three interpretations into a single interpretation per axis by considering the confidence scores, similarities between the interpretations, the most common interpretations, etc. This summary interpretation does not have to be one of the original three interpretations word for word, but it can be. Keep the contrasting phrases in the same relative order, as the first phrase in the interpretation represents what negative embedding values stand for in the axis, while the second  phrase after vs. represents what positive embedding values stand for.\n",
    "\n",
    "Your final answer for each axis should be a python dict formatted as follows: {<interpretation>: <similarity rating>}. As before, each interpretation should consist of two descriptive, contrastive phrases separated by \"vs\". And the similarity rating should just be the number from 1-10.\n",
    "\n",
    "Here are the axis interpretations:\n",
    "# insert here\n",
    "\n",
    "Remember to format your answer for each axis as a python dict as requested above. You should not need to write code do this, please just do this qualitatively. Also make sure there's no duplicate interpretations.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final axes dict\n",
    "# ❗️ note: it seems axes are not necessarily unique\n",
    "axis_0 = {\"traditional or classical art forms and techniques vs modern or contemporary art mediums and practices\": [9,8,8]}\n",
    "axis_1 = {\"basic, linear, and detailed artistic elements vs bold, expressive, and modern art styles and movements\": [8,7,7]}\n",
    "axis_2 = {\"abstract, unconventional, avant-garde art vs classical, traditional, technique-focused art styles\": [9,9,8]}\n",
    "axis_3 = {\"structured, traditional, historical art styles vs imaginative, creative, innovative art expressions\": [9,8,8]}\n",
    "axis_4 = {\"realistic, serious, romantic art forms vs vibrant, expressive, satirical art styles\": [7,7,7]}\n",
    "axis_5 = {\"abstract, modernist, emotionally expressive art vs concrete, traditional, technical art elements\": [8,8,7]}\n",
    "axis_6 = {\"traditional, physical art mediums and tools vs modern, innovative, conceptual art methods\": [7,7,7]}\n",
    "axis_7 = {\"modern, innovative, colorful art techniques vs traditional, classic, monochromatic art styles\": [8,7,7]}\n",
    "axis_8 = {\"contemporary, expressive, vibrant art vs structured, subdued, classic art forms\": [7,7,7]}\n",
    "axis_9 = {\"modern, innovative, institutional art movements vs classic, personal, traditional art concepts\": [7,7,7]}\n",
    "\n",
    "# concatenate all axes into one list\n",
    "all_axes = [axis_0, axis_1, axis_2, axis_3, axis_4, axis_5, axis_6, axis_7, axis_8, axis_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'mean': 8.333, 'median': 8, 'stdev': 0.577}, 1: {'mean': 7.333, 'median': 7, 'stdev': 0.577}, 2: {'mean': 8.667, 'median': 9, 'stdev': 0.577}, 3: {'mean': 8.333, 'median': 8, 'stdev': 0.577}, 4: {'mean': 7, 'median': 7, 'stdev': 0.0}, 5: {'mean': 7.667, 'median': 8, 'stdev': 0.577}, 6: {'mean': 7, 'median': 7, 'stdev': 0.0}, 7: {'mean': 7.333, 'median': 7, 'stdev': 0.577}, 8: {'mean': 7, 'median': 7, 'stdev': 0.0}, 9: {'mean': 7, 'median': 7, 'stdev': 0.0}}\n",
      "mean: 7.566666666666666\n",
      "median: 7.0\n",
      "stdev: 0.2981423969999719\n"
     ]
    }
   ],
   "source": [
    "# compute descriptive stats for each axis' confidence scores\n",
    "# store in dict where key is axis number and value is dict of descriptive stats\n",
    "axes_stats = {}\n",
    "for i in range(len(all_axes)):\n",
    "    axis = all_axes[i]\n",
    "    # value is a list of confidence scores\n",
    "    mean = statistics.mean(list(axis.values())[0])\n",
    "    median = statistics.median(list(axis.values())[0])\n",
    "    stdev = statistics.stdev(list(axis.values())[0])\n",
    "\n",
    "    # round each val to 3 decimal places\n",
    "    mean = round(mean, 3)\n",
    "    median = round(median, 3)\n",
    "    stdev = round(stdev, 3)\n",
    "\n",
    "    # store in dict\n",
    "    axes_stats[i] = {\"mean\": mean, \"median\": median, \"stdev\": stdev}\n",
    "\n",
    "print(axes_stats)\n",
    "\n",
    "# overall mean, median, and stdev of all axes' confidence scores\n",
    "mean = statistics.mean([statistics.mean(list(axis.values())[0]) for axis in all_axes])\n",
    "median = statistics.median([statistics.median(list(axis.values())[0]) for axis in all_axes])\n",
    "stdev = statistics.stdev([statistics.stdev(list(axis.values())[0]) for axis in all_axes])\n",
    "\n",
    "# print overall mean, median, and stdev\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"median: {median}\")\n",
    "print(f\"stdev: {stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- slightly higher mean similarity rating (7.6 vs. 7.0 from before), seems pretty good\n",
    "- stdev is also lower than before (0.3 vs 0.58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traditional or classical art forms and techniques vs modern or contemporary art mediums and practices', 'basic, linear, and detailed artistic elements vs bold, expressive, and modern art styles and movements', 'abstract, unconventional, avant-garde art vs classical, traditional, technique-focused art styles', 'structured, traditional, historical art styles vs imaginative, creative, innovative art expressions', 'realistic, serious, romantic art forms vs vibrant, expressive, satirical art styles', 'abstract, modernist, emotionally expressive art vs concrete, traditional, technical art elements', 'traditional, physical art mediums and tools vs modern, innovative, conceptual art methods', 'modern, innovative, colorful art techniques vs traditional, classic, monochromatic art styles', 'contemporary, expressive, vibrant art vs structured, subdued, classic art forms', 'modern, innovative, institutional art movements vs classic, personal, traditional art concepts']\n"
     ]
    }
   ],
   "source": [
    "# extract interpretations from axes\n",
    "interpretations = []\n",
    "for axis in all_axes:\n",
    "    interpretations.append(list(axis.keys())[0])\n",
    "\n",
    "# sanity check\n",
    "print(interpretations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create template csv file\n",
    "# each row is a word from list 'words', each column will store the interpretation of that word for each axis\n",
    "\n",
    "# create header row\n",
    "# first column is 'word', rest of columns are interpretations; have 3 columns per interpretation\n",
    "header = ['word'] + interpretations\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(columns=header)\n",
    "df['word'] = words\n",
    "\n",
    "# replace NaN with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# sanity check\n",
    "df.head()\n",
    "\n",
    "# save dataframe to csv\n",
    "df.to_csv('llm_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I asked chatgpt to assign scores for each axis, and repeated this 3 times.\n",
    "\n",
    "```\n",
    "For each criteria in this list: {list}\n",
    "\n",
    "assign a score to each word in this list:\n",
    "# insert here\n",
    "\n",
    "(should be a float) between -1 and 1 based on the current criteria. Note that each criteria consists of two contrastive phrases, x and y, formatted like: {x vs. y}. Scores closer to -1 indicate the word is more correlated to {x}, while scores closer to 1 indicate the word is more correlated to {y}. Scores closer to 0 indicate that the word is more neutral with respect to the criteria, falls in between the extremes, or isn't really related to either {x} or {y}. You don't need to justify your scores, just provide the numbers.\n",
    "\n",
    "For each criteria, your output should be a python list of scores (length = 100, because there are 100 words). Print each criteria on a line followed by its corresponding list like this on another line: \n",
    "\n",
    "{criteria}:\n",
    "[score 1, score 2, ...]. \n",
    "\n",
    "You should not need code to perform this task, just assign scores qualitatively. Don't print anything else except for the list of scores, and don't format anything as code.\n",
    "\n",
    "Please start with the first criteria: {criteria}. Only do one criteria at a time.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# generated vals for each axis\n",
    "# ❗️ note: these may not be the right length -- need to check/fix later\n",
    "axis0_1 = [-1, -0.5, -0.8, -0.2, 1, -0.7, -0.8, -0.7, 0.5, 0, 0, 0, 0, 0, -0.5, -0.8, 0, -0.8, -0.5, 1, 0, 0, 0, -0.8, 1, -0.6, -0.5, 0, 0.5, -0.5, -0.8, -0.8, -0.7, 0, 1, 0, 0, -0.9, 0.5, -0.5, -0.8, 0, 0, 0, -0.8, 1, 0, 0.5, -0.8, 0.5, 0, 0.5, -1, 0.5, -1, 0.5, -0.7, 1, 0.8, 0, 0, 0, 0.5, 1, -0.5, 0.5, 0, 0, 1, 0, 0, 0.5, 1, -0.5, -0.8, 0, -0.5, 0.5, -0.8, 1, -0.8, 0.5, 1, -0.5, -1, 0.5, 0, -0.8, 0.5, 0, 0, 0, -0.8, -0.8, 0.5, -0.7, -0.8, -0.8, 0, 0, -0.8, 0.5, -0.8, -0.8, 0.5, -0.8, 0, 1, 0.5, 0, 0, 0.5]\n",
    "axis0_2 = [-1.0, -0.5, -0.8, -0.5, 1.0, -0.8, -0.8, -0.7, 0.6, 0.0, -0.2, 0.3, 0.0, 0.0, -0.8, -0.8, 0.5, -0.9, -0.3, 1.0, 0.0, 0.3, -1.0, -0.7, 1.0, -0.8, -0.7, -0.3, 1.0, -0.7, -0.9, -0.8, -0.7, -0.6, 1.0, -0.5, -0.6, -0.9, -0.6, -0.8, -0.8, -0.9, 0.8, 0.0, -0.6, 1.0, -0.8, -0.8, -0.8, -0.8, -0.7, -0.8, 1.0, -0.8, 0.8, -0.9, -0.8, -0.3, -0.7, -0.2, 0.0, -0.7, 0.0, -0.8, -0.8, 0.7, -0.8, 0.0, 0.7, 0.0, 0.0, 0.0, -0.8, -0.7, -0.8, 1.0, 0.5, -0.8, -0.8, -0.8, -0.9, -0.8, -0.8, -0.9, -0.7, -0.8, 1.0, -0.8, -0.7, 0.0, -0.7, 0.7, -0.8, -0.7, -0.8, -0.9, -0.8, -0.7, -0.9, -0.7, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8]\n",
    "axis0_3 = [-0.8, -0.3, -0.6, -0.1, 1.0, -0.7, -0.6, -0.5, 0.4, 0.1, -0.2, 0.3, -0.1, 0.2, -0.5, -0.6, 0.5, -0.7, -0.2, 0.8, -0.1, 0.2, -0.8, -0.4, 0.9, -0.3, -0.5, -0.1, 0.7, -0.4, -0.6, -0.5, -0.4, -0.3, 0.6, -0.2, -0.5, -0.8, -0.4, -0.5, -0.3, 0.0, 0.1, -0.2, -0.6, -0.9, -0.8, -0.8, -0.7, -0.8, -0.9, -0.7, -0.8, -0.8, -0.6, -0.8, -0.7, -0.6, 0.1, -0.2, -0.3, -0.5, 0.0, -0.5, -0.7, -0.4, -0.6, -0.2, 0.0, -0.8, -0.5, -0.5, -0.7, -0.6, -0.3, 0.7, -0.4, -0.7, -0.8, -0.5, -0.5, 0.3, 0.2, 0.5, -0.6, -0.5, -0.4, 0.8, -0.5, 0.3, -0.7, -0.8, -0.7, -0.6, -0.7, -0.5, -0.4, -0.7, -0.3, -0.4, -0.6, -0.7, -0.8, -0.6, -0.7, -0.7, -0.7, -0.6, -0.7, -0.7, -0.5, -0.6, -0.7, -0.5, -0.7, -0.7, -0.6]\n",
    "axis1_1 = [-0.5, -0.2, -0.5, -0.2, 0.5, -0.5, -0.5, -0.2, 0.2, 0.5, -0.5, 0.5, 0.2, 0, -0.5, -0.5, 0.5, -0.8, -0.2, 1, 0.3, -0.2, -0.8, -0.5, 1, -0.2, -0.5, -0.3, 0.8, -0.2, -0.5, -0.5, -0.2, -0.5, 0.5, 0.3, -0.2, -0.8, 0.5, -0.5, -0.5, 0, 0.5, 0.3, -0.5, 1, -0.5, 0.5, -0.8, 0.5, 0.2, 0.5, -1, 0.8, -1, 0.5, -0.5, 1, 0.8, 0, 0, -0.2, 0.5, 1, -0.5, 0.8, 0, 0, 1, 0.2, 0, 0.5, 1, -0.5, -0.5, 0, -0.5, 0.8, -0.5, 1, -0.5, 0.8, 1, -0.2, -1, 0.5, 0, -0.5, 0.8, 0, 0, 0, -0.5, -0.5, 0.8, -0.2, -0.5, -0.5, 0, 0, -0.5, 0.5, -0.5, -0.5, 0.8, -0.5, 0, 1, 0.5, 0, 0, 0.8]\n",
    "axis1_2 = [-0.5, -0.2, -0.3, -0.2, 0.7, -0.6, -0.5, -0.4, 0.4, 0.3, -0.1, 0.5, 0.0, 0.1, -0.6, -0.5, 0.8, -0.4, -0.1, 0.9, 0.2, 0.1, -0.6, -0.5, 0.8, -0.5, -0.3, 0.0, 0.7, -0.2, -0.6, -0.5, -0.4, -0.3, 0.7, -0.2, -0.3, -0.5, -0.4, -0.6, -0.5, -0.6, 0.8, 0.1, -0.5, 0.8, -0.6, -0.6, -0.6, -0.6, -0.5, -0.6, 0.8, -0.6, 0.8, -0.7, -0.6, -0.1, -0.4, 0.0, 0.1, -0.4, 0.1, -0.6, -0.6, 0.6, -0.6, 0.1, 0.7, 0.2, 0.1, 0.1, -0.6, -0.5, -0.6, 0.9, 0.6, -0.6, -0.6, -0.6, -0.7, -0.6, -0.6, -0.7, -0.5, -0.6, 0.9, -0.6, -0.5, 0.1, -0.5, 0.7, -0.6, -0.5, -0.6, -0.7, -0.6, -0.5, -0.7, -0.5, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6]\n",
    "axis1_3 = [-0.4, -0.1, -0.3, -0.2, 0.5, 0.1, -0.3, -0.2, 0.3, 0.2, -0.1, 0.4, 0.0, 0.1, -0.2, -0.3, 0.6, -0.4, 0.1, 0.7, 0.0, 0.2, -0.5, -0.3, 0.8, -0.1, -0.3, 0.0, 0.6, 0.1, -0.2, -0.3, -0.2, -0.1, 0.4, -0.1, -0.2, -0.5, -0.3, -0.2, -0.1, 0.3, 0.2, -0.1, -0.2, -0.7, -0.6, -0.5, -0.6, -0.6, -0.7, -0.6, -0.6, -0.5, -0.4, -0.6, -0.5, -0.4, 0.2, -0.1, 0.0, -0.3, 0.1, -0.3, -0.5, -0.2, -0.4, 0.1, 0.2, -0.6, -0.3, -0.3, -0.5, -0.4, -0.1, 0.7, -0.2, -0.5, -0.6, -0.3, -0.3, 0.5, 0.4, 0.6, -0.4, -0.3, -0.2, 0.8, -0.3, 0.5, -0.5, -0.6, -0.5, -0.4, -0.5, -0.3, -0.2, -0.5, -0.1, -0.2, -0.4, -0.5, -0.6, -0.4, -0.5, -0.5, -0.5, -0.4, -0.5, -0.5, -0.3, -0.4, -0.5, -0.3, -0.5, -0.5, -0.4]\n",
    "axis2_1 = [1, 0, -0.5, 0.2, 0.8, -0.7, -0.8, -0.3, 1, 0.5, -0.2, 0.8, 0.5, 0.3, -0.7, -0.8, 0.8, -1, -0.2, 1, 0.5, 0.3, -1, -0.5, 1, -0.5, -0.8, 0, 0.7, -0.3, -0.8, -0.8, -0.5, -0.2, 0.7, 0.5, 0.2, -1, 0.6, -0.7, -0.8, 1, 0.5, 0.5, -0.8, 1, 0.3, 0.8, -1, 0.8, 0.5, 0.8, -1, 1, -1, 0.8, -0.7, 1, 1, 0.3, 0, 0.2, 0.8, 1, -0.7, 1, 0, 0, 1, 0.5, 0, 0.8, 1, -0.7, -0.8, 0.3, -0.7, 1, -0.8, 1, -0.8, 1, 1, -0.7, -1, 1, 0, -0.7, 1, 0, 0, 0, -0.8, -0.8, 1, -0.5, -0.8, -0.8, 0.3, 0, -0.8, 1, -0.8, -0.8, 1, -0.8, 0, 1, 1, 0, 0, 1]\n",
    "axis2_2 = [0.9, 0.3, -0.6, 0.2, 0.7, -0.5, -0.7, -0.2, 0.8, 0.4, 0.1, 0.6, 0.0, 0.3, -0.7, -0.6, 0.7, -0.8, -0.2, 0.9, 0.3, 0.5, -0.9, -0.6, 0.9, -0.7, -0.4, 0.0, 0.8, -0.3, -0.8, -0.6, -0.5, -0.4, 0.7, -0.3, -0.4, -0.9, -0.5, -0.7, -0.7, -0.9, 0.9, 0.2, -0.6, 0.9, -0.7, -0.7, -0.7, -0.7, -0.6, -0.7, 0.9, -0.7, 0.8, -0.8, -0.7, 0.0, -0.5, 0.1, 0.3, -0.5, 0.2, -0.7, -0.7, 0.8, -0.7, 0.2, 0.8, 0.3, 0.2, 0.2, -0.7, -0.6, -0.7, 0.9, 0.7, -0.7, -0.7, -0.7, -0.8, -0.7, -0.7, -0.8, -0.6, -0.7, 0.9, -0.7, -0.6, 0.2, -0.6, 0.8, -0.7, -0.6, -0.7, -0.8, -0.7, -0.6, -0.8, -0.6, -0.7, -0.7, -0.7, -0.7, -0.7, -0.7, -0.7]\n",
    "axis2_3 = [0.7, 0.2, 0.1, 0.3, 0.9, 0.0, -0.2, 0.1, 0.8, 0.4, 0.3, 0.6, 0.5, 0.4, 0.1, -0.1, 0.7, -0.3, 0.5, 0.8, 0.3, 0.6, -0.7, 0.1, 0.9, 0.2, -0.1, 0.0, 0.7, 0.4, -0.2, -0.1, 0.0, 0.2, 0.8, 0.1, 0.1, -0.7, 0.0, 0.1, 0.2, 0.9, 0.3, 0.2, 0.0, 0.8, 0.7, 0.6, 0.7, 0.7, 0.8, 0.7, 0.7, 0.6, 0.5, 0.7, 0.6, 0.5, 0.9, 0.4, 0.3, 0.1, 0.6, 0.1, 0.6, 0.3, 0.2, 0.6, 0.4, 0.7, 0.4, 0.4, 0.6, 0.5, 0.2, 1.0, 0.3, 0.6, 0.7, 0.0, 0.0, 0.8, 0.7, 0.9, 0.1, 0.0, 0.1, 0.9, 0.0, 0.8, 0.6, 0.7, 0.6, 0.5, 0.6, 0.0, 0.1, 0.6, 0.2, 0.1, 0.0, 0.6, 0.5, 0.6, 0.6, 0.5, 0.5, 0.5, 0.3, 0.0, 0.5, 0.2, 0.6, 0.6, 0.5]\n",
    "axis3_1 = [-0.7, 0.2, -0.8, 0.3, 0.7, -0.6, -0.8, -0.5, 0.5, 0.3, -0.5, 0.8, -0.2, 0.1, -0.7, -0.8, 0.6, -0.9, -0.4, 0.8, 0.2, -0.2, -0.8, -0.8, 0.9, -0.5, -0.6, -0.3, 0.7, -0.5, -0.8, -0.7, -0.5, -0.5, 0.7, 0.2, -0.1, -0.9, 0.6, -0.7, -0.8, 0.4, 0.3, 0.2, -0.8, 0.8, -0.7, 0.5, -0.9, 0.6, 0.2, 0.6, -1, 0.8, -1, 0.7, -0.6, 0.9, 0.8, 0.2, -0.1, -0.2, 0.8, 0.9, -0.7, 0.8, 0, 0, 0.9, 0.3, 0, 0.7, 0.9, -0.7, -0.8, 0.2, -0.7, 0.7, -0.8, 0.9, -0.8, 0.8, 0.9, -0.6, -1, 0.7, 0, -0.7, 0.7, 0, 0, 0, -0.8, -0.8, 0.7, -0.5, -0.8, -0.8, 0.2, 0, -0.8, 0.8, -0.8, -0.8, 0.8, -0.8, 0, 0.9, 0.7, 0, 0, 0.8]\n",
    "axis3_2 = [-0.6, -0.2, -0.5, 0.0, 0.8, -0.7, -0.6, -0.3, 0.5, 0.2, -0.1, 0.8, 0.0, 0.3, -0.6, -0.5, 0.7, -0.7, -0.3, 0.9, 0.1, 0.4, -0.8, -0.5, 0.9, -0.6, -0.4, 0.0, 0.8, -0.4, -0.7, -0.5, -0.4, -0.3, 0.8, -0.2, -0.3, -0.8, -0.4, -0.6, -0.5, -0.8, 0.9, 0.0, -0.5, 0.9, -0.6, -0.6, -0.6, -0.6, -0.5, -0.6, 0.9, -0.6, 0.8, -0.8, -0.6, 0.1, -0.4, 0.0, 0.2, -0.4, 0.3, -0.6, -0.6, 0.8, -0.6, 0.1, 0.8, 0.2, 0.2, 0.2, -0.6, -0.5, -0.6, 0.9, 0.7, -0.6, -0.6, -0.6, -0.7, -0.6, -0.6, -0.7, -0.5, -0.6, 0.9, -0.6, -0.5, 0.3, -0.5, 0.8, -0.6, -0.5, -0.6, -0.7, -0.6, -0.5, -0.7, -0.5, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6]\n",
    "axis3_3 = [-0.5, -0.1, -0.4, -0.2, 0.8, -0.3, -0.5, -0.4, 0.6, 0.2, -0.2, 0.7, -0.1, 0.3, -0.4, -0.5, 0.5, -0.6, -0.1, 0.9, 0.0, 0.4, -0.7, -0.3, 0.9, -0.2, -0.4, 0.0, 0.8, -0.2, -0.4, -0.4, -0.3, -0.2, 0.7, -0.1, -0.3, -0.7, -0.4, -0.4, -0.2, 0.6, 0.3, 0.0, -0.3, -0.8, -0.7, -0.6, -0.7, -0.7, -0.8, -0.7, -0.7, -0.6, -0.5, -0.7, -0.6, -0.5, 0.8, 0.3, 0.2, -0.2, 0.5, -0.2, -0.6, -0.3, -0.4, 0.4, 0.3, -0.7, -0.3, -0.3, -0.6, -0.5, -0.1, 0.9, -0.3, -0.6, -0.7, -0.4, -0.3, 0.7, 0.6, 0.8, -0.4, -0.3, -0.2, 1.0, -0.3, 0.7, -0.6, -0.7, -0.6, -0.5, -0.6, -0.3, -0.2, -0.6, -0.1, -0.3, -0.4, -0.5, -0.6, -0.4, -0.5, -0.5, -0.5, -0.4, -0.5, -0.5, -0.3, -0.4, -0.5, -0.3, -0.5, -0.5, -0.4]\n",
    "axis4_1 = [-0.4, -0.2, -0.5, -0.3, 0.6, -0.7, -0.5, -0.4, 0.2, 0.7, -0.6, 0.5, -0.2, 0.1, -0.6, -0.5, 0.7, -0.8, -0.3, 0.9, 0.6, -0.3, -0.8, -0.5, 0.8, -0.4, -0.6, -0.2, 0.6, -0.3, -0.5, -0.5, -0.4, -0.6, 0.6, 0.6, -0.2, -0.9, 0.7, -0.5, -0.5, 0.3, 0.6, 0.6, -0.5, 0.9, -0.3, 0.6, -0.8, 0.7, 0.4, 0.7, -0.9, 0.9, -0.9, 0.7, -0.6, 0.9, 0.9, 0.4, 0, -0.2, 0.7, 0.8, -0.6, 0.9, 0, 0, 0.8, 0.5, 0, 0.6, 0.8, -0.6, -0.5, 0.3, -0.6, 0.7, -0.5, 0.9, -0.5, 0.8, 0.9, -0.4, -0.9, 0.7, 0, -0.5, 0.7, 0, 0, 0, -0.5, -0.5, 0.7, -0.4, -0.5, -0.5, 0.3, 0, -0.5, 0.9, -0.5, -0.5, 0.8, -0.5, 0, 0.9, 0.7, 0, 0, 0.8]\n",
    "axis4_2 = [-0.3, -0.1, -0.4, -0.2, 0.6, -0.5, -0.4, -0.3, 0.4, 0.5, -0.2, 0.6, 0.0, 0.2, -0.5, -0.4, 0.7, -0.6, -0.2, 0.8, 0.3, 0.3, -0.7, -0.4, 0.7, -0.4, -0.3, 0.0, 0.6, -0.3, -0.5, -0.4, -0.3, -0.2, 0.6, -0.1, -0.2, -0.7, -0.3, -0.5, -0.4, -0.7, 0.7, 0.1, -0.4, 0.7, -0.5, -0.5, -0.5, -0.5, -0.4, -0.5, 0.7, -0.5, 0.7, -0.6, -0.5, 0.1, -0.3, 0.0, 0.2, -0.3, 0.3, -0.5, -0.5, 0.6, -0.5, 0.1, 0.7, 0.2, 0.2, 0.2, -0.5, -0.4, -0.5, 0.8, 0.6, -0.5, -0.5, -0.5, -0.6, -0.5, -0.5, -0.6, -0.4, -0.5, 0.8, -0.5, -0.4, 0.2, -0.4, 0.7, -0.5, -0.4, -0.5, -0.6, -0.5, -0.4, -0.6, -0.4, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5]\n",
    "axis4_3 = [-0.3, 0.1, -0.2, -0.1, 0.6, -0.2, -0.3, -0.2, 0.4, 0.3, -0.1, 0.5, 0.2, 0.3, -0.3, -0.3, 0.6, -0.4, 0.0, 0.8, 0.1, 0.3, -0.6, -0.2, 0.7, -0.1, -0.3, 0.1, 0.7, 0.2, -0.2, -0.2, -0.1, 0.0, 0.6, -0.1, -0.2, -0.6, -0.2, -0.2, -0.1, 0.5, 0.4, 0.1, -0.2, -0.7, -0.6, -0.5, -0.6, -0.6, -0.7, -0.6, -0.6, -0.5, -0.4, -0.6, -0.5, -0.4, 0.8, 0.4, 0.3, -0.2, 0.6, -0.2, -0.5, -0.2, -0.3, 0.5, 0.4, -0.6, -0.2, -0.2, -0.5, -0.4, 0.0, 0.8, -0.2, -0.5, -0.6, -0.2, -0.2, 0.6, 0.5, 0.7, -0.3, -0.2, -0.1, 0.9, -0.2, 0.6, -0.5, -0.6, -0.5, -0.4, -0.5, -0.2, -0.1, -0.5, 0.0, -0.2, -0.3, -0.4, -0.5, -0.3, -0.4, -0.4, -0.4, -0.3, -0.4, -0.4, -0.2, -0.3, -0.4, -0.2, -0.4, -0.4, -0.3]\n",
    "axis5_1 = [1, 0.5, -0.5, 0.3, 0.8, -0.6, -0.7, -0.2, 0.9, 0.6, -0.3, 0.9, 0.4, 0.2, -0.6, -0.7, 0.9, -0.9, -0.1, 1, 0.6, 0.1, -0.9, -0.5, 1, -0.3, -0.6, 0, 0.8, -0.2, -0.7, -0.6, -0.4, -0.3, 0.8, 0.6, 0, -0.9, 0.7, -0.6, -0.7, 0.5, 0.6, 0.6, -0.7, 1, 0, 0.8, -0.9, 0.8, 0.6, 0.9, -1, 1, -1, 0.9, -0.6, 1, 1, 0.4, -0.2, -0.1, 0.9, 1, -0.6, 1, 0, 0, 1, 0.6, 0, 0.9, 1, -0.6, -0.7, 0.2, -0.6, 0.9, -0.7, 1, -0.7, 1, 1, -0.5, -1, 0.9, 0, -0.6, 0.9, 0, 0, 0, -0.7, -0.7, 1, -0.4, -0.7, -0.7, 0.4, 0, -0.7, 1, -0.7, -0.7, 1, -0.7, 0, 1, 1, 0, 0, 1]\n",
    "axis5_2 = [0.8, 0.2, -0.5, 0.1, 0.6, -0.4, -0.6, -0.1, 0.7, 0.3, 0.0, 0.5, 0.0, 0.2, -0.6, -0.5, 0.6, -0.7, -0.1, 0.8, 0.2, 0.4, -0.8, -0.5, 0.8, -0.6, -0.3, -0.1, 0.7, -0.2, -0.7, -0.5, -0.4, -0.3, 0.6, -0.2, -0.3, -0.8, -0.4, -0.6, -0.5, -0.8, 0.8, 0.1, -0.5, 0.8, -0.6, -0.6, -0.6, -0.6, -0.5, -0.6, 0.8, -0.6, 0.7, -0.7, -0.6, 0.0, -0.4, 0.0, 0.1, -0.4, 0.1, -0.6, -0.6, 0.7, -0.6, 0.1, 0.7, 0.2, 0.1, 0.1, -0.6, -0.4, -0.6, 0.8, 0.6, -0.6, -0.6, -0.6, -0.7, -0.6, -0.6, -0.7, -0.4, -0.6, 0.8, -0.6, -0.4, 0.1, -0.4, 0.7, -0.6, -0.4, -0.6, -0.7, -0.6, -0.4, -0.7, -0.4, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6]\n",
    "axis5_3 = [0.8, 0.3, 0.2, 0.4, 0.9, 0.1, -0.2, 0.1, 0.7, 0.5, 0.4, 0.7, 0.6, 0.5, 0.2, -0.1, 0.8, -0.3, 0.6, 0.8, 0.4, 0.7, -0.8, 0.2, 0.9, 0.3, -0.2, 0.1, 0.8, 0.5, -0.1, -0.1, 0.0, 0.3, 0.9, 0.2, 0.2, -0.8, 0.1, 0.2, 0.3, 1.0, 0.4, 0.3, 0.1, 0.9, 0.8, 0.7, 0.8, 0.8, 0.9, 0.8, 0.8, 0.7, 0.6, 0.8, 0.7, 0.6, 1.0, 0.5, 0.4, 0.2, 0.7, 0.2, 0.7, 0.4, 0.3, 0.7, 0.5, 0.8, 0.5, 0.5, 0.7, 0.6, 0.3, 1.0, 0.4, 0.7, 0.8, 0.1, 0.1, 0.9, 0.8, 1.0, 0.2, 0.1, 0.2, 1.0, 0.1, 0.9, 0.7, 0.8, 0.7, 0.6, 0.7, 0.1, 0.2, 0.7, 0.3, 0.2, 0.1, 0.7, 0.6, 0.7, 0.7, 0.6, 0.6, 0.6, 0.4, 0.1, 0.6, 0.3, 0.7, 0.7, 0.6]\n",
    "axis6_1 = [-0.8, -0.2, -0.9, -0.3, 1, -0.8, -0.9, -0.7, 0.6, 0.1, -0.5, 0.7, 0, 0.2, -0.8, -0.9, 0.5, -1, -0.4, 1, 0.2, -0.4, -1, -0.9, 1, -0.6, -0.8, -0.5, 0.8, -0.5, -0.9, -0.8, -0.7, -0.5, 1, 0.2, -0.4, -1, 0.7, -0.8, -0.9, 0.4, 0.5, 0.3, -0.9, 1, -0.6, 0.7, -1, 0.8, 0.3, 0.8, -1, 1, -1, 0.8, -0.7, 1, 1, 0.5, -0.3, -0.4, 0.8, 1, -0.8, 1, 0, 0, 1, 0.6, 0, 0.8, 1, -0.8, -0.9, 0.2, -0.7, 0.9, -0.9, 1, -0.9, 1, 1, -0.7, -1, 0.9, 0, -0.7, 0.9, 0, 0, 0, -0.9, -0.9, 1, -0.6, -0.9, -0.9, 0.4, 0, -0.9, 1, -0.9, -0.9, 1, -0.9, 0, 1, 1, 0, 0, 1]\n",
    "axis6_2 = [-0.8, -0.3, -0.9, -0.2, 0.8, -0.8, -0.9, -0.7, 0.6, 0.1, -0.1, 0.5, 0.0, 0.2, -0.8, -0.8, 0.5, -0.9, -0.4, 0.9, 0.0, 0.3, -0.9, -0.8, 0.9, -0.8, -0.6, -0.2, 0.8, -0.6, -0.9, -0.8, -0.7, -0.5, 0.8, -0.4, -0.5, -0.9, -0.6, -0.8, -0.8, -0.9, 0.8, 0.0, -0.7, 0.9, -0.8, -0.8, -0.8, -0.8, -0.7, -0.8, 0.9, -0.8, 0.8, -0.9, -0.8, -0.1, -0.6, 0.0, 0.2, -0.6, 0.2, -0.8, -0.8, 0.8, -0.8, 0.0, 0.8, 0.1, 0.1, 0.1, -0.8, -0.7, -0.8, 0.9, 0.7, -0.8, -0.8, -0.8, -0.9, -0.8, -0.8, -0.9, -0.7, -0.8, 0.9, -0.8, -0.7, 0.0, -0.7, 0.8, -0.8, -0.7, -0.8, -0.9, -0.8, -0.7, -0.9, -0.7, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8]\n",
    "axis6_3 = [-0.6, -0.2, -0.7, -0.1, 0.9, -0.5, -0.7, -0.6, 0.5, 0.1, -0.1, 0.3, -0.1, 0.2, -0.4, -0.7, 0.4, -0.7, -0.1, 0.8, 0.0, 0.3, -0.8, -0.5, 0.9, -0.3, -0.4, -0.2, 0.7, -0.2, -0.6, -0.6, -0.4, -0.3, 0.7, -0.2, -0.4, -0.8, -0.5, -0.4, -0.3, 0.1, 0.2, 0.0, -0.5, -0.9, -0.8, -0.7, -0.8, -0.8, -0.9, -0.8, -0.8, -0.7, -0.6, -0.8, -0.7, -0.6, 0.8, -0.2, 0.0, -0.3, 0.6, -0.3, -0.7, -0.4, -0.5, 0.6, 0.3, -0.8, -0.4, -0.4, -0.7, -0.6, -0.1, 0.8, -0.3, -0.7, -0.8, -0.5, -0.4, 0.5, 0.4, 0.8, -0.5, -0.4, -0.3, 0.9, -0.4, 0.6, -0.8, -0.8, -0.7, -0.6, -0.7, -0.4, -0.3, -0.7, -0.1, -0.3, -0.4, -0.5, -0.6, -0.4, -0.5, -0.5, -0.5, -0.4, -0.5, -0.5, -0.3, -0.4, -0.5, -0.3, -0.5, -0.5, -0.4]\n",
    "axis7_1 = [0.6, 0.2, -0.4, 0.4, 0.9, -0.5, -0.6, -0.2, 0.8, 1, -0.3, 0.8, 0.3, 0.4, -0.5, -0.6, 0.7, -0.8, -0.1, 1, 1, 0.1, -0.8, -0.5, 0.9, -0.3, -0.5, 0, 0.9, -0.2, -0.6, -0.5, -0.2, -0.3, 0.9, 1, 0, -0.8, 0.8, -0.5, -0.6, 0.6, 0.7, 1, -0.6, 1, 0, 0.9, -0.8, 0.9, 0.5, 0.9, -0.9, 1, -0.9, 0.9, -0.5, 1, 1, 0.6, 0, 0.1, 0.8, 1, -0.5, 1, 0, 0, 0.9, 0.7, 0, 0.8, 1, -0.5, -0.6, 0.3, -0.5, 0.9, -0.6, 1, -0.6, 1, 1, -0.4, -0.9, 0.9, 0, -0.5, 0.9, 0, 0, 0, -0.6, -0.6, 1, -0.2, -0.6, -0.6, 0.5, 0, -0.6, 1, -0.6, -0.6, 1, -0.6, 0, 1, 1, 0, 0, 1]\n",
    "axis7_2 = [0.8, 0.3, -0.6, 0.2, 0.9, -0.5, -0.7, -0.2, 0.7, 0.9, 0.1, 0.7, 0.0, 0.4, -0.7, -0.6, 0.8, -0.8, -0.1, 1.0, 0.9, 0.6, -0.9, -0.6, 0.9, -0.7, -0.4, 0.0, 0.9, -0.2, -0.8, -0.6, -0.5, -0.4, 0.9, -0.3, -0.4, -0.9, -0.5, -0.7, -0.7, -0.9, 0.9, 0.9, -0.6, 0.9, -0.7, -0.7, -0.7, -0.7, -0.6, -0.7, 0.9, -0.7, 0.9, -0.8, -0.7, 0.1, -0.5, 0.1, 0.9, -0.5, 0.9, -0.7, -0.7, 0.9, -0.7, 0.3, 0.9, 0.9, 0.9, 0.9, -0.7, -0.6, -0.7, 1.0, 0.9, -0.7, -0.7, -0.7, -0.8, -0.7, -0.7, -0.8, -0.6, -0.7, 1.0, -0.7, -0.6, 0.9, -0.6, 0.9, -0.7, -0.6, -0.7, -0.8, -0.7, -0.6, -0.8, -0.6, -0.7, -0.7, -0.7, -0.7, -0.7, -0.7, -0.7]\n",
    "axis7_3 = [0.8, 0.4, 0.3, 0.5, 0.9, 0.2, -0.1, 0.2, 0.8, 1.0, 0.5, 0.7, 0.6, 0.6, 0.3, -0.2, 0.9, -0.4, 0.6, 0.9, 0.8, 0.7, -0.9, 0.3, 1.0, 0.4, -0.3, 0.2, 0.9, 0.6, -0.1, -0.1, 0.1, 0.4, 0.9, 0.3, 0.3, -0.9, 0.2, 0.3, 0.4, 1.0, 0.5, 0.4, 0.2, 1.0, 0.9, 0.8, 0.9, 0.9, 1.0, 0.9, 0.9, 0.8, 0.7, 0.9, 0.8, 0.7, 1.0, 0.6, 0.5, 0.3, 0.8, 0.3, 0.8, 0.5, 0.4, 0.8, 0.6, 0.9, 0.6, 0.6, 0.8, 0.7, 0.4, 1.0, 0.5, 0.8, 0.9, 0.2, 0.2, 1.0, 0.9, 1.0, 0.3, 0.2, 0.3, 1.0, 0.2, 0.9, 0.8, 0.9, 0.8, 0.7, 0.8, 0.2, 0.3, 0.8, 0.4, 0.3, 0.2, 0.8, 0.7, 0.8, 0.8, 0.7, 0.7, 0.7, 0.5, 0.2, 0.7, 0.4, 0.8, 0.8, 0.7]\n",
    "axis8_1 = [0.7, 0.4, -0.4, 0.5, 1, -0.4, -0.5, -0.2, 0.8, 1, -0.2, 0.9, 0.4, 0.5, -0.4, -0.5, 0.8, -0.8, 0, 1, 1, 0.2, -0.8, -0.5, 1, -0.3, -0.5, 0.1, 0.9, -0.2, -0.5, -0.4, -0.2, -0.2, 1, 1, 0.1, -0.9, 0.8, -0.4, -0.5, 0.6, 0.8, 1, -0.5, 1, 0.1, 0.8, -0.9, 0.9, 0.6, 1, -1, 1, -1, 1, -0.4, 1, 1, 0.7, 0.1, 0.2, 0.9, 1, -0.4, 1, 0, 0, 1, 0.8, 0, 0.9, 1, -0.4, -0.5, 0.3, -0.4, 1, -0.5, 1, -0.5, 1, 1, -0.3, -0.9, 1, 0.1, -0.4, 1, 0, 0, 0, -0.5, -0.5, 1, -0.1, -0.5, -0.5, 0.6, 0, -0.5, 1, -0.5, -0.5, 1, -0.5, 0.1, 1, 1, 0.1, 0.1, 1]\n",
    "axis8_2 = [0.7, 0.2, -0.5, 0.1, 0.8, -0.4, -0.6, -0.1, 0.6, 0.8, 0.0, 0.6, 0.0, 0.3, -0.6, -0.5, 0.7, -0.7, -0.1, 0.9, 0.7, 0.5, -0.8, -0.5, 0.8, -0.6, -0.3, 0.0, 0.8, -0.2, -0.7, -0.5, -0.4, -0.3, 0.8, -0.2, -0.3, -0.8, -0.4, -0.6, -0.5, -0.8, 0.8, 0.7, -0.5, 0.8, -0.6, -0.6, -0.6, -0.6, -0.5, -0.6, 0.8, -0.6, 0.8, -0.7, -0.6, 0.1, -0.4, 0.1, 0.8, -0.4, 0.8, -0.6, -0.6, 0.8, -0.6, 0.2, 0.8, 0.8, 0.8, 0.8, -0.6, -0.4, -0.6, 0.9, 0.8, -0.6, -0.6, -0.6, -0.7, -0.6, -0.6, -0.7, -0.4, -0.6, 0.9, -0.6, -0.4, 0.8, -0.4, 0.8, -0.6, -0.4, -0.6, -0.7, -0.6, -0.4, -0.7, -0.4, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6, -0.6]\n",
    "axis8_3 = [0.7, 0.3, 0.2, 0.4, 0.8, 0.1, -0.2, 0.2, 0.7, 0.9, 0.4, 0.6, 0.5, 0.5, 0.2, -0.3, 0.8, -0.4, 0.5, 0.9, 0.7, 0.6, -0.8, 0.2, 0.9, 0.3, -0.2, 0.1, 0.8, 0.5, -0.1, -0.2, 0.0, 0.3, 0.8, 0.2, 0.2, -0.8, 0.1, 0.2, 0.3, 0.9, 0.5, 0.3, 0.1, 0.9, 0.8, 0.7, 0.8, 0.8, 0.9, 0.8, 0.8, 0.7, 0.6, 0.8, 0.7, 0.6, 0.9, 0.5, 0.4, 0.2, 0.7, 0.2, 0.7, 0.4, 0.3, 0.7, 0.5, 0.8, 0.5, 0.5, 0.7, 0.6, 0.3, 0.9, 0.4, 0.7, 0.8, 0.1, 0.1, 0.9, 0.8, 0.9, 0.2, 0.1, 0.2, 0.9, 0.1, 0.8, 0.7, 0.8, 0.7, 0.6, 0.7, 0.1, 0.2, 0.7, 0.3, 0.2, 0.1, 0.7, 0.6, 0.7, 0.7, 0.6, 0.6, 0.6, 0.4, 0.1, 0.6, 0.3, 0.7, 0.7, 0.6]\n",
    "axis9_1 = [0.5, 0.2, -0.6, 0.4, 1, -0.5, -0.7, -0.4, 0.7, 0.5, -0.4, 0.8, 0.3, 0.5, -0.5, -0.7, 0.6, -0.9, -0.2, 1, 0.4, 0.1, -0.9, -0.6, 1, -0.4, -0.6, -0.2, 0.8, -0.3, -0.7, -0.6, -0.4, -0.4, 1, 0.4, -0.2, -1, 0.7, -0.5, -0.7, 0.5, 0.6, 0.5, -0.7, 1, -0.4, 0.7, -0.9, 0.8, 0.4, 0.8, -1, 1, -1, 0.8, -0.5, 1, 1, 0.5, -0.1, -0.2, 0.8, 1, -0.5, 1, 0, 0, 1, 0.6, 0, 0.8, 1, -0.5, -0.7, 0.3, -0.5, 0.9, -0.6, 1, -0.7, 1, 1, -0.5, -1, 0.9, 0.1, -0.5, 0.9, 0, 0, 0, -0.7, -0.7, 1, -0.4, -0.7, -0.7, 0.5, 0, -0.7, 1, -0.7, -0.7, 1, -0.7, 0.2, 1, 1, 0.2, 0.2, 1]\n",
    "axis9_2 = [0.7, 0.1, -0.8, 0.0, 0.9, -0.7, -0.8, -0.4, 0.5, 0.2, 0.0, 0.7, 0.0, 0.4, -0.7, -0.7, 0.6, -0.9, -0.2, 0.9, 0.1, 0.4, -0.9, -0.7, 0.9, -0.7, -0.5, 0.0, 0.8, -0.5, -0.8, -0.7, -0.6, -0.4, 0.9, -0.3, -0.4, -0.9, -0.5, -0.7, -0.7, -0.9, 0.9, 0.1, -0.6, 0.9, -0.7, -0.7, -0.7, -0.7, -0.6, -0.7, 0.9, -0.7, 0.8, -0.8, -0.7, 0.0, -0.5, 0.0, 0.3, -0.5, 0.7, -0.7, -0.7, 0.8, -0.7, 0.1, 0.9, 0.3, 0.3, 0.3, -0.7, -0.6, -0.7, 0.9, 0.8, -0.7, -0.7, -0.7, -0.8, -0.7, -0.7, -0.8, -0.6, -0.7, 0.9, -0.7, -0.6, 0.3, -0.6, 0.8, -0.7, -0.6, -0.7, -0.8, -0.7, -0.6, -0.8, -0.6, -0.7, -0.7, -0.7, -0.7, -0.7, -0.7, -0.7]\n",
    "axis9_3 = [0.7, 0.3, 0.1, 0.4, 0.9, 0.0, -0.3, 0.2, 0.6, 0.5, 0.3, 0.7, 0.5, 0.6, 0.1, -0.4, 0.7, -0.5, 0.6, 0.8, 0.4, 0.6, -0.8, 0.1, 0.9, 0.2, -0.3, 0.0, 0.7, 0.5, -0.2, -0.3, -0.1, 0.2, 0.8, 0.1, 0.1, -0.8, 0.0, 0.1, 0.2, 0.8, 0.4, 0.3, 0.0, 0.9, 0.8, 0.7, 0.8, 0.8, 0.9, 0.8, 0.8, 0.7, 0.6, 0.8, 0.7, 0.6, 0.9, 0.4, 0.3, 0.1, 0.7, 0.1, 0.7, 0.3, 0.2, 0.7, 0.5, 0.8, 0.4, 0.4, 0.7, 0.6, 0.2, 1.0, 0.3, 0.7, 0.8, 0.0, 0.0, 0.9, 0.8, 1.0, 0.1, 0.0, 0.1, 1.0, 0.0, 0.8, 0.6, 0.7, 0.6, 0.5, 0.6, 0.0, 0.1, 0.6, 0.2, 0.1, 0.0, 0.6, 0.5, 0.6, 0.6, 0.5, 0.5, 0.5, 0.3, 0.0, 0.5, 0.2, 0.6, 0.6, 0.5]\n",
    "\n",
    "# combine all the axis data into a list of lists\n",
    "all_axes = [axis0_1, axis0_2, axis0_3, axis1_1, axis1_2, axis1_3, axis2_1, axis2_2, axis2_3, axis3_1, axis3_2, axis3_3, axis4_1, axis4_2, axis4_3, axis5_1, axis5_2, axis5_3, axis6_1, axis6_2, axis6_3, axis7_1, axis7_2, axis7_3, axis8_1, axis8_2, axis8_3, axis9_1, axis9_2, axis9_3]\n",
    "\n",
    "print(len(all_axes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure every axis has the same length (100)\n",
    "for a in range(len(all_axes)):\n",
    "    axis = all_axes[a]\n",
    "    all_axes[a] = axis[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every group of three axes, calculate the mean and standard deviation for each value in the list\n",
    "# store in dict\n",
    "axis_dict = {}\n",
    "\n",
    "# initialize the dict for each axis \n",
    "for i in range(10):\n",
    "    axis_dict[f\"axis{i}\"] = {\"mean\": [], \"std\": []}\n",
    "\n",
    "i = 0\n",
    "while i < len(all_axes):\n",
    "    # each group of three axes represents the three interpretations of one axis\n",
    "    interpret1 = all_axes[i]\n",
    "    interpret2 = all_axes[i+1]\n",
    "    interpret3 = all_axes[i+2]\n",
    "\n",
    "    axis_num = i // 3\n",
    "\n",
    "    axis_dict[f\"axis{axis_num}\"][\"mean\"] = [statistics.mean([interpret1[j], interpret2[j], interpret3[j]]) for j in range(len(interpret1))]\n",
    "    axis_dict[f\"axis{axis_num}\"][\"std\"] = [statistics.stdev([interpret1[j], interpret2[j], interpret3[j]]) for j in range(len(interpret1))]\n",
    "    \n",
    "    i += 3 # increment by 3 to get to the next group of three axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round each value in mean lists to 3 decimal places\n",
    "# and only save mean std values\n",
    "for axis in axis_dict:\n",
    "    axis_dict[axis][\"mean\"] = [round(val, 3) for val in axis_dict[axis][\"mean\"]]\n",
    "    axis_dict[axis][\"std\"] = statistics.mean(axis_dict[axis][\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40803333122455593\n"
     ]
    }
   ],
   "source": [
    "# print overall mean std\n",
    "print(statistics.mean([axis_dict[axis][\"std\"] for axis in axis_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: still some variability (all values fall between -1 and 1)\n",
    "- mean sd did increase a bit (before: 0.32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparing old and generated embeddings for first 10 axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.867</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>0.867</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aesthetic</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acrylic</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artistry</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      0      1      2      3      4      5      6      7      8  \\\n",
       "0   abstract -0.933 -0.467  0.867 -0.600 -0.333  0.867 -0.733  0.733  0.700   \n",
       "1  aesthetic -0.433 -0.167  0.167 -0.033 -0.067  0.333 -0.233  0.300  0.300   \n",
       "2    acrylic -0.733 -0.367 -0.333 -0.567 -0.367 -0.267 -0.833 -0.233 -0.233   \n",
       "3   artistry -0.267 -0.200  0.233  0.033 -0.200  0.267 -0.200  0.367  0.333   \n",
       "4  animation  1.000  0.567  0.800  0.767  0.600  0.767  0.900  0.900  0.867   \n",
       "\n",
       "       9  \n",
       "0  0.633  \n",
       "1  0.200  \n",
       "2 -0.433  \n",
       "3  0.267  \n",
       "4  0.933  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with columns 0-9\n",
    "df_llm = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# use mean values to populate dataframe; column numbers are the axis numbers\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    df_llm[axis] = axis_dict[axis_title][\"mean\"]\n",
    "\n",
    "# add words as first column\n",
    "df_llm.insert(0, \"word\", words)\n",
    "\n",
    "df_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'axis0': {'mean_diff': 0.5327571161950632, 'std_diff': 0.4100664811753058}, 'axis1': {'mean_diff': 0.5166050121065375, 'std_diff': 0.3529606134695156}, 'axis2': {'mean_diff': 0.5081664438122333, 'std_diff': 0.3537342589331988}, 'axis3': {'mean_diff': 0.49242681473456124, 'std_diff': 0.3644715338619721}, 'axis4': {'mean_diff': 0.44363717948717946, 'std_diff': 0.2883780919648976}, 'axis5': {'mean_diff': 0.4253441826215022, 'std_diff': 0.3141262955185306}, 'axis6': {'mean_diff': 0.5813144927536231, 'std_diff': 0.42067238835753906}, 'axis7': {'mean_diff': 0.5898348923959827, 'std_diff': 0.4151669481767916}, 'axis8': {'mean_diff': 0.46398391923990506, 'std_diff': 0.3384734200749216}, 'axis9': {'mean_diff': 0.5235712274368232, 'std_diff': 0.3503883226996408}}\n"
     ]
    }
   ],
   "source": [
    "# compare values in each column (axis) of df_llm to original dataframe df\n",
    "# store mean difference and std for each axis\n",
    "\n",
    "# initialize dict to store mean difference and std for each axis\n",
    "axis_diff_dict = {}\n",
    "\n",
    "# initialize dict for each axis\n",
    "for i in range(10):\n",
    "    axis_diff_dict[f\"axis{i}\"] = {\"mean_diff\": [], \"std_diff\": []}\n",
    "\n",
    "# for each axis, calculate mean difference and std\n",
    "for axis in range(len(axis_diff_dict)):\n",
    "    diffs = [abs(df_llm[axis][i] - df[axis][i]) for i in range(len(df_llm))]\n",
    "    mean_diff = statistics.mean(diffs)\n",
    "    std_diff = statistics.stdev(diffs)\n",
    "\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"mean_diff\"] = mean_diff\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"std_diff\"] = std_diff\n",
    "\n",
    "# print results\n",
    "print(axis_diff_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean diff: 0.5077641280783411 (uncertainty: 0.25)\n",
      "std of diffs: 0.3608438354232314 (uncertainty: 0.18)\n"
     ]
    }
   ],
   "source": [
    "# print overall mean difference\n",
    "overall_mean = statistics.mean([axis_diff_dict[axis][\"mean_diff\"] for axis in axis_diff_dict])\n",
    "mean_uncertainty = overall_mean / 2\n",
    "print(f\"mean diff: {overall_mean} (uncertainty: {mean_uncertainty:.2f})\")\n",
    "\n",
    "# print overall mean std\n",
    "overall_std = statistics.mean([axis_diff_dict[axis][\"std_diff\"] for axis in axis_diff_dict])\n",
    "std_uncertainty = overall_std / 2\n",
    "print(f\"std of diffs: {overall_std} (uncertainty: {std_uncertainty:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting... with more detailed descriptions, mean + std of diffs increased a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cosine similarity function\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare cosine similarity of original and synthesized embeddings\n",
    "# ❓ question: should we be comparing by axis or word?\n",
    "\n",
    "# try columns first (by axis)\n",
    "# compute cosine similarity for each axis in df_llm and df\n",
    "# store in list\n",
    "axis_cos_sim_list = []\n",
    "\n",
    "# also try by word (row)\n",
    "# compute cosine similarity for each word in df_llm and df\n",
    "# store in list \n",
    "word_cos_sim_list = []\n",
    "\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    axis_cos_sim = cosine_similarity([df_llm[axis]], [df[axis]])\n",
    "    axis_cos_sim = axis_cos_sim[0][0]\n",
    "    axis_cos_sim_list.append(axis_cos_sim)\n",
    "\n",
    "for word in range(len(df_llm)):\n",
    "    # crop rows in df to 10 dimensions\n",
    "    word_cos_sim = cosine_similarity([df_llm.iloc[word][1:]], [df.iloc[word][1:11]])\n",
    "    word_cos_sim = word_cos_sim[0][0]\n",
    "    word_cos_sim_list.append(word_cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.003602043227383958, -0.16341921013153243, -0.17235485498635827, -0.0935585422593968, 0.029669460362598668, 0.09148389220452216, -0.11846114554109186, -0.21247530026750175, -0.019203245044967537, -0.11888954281012086]\n",
      "[-0.2953101039312527, -0.3741989959961967, -0.15670158656761743, -0.4818266647199914, 0.0805700989115944, -0.6334966875556708, -0.12180455144432575, -0.2221732846689293, -0.014703929987126656, 0.08563457530130435, -0.16721813048776252, 0.08955094464477055, -0.30001403425589585, -0.43240577995831353, 0.1654936628569716, 0.6120678871224687, 0.14343733810879955, -0.15227112427319217, -0.36004930604677104, 0.3189442389072261, 0.5830190787917917, -0.3252876122806961, 0.27611285857729745, -0.6847511972043232, 0.26854027187873186, -0.30640289473404975, -0.4123024459428165, -0.09663704681343666, 0.030416541458387132, -0.06888445263392479, -0.5390577239629659, -0.25849028599404933, 0.20877605277765526, 0.3739310667316866, 0.1453925050541071, -0.18534251011823674, -0.34150721046788146, -0.0028251246765171934, -0.4699937923229926, -0.3330496788464702, -0.6293118213217102, -0.6045840957314961, 0.5760498229376486, 0.015490736697346278, -0.013628639436017373, -0.4462119456857168, -0.47346941185990893, -0.2636399768207654, -0.21884461205579106, -0.4184505719658298, 0.6700976132267067, -0.7157630233343166, -0.24964941911806765, -0.3131188169237468, -0.7166797246141924, 0.026701102215200154, -0.2844558871955747, 0.11830892612350652, -0.22073359472148898, 0.1418579910679502, 0.39273434999021695, 0.05845222808899196, 0.12390222272918698, -0.564716224058187, -0.2557809433309609, 0.29788170546533294, -0.4536476975052749, -0.28223357193242227, 0.03357775601072615, -0.4365493700439496, -0.20791566830661382, -0.2758131210221265, -0.24730041187488008, -0.3086603656028745, -0.06744920020532233, 0.4448651073061123, -0.29990935055568957, -0.4117283123839026, -0.5731957511830023, 0.21694126160198696, -0.05817817491757811, -0.2651235546124186, -0.37363619733234515, -0.6633985731759506, -0.07569602761550459, 0.3022948843354693, 0.1191967911306175, -0.4325623139888136, -0.018678743249173804, 0.17277880019100383, -0.7016539927890255, 0.37150697256195186, -0.5922311534984052, -0.12155490501242484, -0.3152776068503473, 0.059028632107193356, -0.1821460589135255, 0.3609013275413644, -0.22408897282208434, -0.6346946804440827]\n"
     ]
    }
   ],
   "source": [
    "# see results\n",
    "print(axis_cos_sim_list)\n",
    "print(word_cos_sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis cos sim avg: -0.07808105317012326\n",
      "word cos sim avg: -0.1446461328745161\n"
     ]
    }
   ],
   "source": [
    "# take average of each list\n",
    "axis_cos_sim_avg = statistics.mean(axis_cos_sim_list)\n",
    "word_cos_sim_avg = statistics.mean(word_cos_sim_list)\n",
    "\n",
    "# print results\n",
    "print(f\"axis cos sim avg: {axis_cos_sim_avg}\")\n",
    "print(f\"word cos sim avg: {word_cos_sim_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis cos sim max: 0.09148389220452216\n",
      "axis cos sim min: -0.21247530026750175\n",
      "axis cos sim std: 0.09840029631197905\n",
      "word cos sim max: 0.6700976132267067\n",
      "word cos sim min: -0.7166797246141924\n",
      "word cos sim std: 0.33015266138914245\n"
     ]
    }
   ],
   "source": [
    "# also print max, min, and std\n",
    "print(f\"axis cos sim max: {max(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim min: {min(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim std: {statistics.stdev(axis_cos_sim_list)}\")\n",
    "\n",
    "print(f\"word cos sim max: {max(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim min: {min(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim std: {statistics.stdev(word_cos_sim_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: oof, not very good 😅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new list of words to test\n",
    "test_words = ['pointillism',\n",
    " 'maquette',\n",
    " 'gesso',\n",
    " 'decoupage',\n",
    " 'encaustic',\n",
    " 'figurative',\n",
    " 'grid',\n",
    " 'hatching',\n",
    " 'intaglio',\n",
    " 'juxtapose',\n",
    " 'kiln',\n",
    " 'lithography',\n",
    " 'monotype',\n",
    " 'negative space',\n",
    " 'ochre',\n",
    " 'patina',\n",
    " 'quinacridone',\n",
    " 'raku',\n",
    " 'sfumato',\n",
    " 'tenebrism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new embeddings\n",
    "# get embedding for each class\n",
    "# ❗️ note: I am averaging the embeddings for each word in the class\n",
    "# ❓ question: are we interested in the final contextual embedding for each class? currently, we're looking at the final hidden state.\n",
    "test_embeddings = []\n",
    "for i in range(len(test_words)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(words[i])).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]\n",
    "    # skip the first token, which is the [CLS] token, and skip the last token, which is the [SEP] token\n",
    "    # average the rest of the tokens\n",
    "    test_embeddings.append(last_hidden_states[0][1:-1].mean(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(len(test_embeddings))\n",
    "print(len(test_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round each val in embedding to 3 decimal places\n",
    "test_embeddings = [list(np.around(np.array(e),3)) for e in test_embeddings]\n",
    "\n",
    "# create string of all classes and their embeddings & save to text file\n",
    "# ❗️ note: only taking first 10 axes for now due to context window length\n",
    "with open(\"output.txt\", \"w\") as text_file:\n",
    "    for i in range(len(test_words)):\n",
    "        class_str = f\"{test_words[i]}: {test_embeddings[i][:10]}\\n\"\n",
    "        text_file.write(class_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pointillism</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maquette</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gesso</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.777</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>0.548</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decoupage</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encaustic</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      0      1      2      3      4      5      6      7      8  \\\n",
       "0  pointillism  0.286  0.395 -0.382 -0.242  0.407  0.010 -0.199  0.060  0.203   \n",
       "1     maquette  0.249  0.566 -0.123 -0.117  0.271  0.083  0.036 -0.069  0.083   \n",
       "2        gesso  0.217  0.234 -0.019  0.087  0.777 -0.107 -0.655  0.548 -0.061   \n",
       "3    decoupage  0.147  0.263 -0.044 -0.078  0.660  0.147 -0.043 -0.021 -0.120   \n",
       "4    encaustic -0.006  0.449 -0.484  0.105  0.504  0.228  0.095  0.199 -0.532   \n",
       "\n",
       "   ...    758    759    760    761    762    763    764    765    766    767  \n",
       "0  ...  0.734 -0.119  0.476  0.058  0.239 -0.068  0.101  0.026  0.260 -0.127  \n",
       "1  ...  0.516  0.024  0.273 -0.004  0.114 -0.206  0.080  0.043  0.187  0.201  \n",
       "2  ...  0.254 -0.524  0.176  0.345  0.337 -0.254 -0.499 -0.021  0.162  0.142  \n",
       "3  ...  0.639 -0.331  0.187  0.041 -0.143 -0.029  0.110 -0.205  0.363 -0.308  \n",
       "4  ...  0.550 -0.206  0.477  0.005  0.140 -0.114  0.244 -0.032  0.513  0.498  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataframe\n",
    "df_test = pd.DataFrame(test_embeddings)\n",
    "df_test.insert(0, 'word', test_words)\n",
    "\n",
    "# sanity check\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pointillism</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>0.318876</td>\n",
       "      <td>-0.433628</td>\n",
       "      <td>-0.040491</td>\n",
       "      <td>-0.568465</td>\n",
       "      <td>-0.184729</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>-0.191697</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048035</td>\n",
       "      <td>0.387226</td>\n",
       "      <td>0.324590</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>0.035758</td>\n",
       "      <td>-0.179551</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.033604</td>\n",
       "      <td>-0.247505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maquette</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>0.593574</td>\n",
       "      <td>0.330383</td>\n",
       "      <td>0.266258</td>\n",
       "      <td>-0.850622</td>\n",
       "      <td>-0.004926</td>\n",
       "      <td>0.414955</td>\n",
       "      <td>-0.506716</td>\n",
       "      <td>0.469534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427948</td>\n",
       "      <td>0.672655</td>\n",
       "      <td>-0.340984</td>\n",
       "      <td>-0.080495</td>\n",
       "      <td>-0.272503</td>\n",
       "      <td>-0.523691</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>0.299720</td>\n",
       "      <td>-0.135574</td>\n",
       "      <td>0.407186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gesso</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.766871</td>\n",
       "      <td>0.199170</td>\n",
       "      <td>-0.472906</td>\n",
       "      <td>-0.720624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.421158</td>\n",
       "      <td>-0.659016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277435</td>\n",
       "      <td>-0.643392</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.120448</td>\n",
       "      <td>-0.193511</td>\n",
       "      <td>0.289421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decoupage</td>\n",
       "      <td>0.055990</td>\n",
       "      <td>0.106827</td>\n",
       "      <td>0.563422</td>\n",
       "      <td>0.361963</td>\n",
       "      <td>-0.043568</td>\n",
       "      <td>0.152709</td>\n",
       "      <td>0.285127</td>\n",
       "      <td>-0.389499</td>\n",
       "      <td>-0.015532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159389</td>\n",
       "      <td>-0.035928</td>\n",
       "      <td>-0.622951</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>-0.906289</td>\n",
       "      <td>-0.082294</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>-0.394958</td>\n",
       "      <td>0.272306</td>\n",
       "      <td>-0.608782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encaustic</td>\n",
       "      <td>-0.128236</td>\n",
       "      <td>0.405622</td>\n",
       "      <td>-0.734513</td>\n",
       "      <td>0.811043</td>\n",
       "      <td>-0.367220</td>\n",
       "      <td>0.352217</td>\n",
       "      <td>0.511915</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353712</td>\n",
       "      <td>0.213573</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.208385</td>\n",
       "      <td>-0.294264</td>\n",
       "      <td>0.731935</td>\n",
       "      <td>0.089636</td>\n",
       "      <td>0.619930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word         0         1         2         3         4         5  \\\n",
       "0  pointillism  0.223359  0.318876 -0.433628 -0.040491 -0.568465 -0.184729   \n",
       "1     maquette  0.178808  0.593574  0.330383  0.266258 -0.850622 -0.004926   \n",
       "2        gesso  0.140277  0.060241  0.637168  0.766871  0.199170 -0.472906   \n",
       "3    decoupage  0.055990  0.106827  0.563422  0.361963 -0.043568  0.152709   \n",
       "4    encaustic -0.128236  0.405622 -0.734513  0.811043 -0.367220  0.352217   \n",
       "\n",
       "          6         7         8  ...       758       759       760       761  \\\n",
       "0  0.028759 -0.191697  0.756272  ...  0.048035  0.387226  0.324590  0.111455   \n",
       "1  0.414955 -0.506716  0.469534  ... -0.427948  0.672655 -0.340984 -0.080495   \n",
       "2 -0.720624  1.000000  0.125448  ... -1.000000 -0.421158 -0.659016  1.000000   \n",
       "3  0.285127 -0.389499 -0.015532  ... -0.159389 -0.035928 -0.622951  0.058824   \n",
       "4  0.511915  0.147741 -1.000000  ... -0.353712  0.213573  0.327869 -0.052632   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.035758 -0.179551  0.398601  0.252101  0.033604 -0.247505  \n",
       "1 -0.272503 -0.523691  0.349650  0.299720 -0.135574  0.407186  \n",
       "2  0.277435 -0.643392 -1.000000  0.120448 -0.193511  0.289421  \n",
       "3 -0.906289 -0.082294  0.419580 -0.394958  0.272306 -0.608782  \n",
       "4 -0.208385 -0.294264  0.731935  0.089636  0.619930  1.000000  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize each column to be between -1 and 1\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df_test.iloc[:,1:] = scaler.fit_transform(df_test.iloc[:,1:])\n",
    "\n",
    "# sanity check\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# values assigned by chatgpt\n",
    "# generated vals for each axis\n",
    "# ❗️ note: these may not be the right length -- need to check/fix later\n",
    "axis0_1 = [-0.8, -0.5, -0.7, -0.4, -0.6, -0.3, 0.2, -0.1, -0.5, 0.3, -0.4, -0.6, -0.2, 0.1, -0.3, -0.5, 0.4, -0.2, -0.7, -0.6]\n",
    "axis0_2 = [-0.8, -0.2, -0.6, -0.4, -0.6, -0.1, 0, -0.2, -0.7, 0.2, -0.5, -0.6, -0.3, 0.1, -0.2, -0.1, 0.3, -0.4, -0.7, -0.8]\n",
    "axis0_3 = [-0.6, 0, -0.2, 0, -0.4, -0.5, 0.5, -0.1, -0.4, 0.3, -0.3, -0.2, 0, 0.2, -0.2, -0.1, 0.6, 0.1, -0.5, -0.4]\n",
    "axis1_1 = [-0.6, 0.2, -0.3, -0.2, 0.1, -0.5, -0.7, -0.6, -0.4, 0.3, -0.2, -0.5, -0.1, 0.4, -0.3, -0.4, 0.5, 0.2, -0.6, -0.5]\n",
    "axis1_2 = [-0.3, -0.2, -0.1, -0.4, -0.2, -0.1, 0.1, -0.2, -0.3, 0.2, -0.2, -0.3, -0.1, 0.1, -0.1, -0.2, 0.3, -0.2, -0.3, -0.4]\n",
    "axis1_3 = [-0.5, 0, -0.2, 0.1, -0.3, -0.1, 0.4, -0.6, -0.2, 0.3, 0, -0.3, 0, 0.2, 0, -0.1, 0.5, 0, -0.4, 0.6]\n",
    "axis2_1 = [0.5, 0.3, 0.2, 0.6, 0.4, 0.1, 0.7, 0.5, 0.3, 0.8, 0.2, 0.1, 0.6, 0.9, 0.2, 0.1, 0.7, 0.4, 0.3, 0.2]\n",
    "axis2_2 = [0.4, 0.2, 0.3, 0.5, 0.3, 0.1, 0.2, 0.1, 0.2, 0.6, 0.2, 0.3, 0.4, 0.5, 0.2, 0.1, 0.6, 0.3, 0.2, 0.3]\n",
    "axis2_3 = [0.4, 0, 0, 0.5, 0.6, 0.1, 0.2, 0.3, 0.1, 0.7, 0, 0.2, 0.3, 0.5, 0, 0, 0.4, 0, 0.2, 0.3]\n",
    "axis3_1 = [-0.7, -0.5, -0.6, -0.4, -0.5, -0.3, -0.8, -0.7, -0.6, 0.4, -0.5, -0.6, -0.4, 0.1, -0.3, -0.5, 0.3, -0.2, -0.7, -0.6]\n",
    "axis3_2 = [-0.6, -0.4, -0.5, -0.3, -0.5, -0.2, -0.1, -0.3, -0.6, 0.2, -0.4, -0.5, -0.3, 0.1, -0.2, -0.3, 0.4, -0.4, -0.6, -0.7]\n",
    "axis3_3 = [-0.5, 0, -0.4, 0.3, -0.6, -0.7, -0.2, -0.5, -0.3, 0.2, -0.2, -0.4, 0.1, 0.3, -0.3, -0.1, 0.4, 0, -0.6, -0.4]\n",
    "axis4_1 = [-0.4, -0.2, -0.3, 0.2, -0.1, -0.5, -0.6, -0.5, -0.3, 0.5, -0.2, -0.4, -0.1, 0.3, -0.2, -0.3, 0.4, -0.1, -0.5, -0.4]\n",
    "axis4_2 = [-0.3, -0.2, -0.1, 0.2, -0.2, -0.1, 0, -0.2, -0.3, 0.3, -0.2, -0.3, -0.1, 0.4, -0.1, -0.2, 0.3, -0.2, -0.3, -0.4]\n",
    "axis4_3 = [-0.2, 0, 0, 0.3, -0.1, -0.4, 0.5, -0.3, -0.2, 0.4, 0, -0.1, 0.2, 0.6, 0, -0.1, 0.5, 0, -0.3, 0.7]\n",
    "axis5_1 = [0.6, 0.4, 0.3, 0.7, 0.5, 0.2, 0.8, 0.6, 0.4, 0.9, 0.3, 0.2, 0.7, 1.0, 0.3, 0.2, 0.8, 0.5, 0.4, 0.3]\n",
    "axis5_2 = [0.5, 0.3, 0.4, 0.6, 0.4, 0.2, 0.3, 0.2, 0.3, 0.7, 0.3, 0.4, 0.5, 0.6, 0.3, 0.2, 0.7, 0.4, 0.3, 0.4]\n",
    "axis5_3 = [0.5, 0, 0.1, 0.6, 0.7, 0.4, 0.3, 0.2, 0.3, 0.8, 0.1, 0.2, 0.4, 0.6, 0, 0.1, 0.5, 0, 0.3, 0.2]\n",
    "axis6_1 = [-0.7, -0.5, -0.6, -0.4, -0.6, -0.3, -0.8, -0.7, -0.6, 0.3, -0.5, -0.6, -0.4, 0.2, -0.3, -0.5, 0.4, -0.2, -0.7, -0.6]\n",
    "axis6_2 = [-0.7, -0.5, -0.6, -0.4, -0.6, -0.3, -0.2, -0.5, -0.7, 0.3, -0.5, -0.6, -0.4, 0.2, -0.3, -0.4, 0.5, -0.5, -0.7, -0.8]\n",
    "axis6_3 = [-0.7, -0.5, -0.6, -0.3, -0.8, -0.4, 0.2, -0.2, -0.7, 0.4, -0.6, -0.5, 0.1, 0.3, -0.1, -0.2, 0.6, 0, -0.5, -0.3]\n",
    "axis7_1 = [0.6, 0.4, 0.3, 0.7, 0.5, 0.2, 0.8, 0.6, 0.4, 0.9, 0.3, 0.5, 0.7, 1.0, 0.3, 0.2, 0.8, 0.5, 0.4, 0.3]\n",
    "axis7_2 = [0.6, 0.4, 0.5, 0.7, 0.5, 0.3, 0.4, 0.3, 0.5, 0.8, 0.4, 0.5, 0.6, 0.7, 0.4, 0.3, 0.8, 0.5, 0.5, 0.6]\n",
    "axis7_3 = [0.5, 0, 0.1, 0.6, 0.7, 0.4, 0.3, 0.2, 0.3, 0.8, 0.1, 0.2, 0.4, 0.6, 0, 0.1, 0.5, 0, 0.3, 0.2]\n",
    "axis8_1 = [0.6, 0.4, 0.3, 0.7, 0.5, 0.2, 0.8, 0.6, 0.4, 0.9, 0.3, 0.5, 0.7, 1.0, 0.3, 0.2, 0.8, 0.5, 0.4, 0.3]\n",
    "axis8_2 = [0.5, 0.3, 0.4, 0.6, 0.4, 0.2, 0.3, 0.2, 0.4, 0.7, 0.3, 0.4, 0.5, 0.6, 0.3, 0.2, 0.7, 0.4, 0.4, 0.5]\n",
    "axis8_3 = [0.4, 0, 0.2, 0.5, 0.6, 0.3, 0.1, 0.3, 0.2, 0.7, 0, 0.3, 0.4, 0.5, 0, 0, 0.4, 0, 0.2, 0.3]\n",
    "axis9_1 = [0.5, 0.3, 0.4, 0.6, 0.5, -0.1, 0.7, 0.5, 0.4, 0.8, 0.2, 0.3, 0.6, -0.2, 0.1, 0.3, 0.7, 0.4, 0.5, 0.4]\n",
    "axis9_2 = [0.4, 0.2, 0.3, 0.5, 0.3, 0.1, 0.2, 0.1, 0.3, 0.6, 0.2, 0.3, 0.4, 0.5, 0.2, 0.1, 0.6, 0.3, 0.2, 0.4]\n",
    "axis9_3 = [0.3, 0, 0.2, 0.5, 0.4, 0.1, 0.6, 0.2, 0.1, 0.7, 0, 0.3, 0.5, 0.6, -0.1, 0.1, 0.4, 0, 0.3, 0.2]\n",
    "\n",
    "# combine all the axis data into a list of lists\n",
    "all_axes = [axis0_1, axis0_2, axis0_3, axis1_1, axis1_2, axis1_3, axis2_1, axis2_2, axis2_3, axis3_1, axis3_2, axis3_3, axis4_1, axis4_2, axis4_3, axis5_1, axis5_2, axis5_3, axis6_1, axis6_2, axis6_3, axis7_1, axis7_2, axis7_3, axis8_1, axis8_2, axis8_3, axis9_1, axis9_2, axis9_3]\n",
    "\n",
    "print(len(all_axes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure every axis has the same length (20)\n",
    "for a in range(len(all_axes)):\n",
    "    axis = all_axes[a]\n",
    "    all_axes[a] = axis[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every group of three axes, calculate the mean and standard deviation for each value in the list\n",
    "# store in dict\n",
    "axis_dict = {}\n",
    "\n",
    "# initialize the dict for each axis \n",
    "for i in range(10):\n",
    "    axis_dict[f\"axis{i}\"] = {\"mean\": [], \"std\": []}\n",
    "\n",
    "i = 0\n",
    "while i < len(all_axes):\n",
    "    # each group of three axes represents the three interpretations of one axis\n",
    "    interpret1 = all_axes[i]\n",
    "    interpret2 = all_axes[i+1]\n",
    "    interpret3 = all_axes[i+2]\n",
    "\n",
    "    axis_num = i // 3\n",
    "\n",
    "    axis_dict[f\"axis{axis_num}\"][\"mean\"] = [statistics.mean([interpret1[j], interpret2[j], interpret3[j]]) for j in range(len(interpret1))]\n",
    "    axis_dict[f\"axis{axis_num}\"][\"std\"] = [statistics.stdev([interpret1[j], interpret2[j], interpret3[j]]) for j in range(len(interpret1))]\n",
    "    \n",
    "    i += 3 # increment by 3 to get to the next group of three axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15485851551435226\n"
     ]
    }
   ],
   "source": [
    "# round each value in mean lists to 3 decimal places\n",
    "# and only save mean std values\n",
    "for axis in axis_dict:\n",
    "    axis_dict[axis][\"mean\"] = [round(val, 3) for val in axis_dict[axis][\"mean\"]]\n",
    "    axis_dict[axis][\"std\"] = statistics.mean(axis_dict[axis][\"std\"])\n",
    "\n",
    "# print overall mean std\n",
    "print(statistics.mean([axis_dict[axis][\"std\"] for axis in axis_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smaller std than training data (0.41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pointillism</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maquette</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gesso</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decoupage</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encaustic</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      0      1      2      3      4      5      6      7      8  \\\n",
       "0  pointillism -0.733 -0.467  0.433 -0.600 -0.300  0.533 -0.700  0.567  0.500   \n",
       "1     maquette -0.233  0.000  0.167 -0.300 -0.133  0.233 -0.500  0.267  0.233   \n",
       "2        gesso -0.500 -0.200  0.167 -0.500 -0.133  0.267 -0.600  0.300  0.300   \n",
       "3    decoupage -0.267 -0.167  0.533 -0.133  0.233  0.633 -0.367  0.667  0.600   \n",
       "4    encaustic -0.533 -0.133  0.433 -0.533 -0.133  0.533 -0.667  0.567  0.500   \n",
       "\n",
       "       9  \n",
       "0  0.400  \n",
       "1  0.167  \n",
       "2  0.300  \n",
       "3  0.533  \n",
       "4  0.400  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare original test embeddings to the generated embeddings\n",
    "# create dataframe with columns 0-9\n",
    "df_test_llm = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# use mean values to populate dataframe; column numbers are the axis numbers\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    df_test_llm[axis] = axis_dict[axis_title][\"mean\"]\n",
    "\n",
    "# add words as first column\n",
    "df_test_llm.insert(0, \"word\", test_words)\n",
    "\n",
    "df_test_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'axis0': {'mean_diff': 0.6754966887417219, 'std_diff': 0.3583434990330248}, 'axis1': {'mean_diff': 0.4916833333333334, 'std_diff': 0.3834830105335782}, 'axis2': {'mean_diff': 0.5403995575221239, 'std_diff': 0.3868672607479474}, 'axis3': {'mean_diff': 0.6651049079754602, 'std_diff': 0.40365020321555467}, 'axis4': {'mean_diff': 0.40098485477178425, 'std_diff': 0.24555193552953924}, 'axis5': {'mean_diff': 0.5576098522167489, 'std_diff': 0.33138590815560787}, 'axis6': {'mean_diff': 0.6675563681183236, 'std_diff': 0.39243586794553603}, 'axis7': {'mean_diff': 0.6640804639804639, 'std_diff': 0.4084987757670915}, 'axis8': {'mean_diff': 0.6016786140979689, 'std_diff': 0.3866735927781845}, 'axis9': {'mean_diff': 0.5840078986587182, 'std_diff': 0.40683836259275175}}\n"
     ]
    }
   ],
   "source": [
    "# compare values in each column (axis) of df_llm to original dataframe df\n",
    "# store mean difference and std for each axis\n",
    "\n",
    "# initialize dict to store mean difference and std for each axis\n",
    "axis_diff_dict = {}\n",
    "\n",
    "# initialize dict for each axis\n",
    "for i in range(10):\n",
    "    axis_diff_dict[f\"axis{i}\"] = {\"mean_diff\": [], \"std_diff\": []}\n",
    "\n",
    "# for each axis, calculate mean difference and std\n",
    "for axis in range(len(axis_diff_dict)):\n",
    "    diffs = [abs(df_test_llm[axis][i] - df_test[axis][i]) for i in range(len(df_test_llm))]\n",
    "    mean_diff = statistics.mean(diffs)\n",
    "    std_diff = statistics.stdev(diffs)\n",
    "\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"mean_diff\"] = mean_diff\n",
    "    axis_diff_dict[f\"axis{axis}\"][\"std_diff\"] = std_diff\n",
    "\n",
    "# print results\n",
    "print(axis_diff_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean diff: 0.5848602539416647 (uncertainty: 0.29)\n",
      "std of diffs: 0.3703728416298816 (uncertainty: 0.19)\n"
     ]
    }
   ],
   "source": [
    "# print overall mean difference\n",
    "overall_mean = statistics.mean([axis_diff_dict[axis][\"mean_diff\"] for axis in axis_diff_dict])\n",
    "mean_uncertainty = overall_mean / 2\n",
    "print(f\"mean diff: {overall_mean} (uncertainty: {mean_uncertainty:.2f})\")\n",
    "\n",
    "# print overall mean std\n",
    "overall_std = statistics.mean([axis_diff_dict[axis][\"std_diff\"] for axis in axis_diff_dict])\n",
    "std_uncertainty = overall_std / 2\n",
    "print(f\"std of diffs: {overall_std} (uncertainty: {std_uncertainty:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher mean and std oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try cosine similarity too\n",
    "# compare cosine similarity of original and synthesized embeddings\n",
    "# ❓ question: should we be comparing by axis or word?\n",
    "\n",
    "# try columns first (by axis)\n",
    "# compute cosine similarity for each axis in df_llm and df\n",
    "# store in list\n",
    "axis_cos_sim_list = []\n",
    "\n",
    "# also try by word (row)\n",
    "# compute cosine similarity for each word in df_llm and df\n",
    "# store in list \n",
    "word_cos_sim_list = []\n",
    "\n",
    "for axis in range(len(axis_dict)):\n",
    "    axis_title = f\"axis{axis}\"\n",
    "    axis_cos_sim = cosine_similarity([df_test_llm[axis]], [df_test[axis]])\n",
    "    axis_cos_sim = axis_cos_sim[0][0]\n",
    "    axis_cos_sim_list.append(axis_cos_sim)\n",
    "\n",
    "for word in range(len(df_test_llm)):\n",
    "    # crop rows in df to 10 dimensions\n",
    "    word_cos_sim = cosine_similarity([df_test_llm.iloc[word][1:]], [df_test.iloc[word][1:11]])\n",
    "    word_cos_sim = word_cos_sim[0][0]\n",
    "    word_cos_sim_list.append(word_cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis cos sim avg: -0.16115959248552528\n",
      "word cos sim avg: -0.2006675040543418\n",
      "axis cos sim max: 0.4463631828605409\n",
      "axis cos sim min: -0.5987086488286419\n",
      "axis cos sim std: 0.3029051434591887\n",
      "word cos sim max: 0.3961099288817471\n",
      "word cos sim min: -0.6635811879790965\n",
      "word cos sim std: 0.29855974547635933\n"
     ]
    }
   ],
   "source": [
    "# take average of each list\n",
    "axis_cos_sim_avg = statistics.mean(axis_cos_sim_list)\n",
    "word_cos_sim_avg = statistics.mean(word_cos_sim_list)\n",
    "\n",
    "# print results\n",
    "print(f\"axis cos sim avg: {axis_cos_sim_avg}\")\n",
    "print(f\"word cos sim avg: {word_cos_sim_avg}\")\n",
    "\n",
    "# also print max, min, and std\n",
    "print(f\"axis cos sim max: {max(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim min: {min(axis_cos_sim_list)}\")\n",
    "print(f\"axis cos sim std: {statistics.stdev(axis_cos_sim_list)}\")\n",
    "\n",
    "print(f\"word cos sim max: {max(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim min: {min(word_cos_sim_list)}\")\n",
    "print(f\"word cos sim std: {statistics.stdev(word_cos_sim_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm... yeah the cosine similarity is not great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grouping repeatitive axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial attempts to group axes with semantically similar/redundant interpretations. Here's the prompt I used:\n",
    "\n",
    "```\n",
    "Given this list: \n",
    "# insert here\n",
    "\n",
    "Please produce a dictionary that groups semantically similar/redundant items together. Remember that order matters (the phrase on the left vs. right of \"vs\")-- so even if two items have the similar phrases semantically, unless they appear in the same general order, they shouldn't be grouped together. Your output should look like this:\n",
    "\n",
    "{group 1: [item, item, ...], group 2: [item, item, ...], etc.}\n",
    "\n",
    "But come up with a short phrase to name each group. Try to reduce the number of items in the dictionary from the original list (i.e., since the original list had 10 items, your dictionary should have less).\n",
    "\n",
    "Please briefly explain your groupings at the end. Remember to format your answer as requested above and please make sure the order of phrases matches in your groupings!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "groups = {\n",
    "    \"Traditional vs Modern Art Forms\": [\n",
    "        'traditional or classical art forms and techniques vs modern or contemporary art mediums and practices',\n",
    "        'traditional, physical art mediums and tools vs modern, innovative, conceptual art methods',\n",
    "        'traditional, classic, monochromatic art styles vs modern, innovative, colorful art techniques'\n",
    "    ],\n",
    "    \"Artistic Elements and Movements\": [\n",
    "        'basic, linear, and detailed artistic elements vs bold, expressive, and modern art styles and movements',\n",
    "        'structured, traditional, historical art styles vs imaginative, creative, innovative art expressions',\n",
    "        'realistic, serious, romantic art forms vs vibrant, expressive, satirical art styles'\n",
    "    ],\n",
    "    \"Abstract vs Traditional Art\": [\n",
    "        'abstract, unconventional, avant-garde art vs classical, traditional, technique-focused art styles',\n",
    "        'abstract, modernist, emotionally expressive art vs concrete, traditional, technical art elements'\n",
    "    ],\n",
    "    \"Expression vs Structure in Art\": [\n",
    "        'contemporary, expressive, vibrant art vs structured, subdued, classic art forms',\n",
    "        'modern, innovative, institutional art movements vs classic, personal, traditional art concepts'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes: \n",
    "- groups seem reasonable\n",
    "- ❓ question: do we care about order in the interpretation? e.g., if one axis encodes negative vs. positive and another encodes postive vs. negative, they likely target the same aspect, but in opposite directions.\n",
    "    - i'm currently taking order into account, but could remove that part. \n",
    "    - w/o order, would probably be able to reduce # of groups more(?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946d8ab810ccf0fda35d8421fe75059925cdc2acab76b2b4a2b82ec2be7a9b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
