{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embedding axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>companion</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toast</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lounge</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watch</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.933</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haul</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.423</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      0      1      2      3      4      5      6      7      8  \\\n",
       "0  companion  0.128 -0.082  0.109 -0.012  0.317  0.262 -0.016  0.128  0.357   \n",
       "1      toast  0.209  0.411  0.026 -0.000 -0.243 -0.325  0.148  0.238 -0.120   \n",
       "2     lounge  0.759 -0.116  0.116  0.113  0.460 -0.212  0.115 -0.032  0.137   \n",
       "3      watch  0.401 -0.003 -0.061 -0.406  0.933 -0.140 -0.186  0.286 -0.170   \n",
       "4       haul  0.580  0.031  0.311  0.048 -0.102  0.081  0.047  0.423 -0.187   \n",
       "\n",
       "   ...    758    759    760    761    762    763    764    765    766    767  \n",
       "0  ...  0.395 -0.107 -0.026 -0.061  0.358 -0.138 -0.067  0.236  0.385 -0.115  \n",
       "1  ...  0.373 -0.174  0.119 -0.036  0.445 -0.029  0.145  0.169  0.364 -0.097  \n",
       "2  ...  0.259  0.070 -0.059 -0.114  0.441 -0.096 -0.074  0.196  0.215 -0.254  \n",
       "3  ...  0.459 -0.067 -0.266 -0.318  0.173 -0.109  0.219 -0.010  0.404 -0.161  \n",
       "4  ...  0.505  0.096  0.095 -0.009  0.453  0.003  0.337  0.259  0.064  0.092  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open training_embeddings.csv and load it into a dataframe\n",
    "df = pd.read_csv('training_embeddings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 383 383\n",
      "['companion', 'toast', 'lounge', 'watch', 'haul']\n",
      "[0.128, 0.209, 0.759, 0.401, 0.58]\n"
     ]
    }
   ],
   "source": [
    "def get_x_embedding(df, x):\n",
    "  \"\"\"\n",
    "  Extract the x column from the dataframe and store it as a list\n",
    "  \"\"\"\n",
    "  # Extract the word and x column from the dataframe and store them as a list of lists\n",
    "  # index = 0\n",
    "  words = df['word'].tolist()\n",
    "  emd_index = df[str(x)].tolist()\n",
    "  # data = [[words[i], emd_index[i]] for i in range(len(words))]\n",
    "  # print(data[:5])\n",
    "\n",
    "  # Concatenate the two lists into a list of lists\n",
    "  data = [words,emd_index]\n",
    "  return data\n",
    "\n",
    "data = get_x_embedding(df, 0)\n",
    "print(len(data), len(data[0]), len(data[1]))\n",
    "print(data[0][:5])\n",
    "print(data[1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get axis interpretation from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install OpenAI api\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded.\n"
     ]
    }
   ],
   "source": [
    "# load api key from secrets.json\n",
    "import openai\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open(\"secrets.json\") as f:\n",
    "        secrets = json.load(f)\n",
    "    my_api_key = secrets[\"openai\"]\n",
    "    print(\"API key loaded.\")\n",
    "    openai.api_key = my_api_key\n",
    "except FileNotFoundError:\n",
    "    print(\"Secrets file not found. YOU NEED THEM TO RUN THIS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_emb = get_x_embedding(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"{\\\"Verb or Action Related\\\": 0.7, \\\"Instrument or Tools Associated\\\": 0.6, \\\"Emotion or Feeling Connotated\\\": 0.5}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model_num = \"gpt-3.5-turbo-1106\"\n",
    "# model_num = \"gpt-4-1106-preview\"\n",
    "model_num = \"gpt-4\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=model_num,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert transformer embeddings labeller.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Below are two lists. The first list contains words that have been put into DistilBERT. DistilBERT creates an embedding with 768 dimensions or axes. The second list contains the embedding value from DistilBERT for one axis across the words. By carefully comparing and considering the embedding values for each word, please interpret the likely linguistic feature that this embedding axis encodes. This interpretation must be consistent across all the words and correspond to their respective positive, zero, or negative embedding values.\\n\\n  The output must be a Python dictionary with three items, the key is a string containing the possible interpretation of the axis. The value is a float, representing the confidence score from 0 to 1. \\n\\n Here is an output sample: {{<first interpretation>:<first interpretation confidence score>, <second interpretation>:<second interpretation confidence score>, <third interpretation>:<third interpretation confidence score>}} \\n\\n {axis_emb[0]}\\n\\n {axis_emb[1]}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "\n",
    "# log the stringified output into a txt file by appending it to the end of the file\n",
    "with open(\"output.txt\", \"a\") as f:\n",
    "  f.write(str(completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Verb or Action Related': 0.7, 'Instrument or Tools Associated': 0.6, 'Emotion or Feeling Connotated': 0.5}\n",
      "Verb or Action Related\n"
     ]
    }
   ],
   "source": [
    "# convert the output string into a dictionary\n",
    "interp_dict = eval(completion.choices[0].message.content)\n",
    "print(interp_dict)\n",
    "\n",
    "# convert the dictionary keys into a list\n",
    "interp_keys = list(interp_dict.keys())\n",
    "print(interp_keys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate interpretations using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['companion', 'toast', 'lounge', 'watch', 'haul', 'combination', 'majesty', 'extinguish', 'nutrient', 'bark', 'rest', 'hold', 'drainage', 'chill', 'time', 'drink', 'eat', 'journey', 'surf', 'shipment', 'measure', 'devour', 'cutlery', 'catch', 'drive', 'cooling', 'sail', 'flutter', 'moo', 'descend', 'commute', 'score', 'indulgence', 'cutting', 'containment', 'communication', 'transportation', 'glide', 'slice', 'drying', 'tote', 'nurture', 'breakfast', 'cut', 'throw', 'brush', 'competition', 'signal', 'carry', 'mobility']\n"
     ]
    }
   ],
   "source": [
    "# # test the prompt using smaller set\n",
    "# trunc_word_list = axis_emb[0][:50]\n",
    "# print(trunc_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Step  1  of  13\n",
      "1  Input length:  30\n",
      "[0, 0.65, -0.1, 0.7, 0.8, -0.3, -0.5, 0.8, -0.6, 0.4, 0.6, 0.75, -0.15, 0.65, -0.35, 0.7, 0.9, 0.7, 0.8, -0.2, 0.85, 0.9, -0.6, 0.75, 0.95, -0.6, 0.9, 0.8, -0.45, 0.85]\n",
      "1 Output length:  30\n",
      "1 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  2  of  13\n",
      "2  Input length:  30\n",
      "[1.0, 1.0, -0.5, 1.0, -0.5, 0.2, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8, 0.3, 1.0, 1.0, 1.0, -0.2, 0.5, 1.0, 0.2, 0.8, -0.8, -0.8, -0.5, 1.0, 1.0, 0.9, 0.3, 0, 1.0]\n",
      "2 Output length:  30\n",
      "2 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  3  of  13\n",
      "3  Input length:  30\n",
      "[-1, -1, 0.9, 0.8, -1, 0.2, -1, -1, -1, 1, -0.5, -0.2, -1, 1, -0.5, 0.9, 1, -0.9, 1, -0.9, -1, 1, 1, 1, -0.9, -0.3, 1, 0.8, 1, 1]\n",
      "3 Output length:  30\n",
      "3 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  4  of  13\n",
      "4  Input length:  30\n",
      "[1.0, 1.0, -0.1, 1.0, -0.2, -0.1, 1.0, -0.1, 1.0, 1.0, 1.0, -1.0, -0.7, 0.2, -1.0, 0.7, 1.0, -0.3, 1.0, 1.0, -0.1, 1.0, -0.8, -1.0, -0.8, 0.2, -0.4, -1.0, -1.0, -1.0]\n",
      "4 Output length:  30\n",
      "4 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  5  of  13\n",
      "5  Input length:  30\n",
      "[0, -0.5, 0, -0.3, -0.3, -0.7, 0.8, 0.9, 1, -0.3, 0.8, 0.9, -0.5, 1, 0.9, -0.4, -0.2, 1, 1, -1, -0.6, -0.7, -0.6, -0.8, -0.7, -0.7, -0.8, -0.6, -0.9, -0.9]\n",
      "5 Output length:  30\n",
      "5 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  6  of  13\n",
      "6  Input length:  30\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.2, -0.2, -0.2, -0.3, -0.2, 0.6, 0.7, 0.7, 0.5, 0.6, 0.8, 0.7, 0.7, 0.8, 0.8, -0.4, -0.4]\n",
      "6 Output length:  30\n",
      "6 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  7  of  13\n",
      "7  Input length:  30\n",
      "7 Error:  Here is the scoring for each word in the provided list according to the criteria - 'Verb or Action Related':\n",
      "\n",
      "[-0.9 , -0.9, -0.9, -0.8, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.7, -0.9, -0.9, -0.9, -0.9, -0.1, 0.1, 0.1, 0.1, 0.2, -0.6, -0.6, -0.6]\n",
      "\n",
      "The negatives represent an opposite relation to the given criteria. These are all items and not verbs or actions. A few items towards the end may somehow be related to a verb or action; hence, they have slightly higher scores but are still very much on the negative side.\n",
      "Trying again...\n",
      "\n",
      "\n",
      "Step  7  of  13\n",
      "7  Input length:  30\n",
      "7 Error:  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1] \n",
      "\n",
      "This score is assigned based on the listed items all being physical objects or nouns rather than actions or verbs. Thus, they are not highly correlated with the criteria 'Verb or Action Related'.\n",
      "Trying again...\n",
      "\n",
      "\n",
      "Step  7  of  13\n",
      "7  Input length:  30\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "7 Output length:  30\n",
      "7 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  8  of  13\n",
      "8  Input length:  30\n",
      "8 Error:  [1.0, -1.0, -1.0, -1.0, -1.0, 0.5, -1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
      "\n",
      "The verb or action-related words or items in the list are 'sink' (as in, to sink), 'scissors' (as in, to cut with scissors), 'hair drier' (as in, to dry hair), and 'toothbrush' (as in, to brush teeth). Most of the other things are either objects or punctuation marks, which do not perform actions.\n",
      "Trying again...\n",
      "\n",
      "\n",
      "Step  8  of  13\n",
      "8  Input length:  30\n",
      "[1, -1, -0.2, -1, -1, 0.8, -0.5, 0.7, 0.5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.4, -0.4, -0.4, -0.4, -1, -1]\n",
      "8 Output length:  30\n",
      "8 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  9  of  13\n",
      "9  Input length:  30\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "9 Output length:  30\n",
      "9 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  10  of  13\n",
      "10  Input length:  30\n",
      "[-1, -1, 0.8, 0.8, 0.8, 0.9, 0.9, -1, -1, -1, -1, 0.7, -1, -1, -1, -1, -1, -1, 0.5, -1, -1, -1, -1, 0.1, 0.2, -1, 0.3, -1, -1, -1]\n",
      "10 Output length:  30\n",
      "10 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  11  of  13\n",
      "11  Input length:  30\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0.5, -1, -1, -1, -1, -1, -1, -1, 0.7, -1, -1, -1, 1, 1, 1, 1, -1]\n",
      "11 Output length:  30\n",
      "11 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  12  of  13\n",
      "12  Input length:  30\n",
      "[-1, 0.5, 0.5, 0.5, -1, -1, -1, 1, 1, 1, 1, 0.5, 0.8, 0.8, 0.8, 1, 0.4, 0.4, 1, 1, 1, 0.8, 0.7, 1, 0.3, 0.3, 0.8, 1, 0.5, 1]\n",
      "12 Output length:  30\n",
      "12 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  13  of  13\n",
      "13  Input length:  23\n",
      "[0.1, 0.1, 0.3, 0.6, 0.1, 0.6, -0.3, -0.3, -0.3, -0.3, -0.3, 0.2, 0.2, -0.3, -0.3, -0.3, 0.2, 0.2, 0.4, 0.2, 0.2, -0.5, -0.5]\n",
      "13 Output length:  23\n",
      "13 Are input output lengths the same?  True\n",
      "Length of embedding list:  383\n",
      "Length of score list:  383\n"
     ]
    }
   ],
   "source": [
    "# model_num = \"gpt-3.5-turbo-1106\"\n",
    "# model_num = \"gpt-4-1106-preview\"\n",
    "model_num = \"gpt-4\"\n",
    "\n",
    "score_list = []\n",
    "step = 30\n",
    "\n",
    "for i in range((len(axis_emb[0])// step )+ 1):\n",
    "  # test to make sure the list is being truncated correctly\n",
    "  # print(i*step, (i+1)*step)\n",
    "  trunc_word_list = axis_emb[0][i*step:(i+1)*step]\n",
    "  # print(trunc_word_list)\n",
    "  # print(len(trunc_word_list))\n",
    "\n",
    "  is_length_correct = False\n",
    "\n",
    "  while (is_length_correct == False):\n",
    "    print(\"\\n\\nStep \", i + 1, \" of \", (len(axis_emb[0])// step )+ 1)\n",
    "    print(i+1, \" Input length: \", len(trunc_word_list))\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=model_num,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert word sense scorer.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"For the list of words below, please assign it a score according to how much it relates to the following criteria: '{interp_keys[0]}' \\n\\n  The output must be a Python list of scores for each corresponding word in the provided list. The output must therefore have {len(trunc_word_list)} items, the length as the provided list. The score is a float that ranges from -1 to 1. Positive scores suggest a high correlation to the criteria, while negative scores suggest a high opposite correlation. Scores closer to 0 suggest that the criterion is not applicable to the word. \\n\\n Here is an output sample: [<score for first word>, <score for second word>, ... , <score for second-last word>, <score for last word>] \\n\\n {trunc_word_list}\"}\n",
    "        # {\"role\": \"user\", \"content\": f\"For the list of words below, please assign it a score according to how much it relates to the following criteria: {interp_keys[0]}  \\n\\n  The output must be a Python list of scores for each corresponding word in the provided list. The output must therefore have the same number of items as the provided list. The score is a float that ranges from -1 to 1. Positive scores suggest a high correlation to the criteria, while negative scores suggest a high opposite correlation. Scores closer to 0 suggest that the criterion is not applicable to the word. \\n\\n Here is an output sample: [<score for first word>, <score for second word>, ... , <score for second-last word>, <score for last word>] \\n\\n {axis_emb[0]}\"}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    # print(completion.choices[0].message)\n",
    "\n",
    "    # log the stringified output into a txt file by appending it to the end of the file\n",
    "    with open(\"eval_output.txt\", \"a\") as f:\n",
    "      f.write(str(completion))\n",
    "\n",
    "    # convert the output string into a list\n",
    "    try:\n",
    "      scores = eval(completion.choices[0].message.content)\n",
    "    except:\n",
    "      print(i+1, \"Error: \", completion.choices[0].message.content)\n",
    "      print(\"Trying again...\")\n",
    "      continue\n",
    "    print(scores)\n",
    "\n",
    "    # check if the length is correct\n",
    "    print(i+1, \"Output length: \", len(scores))\n",
    "    print(i+1, \"Are input output lengths the same? \" ,len(scores) == len(trunc_word_list))\n",
    "\n",
    "    if len(scores) == len(trunc_word_list):\n",
    "      is_length_correct = True\n",
    "    else:\n",
    "      print(\"Input output lengths are not the same. Trying again...\")\n",
    "      continue\n",
    "\n",
    "    # concatenate scores with score_list\n",
    "    score_list += scores\n",
    "\n",
    "    # giving it more time â€“ does it lead to better results?\n",
    "    time.sleep(10)\n",
    "\n",
    "with open(\"eval_output.txt\", \"a\") as f:\n",
    "  f.write(\"\\nscore_list: \" + str(score_list))\n",
    "print(\"Length of embedding list: \", len(axis_emb[0]))\n",
    "print(\"Length of score list: \", len(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.128, 0.44100000000000006, -0.859, 0.29899999999999993, 0.22000000000000008]\n",
      "Sum of diff:  284.1839999999997\n",
      "Mean of diff:  0.7419947780678843\n"
     ]
    }
   ],
   "source": [
    "# compare score_list with axis_emb[1] by subtracting them\n",
    "diff_list = [score_list[i] - axis_emb[1][i] for i in range(len(score_list))]\n",
    "print(diff_list[:5])\n",
    "\n",
    "# abs and round the difference list to 3 decimal places\n",
    "diff_list = [abs(round(diff, 3)) for diff in diff_list]\n",
    "\n",
    "# sum the difference list\n",
    "sum_diff = sum(diff_list)\n",
    "print(\"Sum of diff: \", sum_diff)\n",
    "\n",
    "# calculate the mean of the difference list\n",
    "mean_diff = sum(diff_list)/len(diff_list)\n",
    "print(\"Mean of diff: \", mean_diff)\n",
    "\n",
    "with open(\"eval_output.txt\", \"a\") as f:\n",
    "  f.write(\"\\ndiff_list: \" + str(diff_list) + \"\\nsum of diff: \" + str(sum_diff) + \"\\nmean of diff: \" + str(mean_diff) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- mean difference of 0.74 is unacceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between two runs + evaluating the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first run:  383\n",
      "Length of second run:  383\n",
      "[0.0, 0.05, 0.2, 0.1, 0.0, 0.1, 0.4, 0.1, 0.3, 0.3, 0.0, 0.05, 0.05, 0.05, 0.35, 0.0, 0.1, 0.1, 0.0, 0.7, 0.15, 0.1, 0.3, 0.15, 0.05, 0.3, 0.1, 0.1, 0.75, 0.15, 0.1, 0.2, 0.0, 0.2, 0.1, 0.0, 0.1, 0.1, 0.1, 0.4, 0.2, 0.4, 0.2, 0.0, 0.0, 0.1, 0.4, 0.1, 0.1, 0.1, 0.4, 0.0, 0.1, 0.1, 0.2, 0.1, 0.2, 0.0, 0.1, 0.4, 1.1, 0.8, 0.2, 0.1, 0.4, 0.0, 0.7, 0.6, 0.7, 0.0, 0.3, 0.1, 0.7, 0.0, 0.7, 0.2, 0.0, 0.4, 0.0, 0.3, 0.9, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6, 0.4, 0.8, 0.3, 0.0, 0.0, 0.0, 0.1, 0.1, 0.6, 0.0, 0.5, 0.0, 0.5, 0.0, 0.4, 0.2, 0.0, 0.1, 0.0, 0.1, 0.4, 0.0, 0.0, 0.0, 0.0, 0.2, 0.1, 0.1, 0.8, 0.0, 0.3, 0.0, 0.2, 0.05, 0.2, 0.1, 0.05, 0.25, 0.05, 0.2, 0.2, 0.8, 0.05, 0.2, 0.2, 0.4, 0.6, 0.5, 0.65, 0.53, 0.58, 0.78, 0.58, 0.05, 0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8, 0.8, 0.8, 0.7, 0.8, 0.4, 0.2, 0.2, 0.2, 0.3, 0.4, 0.3, 0.1, 0.2, 0.3, 0.1, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.2, 0.2, 0.0, 0.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.0, 0.0, 1, 1, 1, 1.7, 0.7, 1, 1, 1, 1, 1, 1, 0.5, 1, 1, 1, 1, 0.1, 0.2, 1, 0.3, 1.75, 1.75, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.4, 0.3, 0.3, 0.4, 1.7, 0, 0.2, 0.2, 0.2, 0, 0, 0, 0, 0, 0, 0, 0.5, 0.2, 0.2, 0.2, 0, 0.2, 0.2, 0, 0, 0, 0.2, 0.3, 0, 0.3, 0.3, 0.2, 0, 0.5, 0, 0.7, 0.6, 0.5, 0.3, 0.6, 0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.1, 0.1, 0.0, 0.3, 0.3, 0.1, 0.3, 0.3, 0.5, 0.5]\n",
      "Sum of diff between two runs:  135.37\n",
      "Mean of diff between two runs:  0.35344647519582245\n"
     ]
    }
   ],
   "source": [
    "# compare between two runs\n",
    "\n",
    "first_run = [0.0, 0.7, -0.3, 0.6, 0.8, -0.2, -0.9, 0.9, -0.9, 0.7, 0.6, 0.8, -0.1, 0.7, 0.0, 0.7, 0.8, 0.8, 0.8, 0.5, 0.7, 1.0, -0.3, 0.9, 0.9, -0.3, 0.8, 0.7, 0.3, 1.0, 0.9, 0.8, -0.5, 0.8, -0.4, 0.2, 0.6, 0.9, 0.9, 0.6, 0.8, 0.4, 0.1, 1.0, 1.0, 0.9, 0.2, 0.6, 0.9, 0.1, 0.4, -0.8, -0.9, -0.4, 0.8, 0.9, 0.7, 0.3, 0.1, 0.6, 0.1, -0.2, 0.7, 0.7, -0.6, 0.2, -0.3, -0.4, -0.3, 1.0, -0.2, -0.1, -0.3, 1.0, 0.2, 0.7, 1.0, -0.5, 1.0, -0.6, -0.1, 1.0, 1.0, 1.0, 0.1, 0.2, 1.0, 0.6, 0.8, 1.0, 1.0, 1.0, -0.6, 1.0, -0.8, -0.5, 0.2, -0.4, 1.0, 1.0, 1.0, -0.9, -0.6, -0.4, -1.0, 0.2, 1.0, -0.8, 1.0, 0.6, -0.3, 1.0, -0.9, -1.0, -0.7, 0.6, -0.4, -1.0, -1.0, -1.0, -0.2, -0.4, -0.1, 0.5, -0.3, -0.4, 0.8, 0.7, 0.95, -0.5, 0.9, 0.85, -0.25, 0.95, 0.7, -0.2, 0.6, 0.95, 0.8, -0.8, -0.2, -0.1, -0.1, -0.15, -0.17, -0.12, -0.02, -0.02, -0.85, -0.95, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0.2, 0.5, 0.5, 0.3, 0.3, 0.4, 0.4, 0.6, 0.6, 0.5, -0.5, -0.5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1.0, -1.0, -0.5, -1.0, -1.0, 0.8, -0.8, 1.0, 0.8, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -0.2, -0.2, -1.0, -1.0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0.9, 0.9, 0.9, 0.9, 0.9, 0, 0, 0, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.75, 0.75, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.6, 0.7, 0.7, 0.6, 0.7, -1, 0.3, 0.3, 0.3, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.6, 0.6, 1, 1, 1, 1, 1, 1, 0.6, 0.6, 1, 1, 1, 1, 0.8, 0.7, 0.8, 0.9, 0.7, 0.9, -0.2, -0.2, -0.2, -0.2, -0.2, -0.1, -0.1, -0.2, -0.2, -0.3, -0.1, -0.1, 0.3, -0.1, -0.1, -1, -1]\n",
    "second_run = [0, 0.65, -0.1, 0.7, 0.8, -0.3, -0.5, 0.8, -0.6, 0.4, 0.6, 0.75, -0.15, 0.65, -0.35, 0.7, 0.9, 0.7, 0.8, -0.2, 0.85, 0.9, -0.6, 0.75, 0.95, -0.6, 0.9, 0.8, -0.45, 0.85, 1.0, 1.0, -0.5, 1.0, -0.5, 0.2, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8, 0.3, 1.0, 1.0, 1.0, -0.2, 0.5, 1.0, 0.2, 0.8, -0.8, -0.8, -0.5, 1.0, 1.0, 0.9, 0.3, 0, 1.0, -1, -1, 0.9, 0.8, -1, 0.2, -1, -1, -1, 1, -0.5, -0.2, -1, 1, -0.5, 0.9, 1, -0.9, 1, -0.9, -1, 1, 1, 1, -0.9, -0.3, 1, 0.8, 1, 1, 1.0, 1.0, -0.1, 1.0, -0.2, -0.1, 1.0, -0.1, 1.0, 1.0, 1.0, -1.0, -0.7, 0.2, -1.0, 0.7, 1.0, -0.3, 1.0, 1.0, -0.1, 1.0, -0.8, -1.0, -0.8, 0.2, -0.4, -1.0, -1.0, -1.0, 0, -0.5, 0, -0.3, -0.3, -0.7, 0.8, 0.9, 1, -0.3, 0.8, 0.9, -0.5, 1, 0.9, -0.4, -0.2, 1, 1, -1, -0.6, -0.7, -0.6, -0.8, -0.7, -0.7, -0.8, -0.6, -0.9, -0.9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.2, -0.2, -0.2, -0.3, -0.2, 0.6, 0.7, 0.7, 0.5, 0.6, 0.8, 0.7, 0.7, 0.8, 0.8, -0.4, -0.4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -0.2, -1, -1, 0.8, -0.5, 0.7, 0.5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.4, -0.4, -0.4, -0.4, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0.8, 0.8, 0.8, 0.9, 0.9, -1, -1, -1, -1, 0.7, -1, -1, -1, -1, -1, -1, 0.5, -1, -1, -1, -1, 0.1, 0.2, -1, 0.3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0.5, -1, -1, -1, -1, -1, -1, -1, 0.7, -1, -1, -1, 1, 1, 1, 1, -1, -1, 0.5, 0.5, 0.5, -1, -1, -1, 1, 1, 1, 1, 0.5, 0.8, 0.8, 0.8, 1, 0.4, 0.4, 1, 1, 1, 0.8, 0.7, 1, 0.3, 0.3, 0.8, 1, 0.5, 1, 0.1, 0.1, 0.3, 0.6, 0.1, 0.6, -0.3, -0.3, -0.3, -0.3, -0.3, 0.2, 0.2, -0.3, -0.3, -0.3, 0.2, 0.2, 0.4, 0.2, 0.2, -0.5, -0.5]\n",
    "\n",
    "print(\"Length of first run: \", len(first_run))\n",
    "print(\"Length of second run: \", len(second_run)) \n",
    "\n",
    "diff_run_list = [first_run[i] - second_run[i] for i in range(len(first_run))]\n",
    "\n",
    "# abs and round the difference list to 3 decimal places\n",
    "diff_run_list = [abs(round(diff, 3)) for diff in diff_run_list]\n",
    "print(diff_run_list)\n",
    "\n",
    "sum_diff_run = sum(diff_run_list)\n",
    "print(\"Sum of diff between two runs: \", sum_diff_run)\n",
    "mean_diff_run = sum(diff_run_list)/len(diff_run_list)\n",
    "print(\"Mean of diff between two runs: \", mean_diff_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- 0.35 difference between 2 runs seems ok but it can probably be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word  embedding  score\n",
      "0  companion      0.128    0.0\n",
      "1      toast      0.209    0.7\n",
      "2     lounge      0.759   -0.3\n",
      "3      watch      0.401    0.6\n",
      "4       haul      0.580    0.8\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of words, embedding values, and scores\n",
    "df = pd.DataFrame({'word': axis_emb[0], 'embedding': axis_emb[1], 'score': first_run})\n",
    "print(df.head())\n",
    "\n",
    "# save dataframe as csv\n",
    "df.to_csv('llm-outputs/first_run.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word  embedding  score\n",
      "0  companion      0.128   0.00\n",
      "1      toast      0.209   0.65\n",
      "2     lounge      0.759  -0.10\n",
      "3      watch      0.401   0.70\n",
      "4       haul      0.580   0.80\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of words, embedding values, and scores\n",
    "df = pd.DataFrame({'word': axis_emb[0], 'embedding': axis_emb[1], 'score': second_run})\n",
    "print(df.head())\n",
    "\n",
    "# save dataframe as csv\n",
    "df.to_csv('llm-outputs/second_run.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- it seems like the results are somewhat repeatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health |( 0.1 ) - ( -1 )| = 1.1\n",
      "entertainment |( -0.2 ) - ( -1 )| = 0.8\n",
      "reflection |( -0.1 ) - ( -1 )| = 0.9\n",
      "grace |( 0.1 ) - ( -0.9 )| = 1.0\n",
      "heating |( 0.2 ) - ( 1.0 )| = 0.8\n",
      "dry |( 0.5 ) - ( -0.3 )| = 0.8\n",
      "prong |( 0.6 ) - ( -0.2 )| = 0.8\n",
      "truck |( -0.02 ) - ( -0.8 )| = 0.78\n",
      "backpack |( -1 ) - ( -0.2 )| = 0.8\n",
      "umbrella |( -1 ) - ( -0.2 )| = 0.8\n",
      "handbag |( -1 ) - ( -0.2 )| = 0.8\n",
      "suitcase |( -1 ) - ( -0.2 )| = 0.8\n",
      "one |( -1 ) - ( 0 )| = 1\n",
      "two |( -1 ) - ( 0 )| = 1\n",
      "10 |( -1 ) - ( 0 )| = 1\n",
      "the |( -1 ) - ( 0 )| = 1\n",
      "a |( -1 ) - ( 0 )| = 1\n",
      "The |( -1 ) - ( 0 )| = 1\n",
      "an |( -1 ) - ( 0 )| = 1\n",
      "this |( -1 ) - ( 0 )| = 1\n",
      "there |( -1 ) - ( 0 )| = 1\n",
      "There |( -1 ) - ( 0 )| = 1\n",
      "Perestroika |( -1 ) - ( 0 )| = 1\n",
      "besuboru |( -1 ) - ( 0 )| = 1\n",
      "de |( -1 ) - ( 0 )| = 1\n",
      "etc. |( -1 ) - ( 0 )| = 1\n",
      "of |( -1 ) - ( 0 )| = 1\n",
      "for |( -1 ) - ( 0 )| = 1\n",
      "on |( -1 ) - ( 0 )| = 1\n",
      "new |( -1 ) - ( 0 )| = 1\n",
      "other |( -1 ) - ( 0 )| = 1\n",
      "last |( -1 ) - ( 0 )| = 1\n",
      "many |( -1 ) - ( 0 )| = 1\n",
      "higher |( -1 ) - ( 0 )| = 1\n",
      "lower |( -1 ) - ( 0 )| = 1\n",
      "largest |( -1 ) - ( 0 )| = 1\n",
      "least |( -1 ) - ( 0 )| = 1\n",
      "latest |( -1 ) - ( 0 )| = 1\n",
      "best |( -1 ) - ( 0 )| = 1\n",
      "1 |( -1 ) - ( 0 )| = 1\n",
      "2 |( -1 ) - ( 0 )| = 1\n",
      "3 |( -1 ) - ( 0 )| = 1\n",
      "4 |( 0 ) - ( -1 )| = 1\n",
      "5 |( 0 ) - ( -1 )| = 1\n",
      "% |( 0 ) - ( -1 )| = 1\n",
      "company |( 0 ) - ( -1 )| = 1\n",
      "year |( 0 ) - ( -1 )| = 1\n",
      "market |( 0.7 ) - ( -1 )| = 1.7\n",
      "Mr. |( 0 ) - ( -1 )| = 1\n",
      "U.S. |( 0 ) - ( -1 )| = 1\n",
      "New |( 0 ) - ( -1 )| = 1\n",
      "Corp. |( 0 ) - ( -1 )| = 1\n",
      "York |( 0 ) - ( -1 )| = 1\n",
      "Containers |( 0 ) - ( -1 )| = 1\n",
      "Industries |( 0 ) - ( -1 )| = 1\n",
      "Materials |( 0 ) - ( -1 )| = 1\n",
      "Soviets |( 0 ) - ( -1 )| = 1\n",
      "years |( 0 ) - ( -1 )| = 1\n",
      "cents |( 0 ) - ( -1 )| = 1\n",
      "all |( 0.75 ) - ( -1 )| = 1.75\n",
      "such |( 0.75 ) - ( -1 )| = 1.75\n",
      "half |( 0 ) - ( -1 )| = 1\n",
      "Such |( 0.0 ) - ( -1 )| = 1.0\n",
      "All |( 0.0 ) - ( -1 )| = 1.0\n",
      "' |( 0.0 ) - ( -1 )| = 1.0\n",
      "it |( 0.0 ) - ( -1 )| = 1.0\n",
      "he |( 0.0 ) - ( -1 )| = 1.0\n",
      "they |( 0.0 ) - ( -1 )| = 1.0\n",
      "I |( 0.0 ) - ( -1 )| = 1.0\n",
      "It |( 0.0 ) - ( -1 )| = 1.0\n",
      "its |( 0.0 ) - ( -1 )| = 1.0\n",
      "their |( 0.0 ) - ( -1 )| = 1.0\n",
      "his |( 0.0 ) - ( -1 )| = 1.0\n",
      "her |( 0.0 ) - ( -1 )| = 1.0\n",
      "our |( 0.0 ) - ( -1 )| = 1.0\n",
      "n't |( -0.7 ) - ( 0.5 )| = 1.2\n",
      "also |( 0.0 ) - ( -1 )| = 1.0\n",
      "not |( 0.0 ) - ( -1 )| = 1.0\n",
      "only |( 0.0 ) - ( -1 )| = 1.0\n",
      "even |( 0.0 ) - ( -1 )| = 1.0\n",
      "more |( 0.0 ) - ( -1 )| = 1.0\n",
      "earlier |( 0.0 ) - ( -1 )| = 1.0\n",
      "less |( 0.0 ) - ( -1 )| = 1.0\n",
      "longer |( 0.0 ) - ( -1 )| = 1.0\n",
      "most |( 0.0 ) - ( -1 )| = 1.0\n",
      "Most |( 0.0 ) - ( -1 )| = 1.0\n",
      "down |( 0.7 ) - ( -1 )| = 1.7\n",
      "Number of words with a difference of more than 0.5 (not confident):  87 of 383\n",
      "Percentage:  23 %\n"
     ]
    }
   ],
   "source": [
    "# surface words from axis_emb[0] that have a difference of more than 0.5\n",
    "len_a = 0\n",
    "for i in range(len(diff_run_list)):\n",
    "  if diff_run_list[i] > 0.75:\n",
    "    print(axis_emb[0][i], \"|(\", first_run[i], \")\", \"-\", \"(\", second_run[i], \")|\", \"=\", diff_run_list[i])\n",
    "    len_a += 1\n",
    "\n",
    "print(\"Number of words with a difference of more than 0.5 (not confident): \", len_a, \"of\", len(diff_run_list))\n",
    "print(\"Percentage: \", round(len_a/len(diff_run_list) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- my hunch is that GPT is struggling to differentiate between opposite (-1) and irrelevant (0). maybe this can be simplified or strengthened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companion |( 0.0 ) - ( 0 )| = 0.0\n",
      "toast |( 0.7 ) - ( 0.65 )| = 0.05\n",
      "lounge |( -0.3 ) - ( -0.1 )| = 0.2\n",
      "watch |( 0.6 ) - ( 0.7 )| = 0.1\n",
      "haul |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "combination |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "extinguish |( 0.9 ) - ( 0.8 )| = 0.1\n",
      "rest |( 0.6 ) - ( 0.6 )| = 0.0\n",
      "hold |( 0.8 ) - ( 0.75 )| = 0.05\n",
      "drainage |( -0.1 ) - ( -0.15 )| = 0.05\n",
      "chill |( 0.7 ) - ( 0.65 )| = 0.05\n",
      "drink |( 0.7 ) - ( 0.7 )| = 0.0\n",
      "eat |( 0.8 ) - ( 0.9 )| = 0.1\n",
      "journey |( 0.8 ) - ( 0.7 )| = 0.1\n",
      "surf |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "measure |( 0.7 ) - ( 0.85 )| = 0.15\n",
      "devour |( 1.0 ) - ( 0.9 )| = 0.1\n",
      "catch |( 0.9 ) - ( 0.75 )| = 0.15\n",
      "drive |( 0.9 ) - ( 0.95 )| = 0.05\n",
      "sail |( 0.8 ) - ( 0.9 )| = 0.1\n",
      "flutter |( 0.7 ) - ( 0.8 )| = 0.1\n",
      "descend |( 1.0 ) - ( 0.85 )| = 0.15\n",
      "commute |( 0.9 ) - ( 1.0 )| = 0.1\n",
      "score |( 0.8 ) - ( 1.0 )| = 0.2\n",
      "indulgence |( -0.5 ) - ( -0.5 )| = 0.0\n",
      "cutting |( 0.8 ) - ( 1.0 )| = 0.2\n",
      "containment |( -0.4 ) - ( -0.5 )| = 0.1\n",
      "communication |( 0.2 ) - ( 0.2 )| = 0.0\n",
      "transportation |( 0.6 ) - ( 0.5 )| = 0.1\n",
      "glide |( 0.9 ) - ( 1.0 )| = 0.1\n",
      "slice |( 0.9 ) - ( 1.0 )| = 0.1\n",
      "tote |( 0.8 ) - ( 1.0 )| = 0.2\n",
      "breakfast |( 0.1 ) - ( 0.3 )| = 0.2\n",
      "cut |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "throw |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "brush |( 0.9 ) - ( 1.0 )| = 0.1\n",
      "signal |( 0.6 ) - ( 0.5 )| = 0.1\n",
      "carry |( 0.9 ) - ( 1.0 )| = 0.1\n",
      "mobility |( 0.1 ) - ( 0.2 )| = 0.1\n",
      "conformity |( -0.8 ) - ( -0.8 )| = 0.0\n",
      "Thanksgiving |( -0.9 ) - ( -0.8 )| = 0.1\n",
      "comfort |( -0.4 ) - ( -0.5 )| = 0.1\n",
      "call |( 0.8 ) - ( 1.0 )| = 0.2\n",
      "soar |( 0.9 ) - ( 1.0 )| = 0.1\n",
      "pause |( 0.7 ) - ( 0.9 )| = 0.2\n",
      "input |( 0.3 ) - ( 0.3 )| = 0.0\n",
      "hygiene |( 0.1 ) - ( 0 )| = 0.1\n",
      "halt |( 0.7 ) - ( 0.9 )| = 0.2\n",
      "crunch |( 0.7 ) - ( 0.8 )| = 0.1\n",
      "control |( 0.2 ) - ( 0.2 )| = 0.0\n",
      "gallop |( 1.0 ) - ( 1 )| = 0.0\n",
      "gathering |( -0.1 ) - ( -0.2 )| = 0.1\n",
      "walk |( 1.0 ) - ( 1 )| = 0.0\n",
      "purr |( 0.7 ) - ( 0.9 )| = 0.2\n",
      "sip |( 1.0 ) - ( 1 )| = 0.0\n",
      "bite |( 1.0 ) - ( 1 )| = 0.0\n",
      "rinse |( 1.0 ) - ( 1 )| = 0.0\n",
      "uncork |( 1.0 ) - ( 1 )| = 0.0\n",
      "skate |( 1.0 ) - ( 1 )| = 0.0\n",
      "scoop |( 1.0 ) - ( 1 )| = 0.0\n",
      "tick |( 0.6 ) - ( 0.8 )| = 0.2\n",
      "flight |( 0.8 ) - ( 1 )| = 0.2\n",
      "type |( 1.0 ) - ( 1 )| = 0.0\n",
      "read |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "bake |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "poke |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "consume |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "fly |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "hug |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "knowledge |( -0.9 ) - ( -1.0 )| = 0.1\n",
      "shield |( -0.6 ) - ( -0.7 )| = 0.1\n",
      "solitude |( -1.0 ) - ( -1.0 )| = 0.0\n",
      "fasten |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "hit |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "adventure |( -0.3 ) - ( -0.1 )| = 0.2\n",
      "peel |( 1.0 ) - ( 1.0 )| = 0.0\n",
      "song |( -0.9 ) - ( -0.8 )| = 0.1\n",
      "elegance |( -1.0 ) - ( -1.0 )| = 0.0\n",
      "recreation |( -0.7 ) - ( -0.8 )| = 0.1\n",
      "trumpet |( -0.4 ) - ( -0.4 )| = 0.0\n",
      "container |( -1.0 ) - ( -1.0 )| = 0.0\n",
      "aroma |( -1.0 ) - ( -1.0 )| = 0.0\n",
      "childhood |( -1.0 ) - ( -1.0 )| = 0.0\n",
      "measurement |( -0.2 ) - ( 0 )| = 0.2\n",
      "sanitation |( -0.4 ) - ( -0.5 )| = 0.1\n",
      "vibration |( -0.1 ) - ( 0 )| = 0.1\n",
      "growth |( -0.3 ) - ( -0.3 )| = 0.0\n",
      "swing |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "crave |( 0.7 ) - ( 0.9 )| = 0.2\n",
      "ride |( 0.95 ) - ( 1 )| = 0.05\n",
      "sharpness |( -0.5 ) - ( -0.3 )| = 0.2\n",
      "stride |( 0.9 ) - ( 0.8 )| = 0.1\n",
      "graze |( 0.85 ) - ( 0.9 )| = 0.05\n",
      "sit |( 0.95 ) - ( 1 )| = 0.05\n",
      "indulge |( 0.7 ) - ( 0.9 )| = 0.2\n",
      "acidity |( -0.2 ) - ( -0.4 )| = 0.2\n",
      "chop |( 0.95 ) - ( 1 )| = 0.05\n",
      "munch |( 0.8 ) - ( 1 )| = 0.2\n",
      "person |( -0.8 ) - ( -1 )| = 0.2\n",
      "traffic light |( -0.85 ) - ( -0.9 )| = 0.05\n",
      "fire hydrant |( -0.95 ) - ( -0.9 )| = 0.05\n",
      "stop sign |( -1 ) - ( -1 )| = 0\n",
      "parking meter |( -1 ) - ( -1 )| = 0\n",
      "bench |( -1 ) - ( -1 )| = 0\n",
      "bird |( -1 ) - ( -1 )| = 0\n",
      "cat |( -1 ) - ( -1 )| = 0\n",
      "dog |( -1 ) - ( -1 )| = 0\n",
      "horse |( -1 ) - ( -1 )| = 0\n",
      "sheep |( -1 ) - ( -1 )| = 0\n",
      "cow |( -1 ) - ( -1 )| = 0\n",
      "elephant |( -1 ) - ( -1 )| = 0\n",
      "bear |( -1 ) - ( -1 )| = 0\n",
      "zebra |( -1 ) - ( -1 )| = 0\n",
      "giraffe |( -1 ) - ( -1 )| = 0\n",
      "skis |( 0.5 ) - ( 0.7 )| = 0.2\n",
      "snowboard |( 0.5 ) - ( 0.7 )| = 0.2\n",
      "sports ball |( 0.3 ) - ( 0.5 )| = 0.2\n",
      "skateboard |( 0.6 ) - ( 0.7 )| = 0.1\n",
      "surfboard |( 0.6 ) - ( 0.8 )| = 0.2\n",
      "bottle |( -0.5 ) - ( -0.4 )| = 0.1\n",
      "wine glass |( -0.5 ) - ( -0.4 )| = 0.1\n",
      "cup |( -1 ) - ( -1 )| = 0\n",
      "fork |( -1 ) - ( -1 )| = 0\n",
      "knife |( -1 ) - ( -1 )| = 0\n",
      "spoon |( -1 ) - ( -1 )| = 0\n",
      "bowl |( -1 ) - ( -1 )| = 0\n",
      "banana |( -1 ) - ( -1 )| = 0\n",
      "apple |( -1 ) - ( -1 )| = 0\n",
      "sandwich |( -1 ) - ( -1 )| = 0\n",
      "orange |( -1 ) - ( -1 )| = 0\n",
      "broccoli |( -1 ) - ( -1 )| = 0\n",
      "carrot |( -1 ) - ( -1 )| = 0\n",
      "hot dog |( -1 ) - ( -1 )| = 0\n",
      "pizza |( -1 ) - ( -1 )| = 0\n",
      "donut |( -1 ) - ( -1 )| = 0\n",
      "cake |( -1 ) - ( -1 )| = 0\n",
      "chair |( -1 ) - ( -1 )| = 0\n",
      "couch |( -1 ) - ( -1 )| = 0\n",
      "potted plant |( -1 ) - ( -1 )| = 0\n",
      "bed |( -1 ) - ( -1 )| = 0\n",
      "dining table |( -1 ) - ( -1 )| = 0\n",
      "toilet |( -1 ) - ( -1 )| = 0\n",
      "tv |( -1 ) - ( -1 )| = 0\n",
      "laptop |( -1 ) - ( -1 )| = 0\n",
      "mouse |( -1 ) - ( -1 )| = 0\n",
      "remote |( -1 ) - ( -1 )| = 0\n",
      "keyboard |( -1 ) - ( -1 )| = 0\n",
      "cell phone |( -1 ) - ( -1 )| = 0\n",
      "microwave |( -1 ) - ( -1 )| = 0\n",
      "oven |( -1 ) - ( -1 )| = 0\n",
      "toaster |( -1 ) - ( -1 )| = 0\n",
      "sink |( 1.0 ) - ( 1 )| = 0.0\n",
      "refrigerator |( -1.0 ) - ( -1 )| = 0.0\n",
      "clock |( -1.0 ) - ( -1 )| = 0.0\n",
      "vase |( -1.0 ) - ( -1 )| = 0.0\n",
      "scissors |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "# |( -1.0 ) - ( -1 )| = 0.0\n",
      "$ |( -1.0 ) - ( -1 )| = 0.0\n",
      "US$ |( -1.0 ) - ( -1 )| = 0.0\n",
      "C$ |( -1.0 ) - ( -1 )| = 0.0\n",
      "'' |( -1.0 ) - ( -1 )| = 0.0\n",
      ", |( -1.0 ) - ( -1 )| = 0.0\n",
      "Wa |( -1.0 ) - ( -1 )| = 0.0\n",
      ". |( -1.0 ) - ( -1 )| = 0.0\n",
      "? |( -1.0 ) - ( -1 )| = 0.0\n",
      "! |( -1.0 ) - ( -1 )| = 0.0\n",
      "-- |( -1.0 ) - ( -1 )| = 0.0\n",
      "; |( -1.0 ) - ( -1 )| = 0.0\n",
      ": |( -1.0 ) - ( -1 )| = 0.0\n",
      "... |( -1.0 ) - ( -1 )| = 0.0\n",
      "- |( -1.0 ) - ( -1 )| = 0.0\n",
      "But |( -0.2 ) - ( -0.4 )| = 0.2\n",
      "but |( -0.2 ) - ( -0.4 )| = 0.2\n",
      "million |( -1.0 ) - ( -1 )| = 0.0\n",
      "billion |( -1.0 ) - ( -1 )| = 0.0\n",
      "will |( 0.9 ) - ( 0.8 )| = 0.1\n",
      "would |( 0.9 ) - ( 0.8 )| = 0.1\n",
      "could |( 0.9 ) - ( 0.8 )| = 0.1\n",
      "can |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "may |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "shares |( 0 ) - ( 0.1 )| = 0.1\n",
      "prices |( 0 ) - ( 0.2 )| = 0.2\n",
      "better |( 0.8 ) - ( 0.7 )| = 0.1\n",
      "& |( -1 ) - ( -1 )| = 0\n",
      "to |( 0.3 ) - ( 0.5 )| = 0.2\n",
      "To |( 0.3 ) - ( 0.5 )| = 0.2\n",
      "TO |( 0.3 ) - ( 0.5 )| = 0.2\n",
      "OK |( -1 ) - ( -1 )| = 0\n",
      "Oh |( -1 ) - ( -1 )| = 0\n",
      "no |( -1 ) - ( -1 )| = 0\n",
      "be |( 1 ) - ( 1 )| = 0\n",
      "make |( 1 ) - ( 1 )| = 0\n",
      "buy |( 1 ) - ( 1 )| = 0\n",
      "take |( 1 ) - ( 1 )| = 0\n",
      "was |( 1 ) - ( 0.8 )| = 0.2\n",
      "were |( 1 ) - ( 0.8 )| = 0.2\n",
      "had |( 1 ) - ( 0.8 )| = 0.2\n",
      "did |( 1 ) - ( 1 )| = 0\n",
      "including |( 0.6 ) - ( 0.4 )| = 0.2\n",
      "according |( 0.6 ) - ( 0.4 )| = 0.2\n",
      "being |( 1 ) - ( 1 )| = 0\n",
      "growing |( 1 ) - ( 1 )| = 0\n",
      "trying |( 1 ) - ( 1 )| = 0\n",
      "been |( 1 ) - ( 0.8 )| = 0.2\n",
      "made |( 1 ) - ( 1 )| = 0\n",
      "are |( 1 ) - ( 0.8 )| = 0.2\n",
      "have |( 1 ) - ( 1 )| = 0\n",
      "do |( 1 ) - ( 1 )| = 0\n",
      "which |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "that |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "That |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "THAT |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "who |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "whom |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "Who |( -0.2 ) - ( -0.3 )| = 0.1\n",
      "whose |( -0.3 ) - ( -0.3 )| = 0.0\n",
      "how |( 0.3 ) - ( 0.4 )| = 0.1\n",
      "Number of words with a difference of less than 0.25 (very confident):  217 of 383\n",
      "Percentage:  57 %\n"
     ]
    }
   ],
   "source": [
    "# surface words from axis_emb[0] that have a difference of less than 0.25\n",
    "len_b = 0\n",
    "for i in range(len(diff_run_list)):\n",
    "  if diff_run_list[i] < 0.25:\n",
    "    print(axis_emb[0][i], \"|(\", first_run[i], \")\", \"-\", \"(\", second_run[i], \")|\", \"=\", diff_run_list[i])\n",
    "    len_b += 1\n",
    "\n",
    "print(\"Number of words with a difference of less than 0.25 (very confident): \", len_b, \"of\", len(diff_run_list))\n",
    "print(\"Percentage: \", round(len_b/len(diff_run_list) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6861",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
