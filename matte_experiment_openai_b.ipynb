{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embedding axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>companion</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toast</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lounge</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watch</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.933</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haul</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.423</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      0      1      2      3      4      5      6      7      8  \\\n",
       "0  companion  0.128 -0.082  0.109 -0.012  0.317  0.262 -0.016  0.128  0.357   \n",
       "1      toast  0.209  0.411  0.026 -0.000 -0.243 -0.325  0.148  0.238 -0.120   \n",
       "2     lounge  0.759 -0.116  0.116  0.113  0.460 -0.212  0.115 -0.032  0.137   \n",
       "3      watch  0.401 -0.003 -0.061 -0.406  0.933 -0.140 -0.186  0.286 -0.170   \n",
       "4       haul  0.580  0.031  0.311  0.048 -0.102  0.081  0.047  0.423 -0.187   \n",
       "\n",
       "   ...    758    759    760    761    762    763    764    765    766    767  \n",
       "0  ...  0.395 -0.107 -0.026 -0.061  0.358 -0.138 -0.067  0.236  0.385 -0.115  \n",
       "1  ...  0.373 -0.174  0.119 -0.036  0.445 -0.029  0.145  0.169  0.364 -0.097  \n",
       "2  ...  0.259  0.070 -0.059 -0.114  0.441 -0.096 -0.074  0.196  0.215 -0.254  \n",
       "3  ...  0.459 -0.067 -0.266 -0.318  0.173 -0.109  0.219 -0.010  0.404 -0.161  \n",
       "4  ...  0.505  0.096  0.095 -0.009  0.453  0.003  0.337  0.259  0.064  0.092  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open training_embeddings.csv and load it into a dataframe\n",
    "df = pd.read_csv('training_embeddings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.21, 2.042)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get slice of dataframe after first column\n",
    "# get min and max values across all columns\n",
    "df.iloc[:,1:].min().min(), df.iloc[:,1:].max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply maximum and minimum truncation to dataframe\n",
    "# this does not fundamentally change the data because it follows a normal distribution from -1 to 1\n",
    "df.iloc[:,1:] = df.iloc[:,1:].clip(-1,1)\n",
    "\n",
    "# get min and max values across all columns\n",
    "df.iloc[:,1:].min().min(), df.iloc[:,1:].max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>companion</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toast</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lounge</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watch</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.933</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haul</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.423</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      0      1      2      3      4      5      6      7      8  \\\n",
       "0  companion  0.128 -0.082  0.109 -0.012  0.317  0.262 -0.016  0.128  0.357   \n",
       "1      toast  0.209  0.411  0.026 -0.000 -0.243 -0.325  0.148  0.238 -0.120   \n",
       "2     lounge  0.759 -0.116  0.116  0.113  0.460 -0.212  0.115 -0.032  0.137   \n",
       "3      watch  0.401 -0.003 -0.061 -0.406  0.933 -0.140 -0.186  0.286 -0.170   \n",
       "4       haul  0.580  0.031  0.311  0.048 -0.102  0.081  0.047  0.423 -0.187   \n",
       "\n",
       "   ...    758    759    760    761    762    763    764    765    766    767  \n",
       "0  ...  0.395 -0.107 -0.026 -0.061  0.358 -0.138 -0.067  0.236  0.385 -0.115  \n",
       "1  ...  0.373 -0.174  0.119 -0.036  0.445 -0.029  0.145  0.169  0.364 -0.097  \n",
       "2  ...  0.259  0.070 -0.059 -0.114  0.441 -0.096 -0.074  0.196  0.215 -0.254  \n",
       "3  ...  0.459 -0.067 -0.266 -0.318  0.173 -0.109  0.219 -0.010  0.404 -0.161  \n",
       "4  ...  0.505  0.096  0.095 -0.009  0.453  0.003  0.337  0.259  0.064  0.092  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 383 383\n",
      "['companion', 'toast', 'lounge', 'watch', 'haul']\n",
      "[0.128, 0.209, 0.759, 0.401, 0.58]\n"
     ]
    }
   ],
   "source": [
    "def get_x_embedding(df, x):\n",
    "  \"\"\"\n",
    "  Extract the x column from the dataframe and store it as a list\n",
    "  \"\"\"\n",
    "  # Extract the word and x column from the dataframe and store them as a list of lists\n",
    "  # index = 0\n",
    "  words = df['word'].tolist()\n",
    "  emd_index = df[str(x)].tolist()\n",
    "  # data = [[words[i], emd_index[i]] for i in range(len(words))]\n",
    "  # print(data[:5])\n",
    "\n",
    "  # Concatenate the two lists into a list of lists\n",
    "  data = [words,emd_index]\n",
    "  return data\n",
    "\n",
    "data = get_x_embedding(df, 0)\n",
    "print(len(data), len(data[0]), len(data[1]))\n",
    "print(data[0][:5])\n",
    "print(data[1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get axis interpretation from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install OpenAI api\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded.\n"
     ]
    }
   ],
   "source": [
    "# load api key from secrets.json\n",
    "import openai\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open(\"secrets.json\") as f:\n",
    "        secrets = json.load(f)\n",
    "    my_api_key = secrets[\"openai\"]\n",
    "    print(\"API key loaded.\")\n",
    "    openai.api_key = my_api_key\n",
    "except FileNotFoundError:\n",
    "    print(\"Secrets file not found. YOU NEED THEM TO RUN THIS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_emb = get_x_embedding(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"{\\\"action vs state\\\": 0.6, \\\"objects vs abstract concepts\\\": 0.65, \\\"positive sentiment vs negative sentiment\\\": 0.4}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model_num = \"gpt-3.5-turbo-1106\"\n",
    "# model_num = \"gpt-4-1106-preview\"\n",
    "model_num = \"gpt-4\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=model_num,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert transformer embeddings labeller.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Below are two lists. The first list contains words that have been put into DistilBERT. DistilBERT creates an embedding with 768 dimensions or axes. The second list contains the embedding value from DistilBERT for one axis across the words. By carefully comparing and considering the embedding values for each word, please interpret the likely linguistic binary feature that this embedding axis encodes. This binary interpretation must be consistent across all the words and must be expressed as 'x vs y', where 'x' relates to words with positive embedding values and 'y' relates to words with negative embedding values. Words that relate to neither 'x' nor 'y' will have embedding values close to 0. \\n\\n  The output must be a Python dictionary with three items, the key is a string containing the possible binary interpretation of the axis. The value is a float, representing the confidence score from 0 to 1. \\n\\n The output must be the dictionary only, which can be eval-ed into code. Here is the output format: {{<first x vs first y>:<first interpretation confidence score>, <second x vs second y>:<second interpretation confidence score>, <third x vs third y>:<third interpretation confidence score>}} \\n\\n {axis_emb[0]}\\n\\n {axis_emb[1]}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "\n",
    "# log the stringified output into a txt file by appending it to the end of the file\n",
    "with open(\"output.txt\", \"a\") as f:\n",
    "  f.write(str(completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action vs state': 0.6, 'objects vs abstract concepts': 0.65, 'positive sentiment vs negative sentiment': 0.4}\n",
      "1\n",
      "objects vs abstract concepts\n"
     ]
    }
   ],
   "source": [
    "# convert the output string into a dictionary\n",
    "interp_dict = eval(completion.choices[0].message.content)\n",
    "print(interp_dict)\n",
    "\n",
    "# convert the dictionary keys into a list\n",
    "interp_keys = list(interp_dict.keys())\n",
    "\n",
    "# get the index of the key with the highest value\n",
    "interp_values = list(interp_dict.values())\n",
    "max_interp_index = interp_values.index(max(interp_values))\n",
    "print(max_interp_index)\n",
    "\n",
    "# get the key with the highest value\n",
    "max_interp_key = interp_keys[max_interp_index]\n",
    "print(max_interp_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['objects', 'abstract concepts']\n"
     ]
    }
   ],
   "source": [
    "# split the key into two words using \"vs\" as the delimiter\n",
    "pos_neg = max_interp_key.split(\" vs \")\n",
    "print(pos_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate interpretations using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Step  1  of  13\n",
      "1  Input length:  30\n",
      "[0.1, 0.9, 0.4, 0.9, 0.4, -0.2, -0.7, 0.3, 0.8, 0.8, -0.1, 0.3, 0.8, 0.2, -0.9, 0.6, 0.8, -0.5, 0.6, 0.8, -0.3, 0.7, 0.9, 0.3, 0.4, 0.7, -0.5, 0.1, 0.9, 0.4]\n",
      "1 Output length:  30\n",
      "1 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  2  of  13\n",
      "2  Input length:  30\n",
      "[0.5, -0.5, -0.9, 0.3, 0.5, -0.7, 0.8, 0.2, 0, 0.5, 0.8, -0.8, 0.9, 0.3, 0.4, 0.8, -0.7, 0, 0.9, 0.8, 0.9, -0.9, 0.9, -0.2, 0, -0.2, -0.1, 0, 0.6, 0.4]\n",
      "2 Output length:  30\n",
      "2 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  3  of  13\n",
      "3  Input length:  30\n",
      "[-0.9, -0.6, 0.1, 0.3, -0.8, -0.9, -0.95, -0.9, -0.95, 0.1, -0.85, -0.1, -0.6, 0.1, -0.8, 0.2, 0.1, 0.7, 0.2, 0.9, 0.1, 0.3, 0.1, 0.2, -0.85, -0.85, 0.3, 0.2, 0.05, 0.1]\n",
      "3 Output length:  30\n",
      "3 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  4  of  13\n",
      "4  Input length:  30\n",
      "[0.0, 0.0, 0.0, 0.0, -0.2, -0.2, 0.0, -0.8, -0.2, 0.0, 0.0, -1.0, 0.8, -0.2, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -0.8, 0.0, -0.8, -1.0, -0.8, -0.2, -0.2, 0.9, -0.5, -1.0]\n",
      "4 Output length:  30\n",
      "4 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  5  of  13\n",
      "5  Input length:  30\n",
      "[0, -0.2, 0, -0.5, -0.7, -0.5, 0.1, -0.8, 0, 0, -0.1, 0.1, -0.9, -0.2, -0.8, 0, 0.5, 0.3, 0.2, 0.7, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]\n",
      "5 Output length:  30\n",
      "5 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  6  of  13\n",
      "6  Input length:  30\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "6 Output length:  30\n",
      "6 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  7  of  13\n",
      "7  Input length:  30\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "7 Output length:  30\n",
      "7 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  8  of  13\n",
      "8  Input length:  30\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.5, -0.5]\n",
      "8 Output length:  30\n",
      "8 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  9  of  13\n",
      "9  Input length:  30\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5, -0.6, -0.6, -0.6, -0.6, -0.6, -0.9, 0.0, 0.0, 0.0]\n",
      "9 Output length:  30\n",
      "9 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  10  of  13\n",
      "10  Input length:  30\n",
      "[0.9, 0.9, -0.7, -0.7, -0.7, -0.7, -0.7, 0.9, 0.1, 0.4, 0.2, 0.3, 0.5, 0.7, 0.4, 0.6, 0.4, 0.9, 0.8, 0.9, 0.9, 0.6, 0.4, 0.6, 0.7, 0.9, 0.5, -0.7, -0.7, 0.5]\n",
      "10 Output length:  30\n",
      "10 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  11  of  13\n",
      "11  Input length:  30\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.2, -0.2, -0.2, -0.2, -0.2, -0.2, -0.2, 0, 0, 0, 0, 0]\n",
      "11 Output length:  30\n",
      "11 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  12  of  13\n",
      "12  Input length:  30\n",
      "[0, 0, 0, 0, 0, 0, 0, -0.2, -0.2, 0.8, 0.4, 0, -0.2, -0.2, -0.2, -0.2, -0.4, -0.4, -0.4, -0.4, -0.4, -0.2, -0.6, 0, -0.6, -0.6, -0.2, -0.2, 0, -0.2]\n",
      "12 Output length:  30\n",
      "12 Are input output lengths the same?  True\n",
      "\n",
      "\n",
      "Step  13  of  13\n",
      "13  Input length:  23\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "13 Output length:  23\n",
      "13 Are input output lengths the same?  True\n",
      "Length of embedding list:  383\n",
      "Length of score list:  383\n"
     ]
    }
   ],
   "source": [
    "# model_num = \"gpt-3.5-turbo-1106\"\n",
    "# model_num = \"gpt-4-1106-preview\"\n",
    "model_num = \"gpt-4\"\n",
    "\n",
    "score_list = []\n",
    "step = 30\n",
    "\n",
    "for i in range((len(axis_emb[0])// step )+ 1):\n",
    "  # test to make sure the list is being truncated correctly\n",
    "  # print(i*step, (i+1)*step)\n",
    "  trunc_word_list = axis_emb[0][i*step:(i+1)*step]\n",
    "  # print(trunc_word_list)\n",
    "  # print(len(trunc_word_list))\n",
    "\n",
    "  is_length_correct = False\n",
    "\n",
    "  while (is_length_correct == False):\n",
    "    print(\"\\n\\nStep \", i + 1, \" of \", (len(axis_emb[0])// step )+ 1)\n",
    "    print(i+1, \" Input length: \", len(trunc_word_list))\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=model_num,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert word sense scorer.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"For the list of words below, please assign it a score according to how much it relates to the following criteria: '{max_interp_key}' \\n\\n  The output must be a Python list of scores for each corresponding word in the provided list. The output must therefore have {len(trunc_word_list)} items, the same length as the provided list. The score is a float that ranges from -1 to 1. Positive scores suggest a strong relationship with the positive criterion, '{pos_neg[0]}', while negative scores suggest a strong relationship with the negative criterion, '{pos_neg[1]}'. Scores close to 0 suggest that the word is not related to both the positive and negative criteria. \\n\\n Here is an output sample: [<score for first word>, <score for second word>, ... , <score for second-last word>, <score for last word>] \\n\\n {trunc_word_list}\"}\n",
    "        # {\"role\": \"user\", \"content\": f\"For the list of words below, please assign it a score according to how much it relates to the following criteria: {interp_keys[0]}  \\n\\n  The output must be a Python list of scores for each corresponding word in the provided list. The output must therefore have the same number of items as the provided list. The score is a float that ranges from -1 to 1. Positive scores suggest a high correlation to the criteria, while negative scores suggest a high opposite correlation. Scores closer to 0 suggest that the criterion is not applicable to the word. \\n\\n Here is an output sample: [<score for first word>, <score for second word>, ... , <score for second-last word>, <score for last word>] \\n\\n {axis_emb[0]}\"}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    # print(completion.choices[0].message)\n",
    "\n",
    "    # log the stringified output into a txt file by appending it to the end of the file\n",
    "    with open(\"eval_output.txt\", \"a\") as f:\n",
    "      f.write(str(completion))\n",
    "\n",
    "    # convert the output string into a list\n",
    "    try:\n",
    "      scores = eval(completion.choices[0].message.content)\n",
    "    except:\n",
    "      print(i+1, \"Error: \", completion.choices[0].message.content)\n",
    "      print(\"Trying again...\")\n",
    "      continue\n",
    "    print(scores)\n",
    "\n",
    "    # check if the length is correct\n",
    "    print(i+1, \"Output length: \", len(scores))\n",
    "    print(i+1, \"Are input output lengths the same? \" ,len(scores) == len(trunc_word_list))\n",
    "\n",
    "    if len(scores) == len(trunc_word_list):\n",
    "      is_length_correct = True\n",
    "    else:\n",
    "      print(\"Input output lengths are not the same. Trying again...\")\n",
    "      continue\n",
    "\n",
    "    # concatenate scores with score_list\n",
    "    score_list += scores\n",
    "\n",
    "    # giving it more time â€“ does it lead to better results?\n",
    "    time.sleep(10)\n",
    "\n",
    "with open(\"eval_output.txt\", \"a\") as f:\n",
    "  f.write(\"\\nscore_list: \" + str(score_list))\n",
    "print(\"Length of embedding list: \", len(axis_emb[0]))\n",
    "print(\"Length of score list: \", len(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.027999999999999997, 0.6910000000000001, -0.359, 0.499, -0.17999999999999994]\n",
      "Sum of diff:  195.76600000000005\n",
      "Mean of diff:  0.5111383812010445\n"
     ]
    }
   ],
   "source": [
    "# compare score_list with axis_emb[1] by subtracting them\n",
    "diff_list = [score_list[i] - axis_emb[1][i] for i in range(len(score_list))]\n",
    "print(diff_list[:5])\n",
    "\n",
    "# abs and round the difference list to 3 decimal places\n",
    "diff_list = [abs(round(diff, 3)) for diff in diff_list]\n",
    "\n",
    "# sum the difference list\n",
    "sum_diff = sum(diff_list)\n",
    "print(\"Sum of diff: \", sum_diff)\n",
    "\n",
    "# calculate the mean of the difference list\n",
    "mean_diff = sum(diff_list)/len(diff_list)\n",
    "print(\"Mean of diff: \", mean_diff)\n",
    "\n",
    "with open(\"eval_output.txt\", \"a\") as f:\n",
    "  f.write(\"\\ndiff_list: \" + str(diff_list) + \"\\nsum of diff: \" + str(sum_diff) + \"\\nmean of diff: \" + str(mean_diff) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- mean difference of 0.51 is getting better, previously was 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can set a threshold to decide if the interpretation is good. E.g. above 0.25 mean difference is bad and below 0.25 is good?\n",
    "\n",
    "We can also make it loop through all 3 outputs if it doesn't meet the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between two runs + evaluating the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first run:  383\n",
      "Length of second run:  383\n",
      "[0.1, 0.1, 0.6, 0.1, 0.6, 0.2, 0.1, 0.5, 0.0, 0.0, 0.1, 0.1, 0.2, 0.3, 0.1, 0.0, 0.1, 0.1, 0.9, 0.2, 0.4, 0.3, 0.1, 0.2, 0.2, 0.9, 0.3, 0.4, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.2, 0.1, 0.2, 0.2, 0.2, 0.3, 0.1, 0.1, 0.1, 0.2, 0.3, 0.0, 0.2, 0.1, 0.2, 0.2, 0.6, 0.0, 0.1, 0.1, 0.4, 0.6, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.5, 0.4, 0.1, 0.3, 0.05, 0.2, 0.05, 0.4, 0.35, 0.1, 0.4, 0.5, 0.0, 0.3, 0.4, 0.2, 0.5, 0.0, 0.3, 0.3, 0.6, 0.6, 0.55, 0.35, 0.4, 0.4, 0.45, 0.3, 0.1, 0.2, 0.4, 0.3, 0.2, 0.0, 0.2, 0.0, 0.3, 0.2, 0.2, 0.1, 0.0, 0.1, 0.1, 0.2, 0.5, 0.3, 0.3, 0.4, 0.2, 0.4, 0.5, 0.2, 0.2, 0.5, 0.8, 0.0, 0.6, 0.1, 0.1, 0.8, 0.3, 1.0, 0.2, 0.1, 0.0, 0.5, 0.2, 0.3, 0.3, 0.1, 0.4, 0.3, 0.5, 0.2, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.4, 0.4, 0.3, 0.2, 0.2, 0.2, 0.8, 0.2, 0.2, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.8, 0.2, 0.1, 0.1, 0.2, 0.4, 0.3, 0.3, 0.3, 0.0, 0.1, 0.0, 0.0, 0.3, 0.2, 0.5, 0.5, 0.0, 0.7, 0.3, 0.1, 0.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0.8, 0.6, 0.8, 0.6, 0.5, 0.8, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6, 0.3, 0.6, 0.8, 0.1, 0.5, 0.1, 0.4, 0.8, 0.8, 1, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Sum of diff between two runs:  67.00000000000003\n",
      "Mean of diff between two runs:  0.17493472584856404\n"
     ]
    }
   ],
   "source": [
    "# compare between two runs\n",
    "\n",
    "first_run = [0.2, 1.0, 1.0, 1.0, 1.0, -0.4, -0.8, -0.2, 0.8, 0.8, -0.2, 0.4, 1.0, -0.1, -1.0, 0.6, 0.7, -0.4, -0.3, 1.0, -0.7, 0.4, 1.0, 0.5, 0.6, -0.2, -0.2, -0.3, 1.0, 0.3, 0.5, -0.4, -0.9, 0.2, 0.3, -0.8, 0.6, 0.4, 0.2, 0.2, 0.7, -0.7, 0.8, 0.1, 0.1, 0.8, -0.9, -0.1, 0.7, 0.6, 0.3, -0.9, 0.8, -0.1, -0.4, 0.4, -0.1, -0.1, 0.6, 0.5, -0.8, -0.7, 0.6, 0.7, -0.7, -0.6, -0.9, -0.7, -0.9, 0.5, -0.5, -0.2, -0.2, 0.6, -0.8, 0.5, 0.5, 0.9, 0.7, 0.9, -0.2, 0.6, 0.7, 0.8, -0.3, -0.5, 0.7, 0.6, 0.5, 0.4, 0.1, 0.2, 0.4, 0.3, -0.4, -0.2, 0.2, -0.8, 0.1, 0.2, 0.2, -0.9, 0.8, -0.1, -0.9, 0.2, 0.5, -0.7, 0.3, 0.4, -0.6, 0.4, -0.3, -0.8, -0.6, 0.3, 0.6, 0.9, 0.1, -0.9, 0.1, 0.6, 0.3, 0.5, -0.5, -0.4, 0.1, -0.3, 0.2, 0.3, 0.2, 0.2, -0.5, 0.1, -0.3, 0.2, 0.6, 0.2, 0.3, 0.6, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.5, -0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.2, 0, -0.1, -0.1, 0, 0, 0, -0.4, -0.4, -0.3, -0.3, -0.4, -0.4, 0.2, -0.4, -0.4, -0.5, 0, 0, 0, 0.9, 0.9, -0.9, -0.9, -0.9, -0.9, -0.9, 0.9, 0.9, 0.2, 0.1, 0.2, 0.7, 0.3, 0.1, 0.9, 0.1, 0.9, 0.9, 0.9, 0.9, 0.9, 0.2, 0.1, 0.2, 0.9, -0.2, -1, -0.8, 0.9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -0.5, -0.5, -0.5, -1, -0.8, 0, -0.2, -0.5, -1, -1, -1, -0.8, -1, -1, -1, -0.7, -1, -1, -0.7, -0.5, -0.7, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "second_run = [0.1, 0.9, 0.4, 0.9, 0.4, -0.2, -0.7, 0.3, 0.8, 0.8, -0.1, 0.3, 0.8, 0.2, -0.9, 0.6, 0.8, -0.5, 0.6, 0.8, -0.3, 0.7, 0.9, 0.3, 0.4, 0.7, -0.5, 0.1, 0.9, 0.4, 0.5, -0.5, -0.9, 0.3, 0.5, -0.7, 0.8, 0.2, 0, 0.5, 0.8, -0.8, 0.9, 0.3, 0.4, 0.8, -0.7, 0, 0.9, 0.8, 0.9, -0.9, 0.9, -0.2, 0, -0.2, -0.1, 0, 0.6, 0.4, -0.9, -0.6, 0.1, 0.3, -0.8, -0.9, -0.95, -0.9, -0.95, 0.1, -0.85, -0.1, -0.6, 0.1, -0.8, 0.2, 0.1, 0.7, 0.2, 0.9, 0.1, 0.3, 0.1, 0.2, -0.85, -0.85, 0.3, 0.2, 0.05, 0.1, 0.0, 0.0, 0.0, 0.0, -0.2, -0.2, 0.0, -0.8, -0.2, 0.0, 0.0, -1.0, 0.8, -0.2, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -0.8, 0.0, -0.8, -1.0, -0.8, -0.2, -0.2, 0.9, -0.5, -1.0, 0, -0.2, 0, -0.5, -0.7, -0.5, 0.1, -0.8, 0, 0, -0.1, 0.1, -0.9, -0.2, -0.8, 0, 0.5, 0.3, 0.2, 0.7, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.5, -0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5, -0.6, -0.6, -0.6, -0.6, -0.6, -0.9, 0.0, 0.0, 0.0, 0.9, 0.9, -0.7, -0.7, -0.7, -0.7, -0.7, 0.9, 0.1, 0.4, 0.2, 0.3, 0.5, 0.7, 0.4, 0.6, 0.4, 0.9, 0.8, 0.9, 0.9, 0.6, 0.4, 0.6, 0.7, 0.9, 0.5, -0.7, -0.7, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.2, -0.2, -0.2, -0.2, -0.2, -0.2, -0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.2, -0.2, 0.8, 0.4, 0, -0.2, -0.2, -0.2, -0.2, -0.4, -0.4, -0.4, -0.4, -0.4, -0.2, -0.6, 0, -0.6, -0.6, -0.2, -0.2, 0, -0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "print(\"Length of first run: \", len(first_run))\n",
    "print(\"Length of second run: \", len(second_run)) \n",
    "\n",
    "diff_run_list = [first_run[i] - second_run[i] for i in range(len(first_run))]\n",
    "\n",
    "# abs and round the difference list to 3 decimal places\n",
    "diff_run_list = [abs(round(diff, 3)) for diff in diff_run_list]\n",
    "print(diff_run_list)\n",
    "\n",
    "sum_diff_run = sum(diff_run_list)\n",
    "print(\"Sum of diff between two runs: \", sum_diff_run)\n",
    "mean_diff_run = sum(diff_run_list)/len(diff_run_list)\n",
    "print(\"Mean of diff between two runs: \", mean_diff_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- 0.17 difference between 2 runs seems pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word  embedding  score\n",
      "0  companion      0.128    0.2\n",
      "1      toast      0.209    1.0\n",
      "2     lounge      0.759    1.0\n",
      "3      watch      0.401    1.0\n",
      "4       haul      0.580    1.0\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of words, embedding values, and scores\n",
    "df = pd.DataFrame({'word': axis_emb[0], 'embedding': axis_emb[1], 'score': first_run})\n",
    "print(df.head())\n",
    "\n",
    "# save dataframe as csv\n",
    "df.to_csv('llm-outputs/first_run.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word  embedding  score\n",
      "0  companion      0.128    0.1\n",
      "1      toast      0.209    0.9\n",
      "2     lounge      0.759    0.4\n",
      "3      watch      0.401    0.9\n",
      "4       haul      0.580    0.4\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of words, embedding values, and scores\n",
    "df = pd.DataFrame({'word': axis_emb[0], 'embedding': axis_emb[1], 'score': second_run})\n",
    "print(df.head())\n",
    "\n",
    "# save dataframe as csv\n",
    "df.to_csv('llm-outputs/second_run.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- it seems like the results are somewhat repeatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surf |( -0.3 ) - ( 0.6 )| = 0.9\n",
      "cooling |( -0.2 ) - ( 0.7 )| = 0.9\n",
      "trumpet |( 0.6 ) - ( -0.2 )| = 0.8\n",
      "sanitation |( 0.6 ) - ( -0.2 )| = 0.8\n",
      "dry |( 0.5 ) - ( -0.5 )| = 1.0\n",
      "largest |( 0.2 ) - ( -0.6 )| = 0.8\n",
      "company |( 0.9 ) - ( 0.1 )| = 0.8\n",
      "& |( -1 ) - ( 0 )| = 1\n",
      "to |( -1 ) - ( 0 )| = 1\n",
      "To |( -1 ) - ( 0 )| = 1\n",
      "TO |( -1 ) - ( 0 )| = 1\n",
      "be |( -1 ) - ( -0.2 )| = 0.8\n",
      "buy |( 0 ) - ( 0.8 )| = 0.8\n",
      "was |( -1 ) - ( -0.2 )| = 0.8\n",
      "were |( -1 ) - ( -0.2 )| = 0.8\n",
      "had |( -1 ) - ( -0.2 )| = 0.8\n",
      "been |( -1 ) - ( -0.2 )| = 0.8\n",
      "are |( -1 ) - ( -0.2 )| = 0.8\n",
      "have |( -1 ) - ( -0.2 )| = 0.8\n",
      "say |( -1 ) - ( 0 )| = 1\n",
      "do |( -1 ) - ( -0.2 )| = 0.8\n",
      "Number of words with a difference of more than 0.5 (not confident):  21 of 383\n",
      "Percentage:  5 %\n"
     ]
    }
   ],
   "source": [
    "# surface words from axis_emb[0] that have a difference of more than 0.5\n",
    "len_a = 0\n",
    "for i in range(len(diff_run_list)):\n",
    "  if diff_run_list[i] > 0.75:\n",
    "    print(axis_emb[0][i], \"|(\", first_run[i], \")\", \"-\", \"(\", second_run[i], \")|\", \"=\", diff_run_list[i])\n",
    "    len_a += 1\n",
    "\n",
    "print(\"Number of words with a difference of more than 0.5 (not confident): \", len_a, \"of\", len(diff_run_list))\n",
    "print(\"Percentage: \", round(len_a/len(diff_run_list) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- (from prev:) my hunch is that GPT is struggling to differentiate between opposite (-1) and irrelevant (0). maybe this can be simplified or strengthened?\n",
    "- my hunch seems to be confirmed. This run is far better than the previous one â€“ 5% compared to 23% not confident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companion |( 0.2 ) - ( 0.1 )| = 0.1\n",
      "toast |( 1.0 ) - ( 0.9 )| = 0.1\n",
      "watch |( 1.0 ) - ( 0.9 )| = 0.1\n",
      "combination |( -0.4 ) - ( -0.2 )| = 0.2\n",
      "majesty |( -0.8 ) - ( -0.7 )| = 0.1\n",
      "nutrient |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "bark |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "rest |( -0.2 ) - ( -0.1 )| = 0.1\n",
      "hold |( 0.4 ) - ( 0.3 )| = 0.1\n",
      "drainage |( 1.0 ) - ( 0.8 )| = 0.2\n",
      "time |( -1.0 ) - ( -0.9 )| = 0.1\n",
      "drink |( 0.6 ) - ( 0.6 )| = 0.0\n",
      "eat |( 0.7 ) - ( 0.8 )| = 0.1\n",
      "journey |( -0.4 ) - ( -0.5 )| = 0.1\n",
      "shipment |( 1.0 ) - ( 0.8 )| = 0.2\n",
      "cutlery |( 1.0 ) - ( 0.9 )| = 0.1\n",
      "catch |( 0.5 ) - ( 0.3 )| = 0.2\n",
      "drive |( 0.6 ) - ( 0.4 )| = 0.2\n",
      "moo |( 1.0 ) - ( 0.9 )| = 0.1\n",
      "descend |( 0.3 ) - ( 0.4 )| = 0.1\n",
      "commute |( 0.5 ) - ( 0.5 )| = 0.0\n",
      "score |( -0.4 ) - ( -0.5 )| = 0.1\n",
      "indulgence |( -0.9 ) - ( -0.9 )| = 0.0\n",
      "cutting |( 0.2 ) - ( 0.3 )| = 0.1\n",
      "containment |( 0.3 ) - ( 0.5 )| = 0.2\n",
      "communication |( -0.8 ) - ( -0.7 )| = 0.1\n",
      "transportation |( 0.6 ) - ( 0.8 )| = 0.2\n",
      "glide |( 0.4 ) - ( 0.2 )| = 0.2\n",
      "slice |( 0.2 ) - ( 0 )| = 0.2\n",
      "tote |( 0.7 ) - ( 0.8 )| = 0.1\n",
      "nurture |( -0.7 ) - ( -0.8 )| = 0.1\n",
      "breakfast |( 0.8 ) - ( 0.9 )| = 0.1\n",
      "cut |( 0.1 ) - ( 0.3 )| = 0.2\n",
      "brush |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "competition |( -0.9 ) - ( -0.7 )| = 0.2\n",
      "signal |( -0.1 ) - ( 0 )| = 0.1\n",
      "carry |( 0.7 ) - ( 0.9 )| = 0.2\n",
      "mobility |( 0.6 ) - ( 0.8 )| = 0.2\n",
      "conformity |( -0.9 ) - ( -0.9 )| = 0.0\n",
      "Thanksgiving |( 0.8 ) - ( 0.9 )| = 0.1\n",
      "comfort |( -0.1 ) - ( -0.2 )| = 0.1\n",
      "pause |( -0.1 ) - ( -0.1 )| = 0.0\n",
      "input |( -0.1 ) - ( 0 )| = 0.1\n",
      "hygiene |( 0.6 ) - ( 0.6 )| = 0.0\n",
      "click |( 0.5 ) - ( 0.4 )| = 0.1\n",
      "health |( -0.8 ) - ( -0.9 )| = 0.1\n",
      "entertainment |( -0.7 ) - ( -0.6 )| = 0.1\n",
      "softness |( -0.7 ) - ( -0.8 )| = 0.1\n",
      "loyalty |( -0.9 ) - ( -0.95 )| = 0.05\n",
      "formality |( -0.7 ) - ( -0.9 )| = 0.2\n",
      "individuality |( -0.9 ) - ( -0.95 )| = 0.05\n",
      "gathering |( -0.2 ) - ( -0.1 )| = 0.1\n",
      "productivity |( -0.8 ) - ( -0.8 )| = 0.0\n",
      "decoration |( 0.9 ) - ( 0.7 )| = 0.2\n",
      "accessory |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "read |( 0.1 ) - ( 0.0 )| = 0.1\n",
      "bake |( 0.2 ) - ( 0.0 )| = 0.2\n",
      "descent |( -0.4 ) - ( -0.2 )| = 0.2\n",
      "voyage |( -0.2 ) - ( -0.2 )| = 0.0\n",
      "heating |( 0.2 ) - ( 0.0 )| = 0.2\n",
      "thrill |( -0.8 ) - ( -0.8 )| = 0.0\n",
      "fly |( 0.2 ) - ( 0.0 )| = 0.2\n",
      "hug |( 0.2 ) - ( 0.0 )| = 0.2\n",
      "knowledge |( -0.9 ) - ( -1.0 )| = 0.1\n",
      "shield |( 0.8 ) - ( 0.8 )| = 0.0\n",
      "transit |( -0.1 ) - ( -0.2 )| = 0.1\n",
      "solitude |( -0.9 ) - ( -1.0 )| = 0.1\n",
      "heat |( 0.2 ) - ( 0.0 )| = 0.2\n",
      "adventure |( -0.6 ) - ( -0.8 )| = 0.2\n",
      "elegance |( -0.8 ) - ( -1.0 )| = 0.2\n",
      "recreation |( -0.6 ) - ( -0.8 )| = 0.2\n",
      "container |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "childhood |( -0.9 ) - ( -1.0 )| = 0.1\n",
      "measurement |( 0.1 ) - ( 0 )| = 0.1\n",
      "growth |( -0.5 ) - ( -0.7 )| = 0.2\n",
      "safety |( -0.4 ) - ( -0.5 )| = 0.1\n",
      "swing |( 0.1 ) - ( 0.1 )| = 0.0\n",
      "ride |( 0.2 ) - ( 0 )| = 0.2\n",
      "graze |( 0.2 ) - ( 0.1 )| = 0.1\n",
      "acidity |( 0.2 ) - ( 0 )| = 0.2\n",
      "prong |( 0.6 ) - ( 0.5 )| = 0.1\n",
      "chop |( 0.2 ) - ( 0.3 )| = 0.1\n",
      "munch |( 0.3 ) - ( 0.2 )| = 0.1\n",
      "person |( 0.6 ) - ( 0.7 )| = 0.1\n",
      "bicycle |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "car |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "motorcycle |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "airplane |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "bus |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "train |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "truck |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "boat |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "traffic light |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "fire hydrant |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "stop sign |( 1 ) - ( 1 )| = 0\n",
      "parking meter |( 1 ) - ( 1 )| = 0\n",
      "bench |( 1 ) - ( 1 )| = 0\n",
      "bird |( 1 ) - ( 1 )| = 0\n",
      "cat |( 1 ) - ( 1 )| = 0\n",
      "dog |( 1 ) - ( 1 )| = 0\n",
      "horse |( 1 ) - ( 1 )| = 0\n",
      "sheep |( 1 ) - ( 1 )| = 0\n",
      "cow |( 1 ) - ( 1 )| = 0\n",
      "elephant |( 1 ) - ( 1 )| = 0\n",
      "bear |( 1 ) - ( 1 )| = 0\n",
      "zebra |( 1 ) - ( 1 )| = 0\n",
      "giraffe |( 1 ) - ( 1 )| = 0\n",
      "backpack |( 1 ) - ( 1 )| = 0\n",
      "umbrella |( 1 ) - ( 1 )| = 0\n",
      "handbag |( 1 ) - ( 1 )| = 0\n",
      "tie |( 1 ) - ( 1 )| = 0\n",
      "suitcase |( 1 ) - ( 1 )| = 0\n",
      "frisbee |( 1 ) - ( 1 )| = 0\n",
      "skis |( 1 ) - ( 1 )| = 0\n",
      "snowboard |( 1 ) - ( 1 )| = 0\n",
      "sports ball |( 1 ) - ( 1 )| = 0\n",
      "kite |( 1 ) - ( 1 )| = 0\n",
      "baseball bat |( 1 ) - ( 1 )| = 0\n",
      "baseball glove |( 1 ) - ( 1 )| = 0\n",
      "skateboard |( 1 ) - ( 1 )| = 0\n",
      "surfboard |( 1 ) - ( 1 )| = 0\n",
      "tennis racket |( 1 ) - ( 1 )| = 0\n",
      "bottle |( 1 ) - ( 1 )| = 0\n",
      "wine glass |( 1 ) - ( 1 )| = 0\n",
      "cup |( 1 ) - ( 1.0 )| = 0.0\n",
      "fork |( 1 ) - ( 1.0 )| = 0.0\n",
      "knife |( 1 ) - ( 1.0 )| = 0.0\n",
      "spoon |( 1 ) - ( 1.0 )| = 0.0\n",
      "bowl |( 1 ) - ( 1.0 )| = 0.0\n",
      "banana |( 1 ) - ( 1.0 )| = 0.0\n",
      "apple |( 1 ) - ( 1.0 )| = 0.0\n",
      "sandwich |( 1 ) - ( 1.0 )| = 0.0\n",
      "orange |( 1 ) - ( 1.0 )| = 0.0\n",
      "broccoli |( 1 ) - ( 1.0 )| = 0.0\n",
      "carrot |( 1 ) - ( 1.0 )| = 0.0\n",
      "hot dog |( 1 ) - ( 1.0 )| = 0.0\n",
      "pizza |( 1 ) - ( 1.0 )| = 0.0\n",
      "donut |( 1 ) - ( 1.0 )| = 0.0\n",
      "cake |( 1 ) - ( 1.0 )| = 0.0\n",
      "chair |( 1 ) - ( 1.0 )| = 0.0\n",
      "couch |( 1 ) - ( 1.0 )| = 0.0\n",
      "potted plant |( 1 ) - ( 1.0 )| = 0.0\n",
      "bed |( 1 ) - ( 1.0 )| = 0.0\n",
      "dining table |( 1 ) - ( 1.0 )| = 0.0\n",
      "toilet |( 1 ) - ( 1.0 )| = 0.0\n",
      "tv |( 1 ) - ( 1.0 )| = 0.0\n",
      "laptop |( 1 ) - ( 1.0 )| = 0.0\n",
      "mouse |( 1 ) - ( 1.0 )| = 0.0\n",
      "remote |( 1 ) - ( 1.0 )| = 0.0\n",
      "keyboard |( 1 ) - ( 1.0 )| = 0.0\n",
      "cell phone |( 1 ) - ( 1.0 )| = 0.0\n",
      "microwave |( 1 ) - ( 1.0 )| = 0.0\n",
      "oven |( 1 ) - ( 1.0 )| = 0.0\n",
      "toaster |( 1 ) - ( 1.0 )| = 0.0\n",
      "sink |( 1 ) - ( 1.0 )| = 0.0\n",
      "refrigerator |( 1 ) - ( 1.0 )| = 0.0\n",
      "book |( 1 ) - ( 1.0 )| = 0.0\n",
      "clock |( 1 ) - ( 1.0 )| = 0.0\n",
      "vase |( 1 ) - ( 1.0 )| = 0.0\n",
      "scissors |( 1 ) - ( 1.0 )| = 0.0\n",
      "teddy bear |( 1 ) - ( 1.0 )| = 0.0\n",
      "hair drier |( 1 ) - ( 1.0 )| = 0.0\n",
      "toothbrush |( 1 ) - ( 1.0 )| = 0.0\n",
      "# |( 0 ) - ( 0 )| = 0\n",
      "$ |( 0 ) - ( 0 )| = 0\n",
      "US$ |( 0 ) - ( 0 )| = 0\n",
      "C$ |( 0 ) - ( 0 )| = 0\n",
      "'' |( 0 ) - ( 0 )| = 0\n",
      ", |( 0 ) - ( 0 )| = 0\n",
      "Wa |( 0 ) - ( 0 )| = 0\n",
      ". |( 0 ) - ( 0 )| = 0\n",
      "? |( 0 ) - ( 0 )| = 0\n",
      "! |( 0 ) - ( 0 )| = 0\n",
      "-- |( 0 ) - ( 0 )| = 0\n",
      "; |( 0 ) - ( 0 )| = 0\n",
      ": |( 0 ) - ( 0 )| = 0\n",
      "... |( 0 ) - ( 0 )| = 0\n",
      "- |( 0 ) - ( 0 )| = 0\n",
      "and |( 0 ) - ( 0 )| = 0\n",
      "or |( 0 ) - ( 0 )| = 0\n",
      "But |( 0 ) - ( 0 )| = 0\n",
      "but |( 0 ) - ( 0 )| = 0\n",
      "million |( -0.5 ) - ( -0.5 )| = 0.0\n",
      "billion |( -0.5 ) - ( -0.5 )| = 0.0\n",
      "one |( 0 ) - ( 0.0 )| = 0.0\n",
      "two |( 0 ) - ( 0.0 )| = 0.0\n",
      "10 |( 0 ) - ( 0.0 )| = 0.0\n",
      "the |( 0 ) - ( 0.0 )| = 0.0\n",
      "a |( 0 ) - ( 0.0 )| = 0.0\n",
      "The |( 0 ) - ( 0.0 )| = 0.0\n",
      "an |( 0 ) - ( 0.0 )| = 0.0\n",
      "this |( 0 ) - ( 0.0 )| = 0.0\n",
      "there |( 0 ) - ( 0.0 )| = 0.0\n",
      "There |( 0 ) - ( 0.0 )| = 0.0\n",
      "besuboru |( 0 ) - ( 0.0 )| = 0.0\n",
      "de |( -0.1 ) - ( 0.0 )| = 0.1\n",
      "etc. |( -0.1 ) - ( 0.0 )| = 0.1\n",
      "of |( 0 ) - ( 0.0 )| = 0.0\n",
      "for |( 0 ) - ( 0.0 )| = 0.0\n",
      "on |( 0 ) - ( 0.0 )| = 0.0\n",
      "many |( -0.3 ) - ( -0.5 )| = 0.2\n",
      "higher |( -0.4 ) - ( -0.6 )| = 0.2\n",
      "lower |( -0.4 ) - ( -0.6 )| = 0.2\n",
      "least |( -0.4 ) - ( -0.6 )| = 0.2\n",
      "latest |( -0.4 ) - ( -0.6 )| = 0.2\n",
      "1 |( 0 ) - ( 0.0 )| = 0.0\n",
      "2 |( 0 ) - ( 0.0 )| = 0.0\n",
      "3 |( 0 ) - ( 0.0 )| = 0.0\n",
      "4 |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "5 |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "will |( -0.9 ) - ( -0.7 )| = 0.2\n",
      "would |( -0.9 ) - ( -0.7 )| = 0.2\n",
      "could |( -0.9 ) - ( -0.7 )| = 0.2\n",
      "can |( -0.9 ) - ( -0.7 )| = 0.2\n",
      "may |( -0.9 ) - ( -0.7 )| = 0.2\n",
      "% |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "year |( 0.2 ) - ( 0.4 )| = 0.2\n",
      "market |( 0.1 ) - ( 0.2 )| = 0.1\n",
      "trading |( 0.2 ) - ( 0.3 )| = 0.1\n",
      "Mr. |( 0.7 ) - ( 0.5 )| = 0.2\n",
      "Containers |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "Securities |( 0.9 ) - ( 0.8 )| = 0.1\n",
      "Industries |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "Materials |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "years |( 0.2 ) - ( 0.4 )| = 0.2\n",
      "cents |( 0.9 ) - ( 0.9 )| = 0.0\n",
      "such |( -0.8 ) - ( -0.7 )| = 0.1\n",
      "Such |( 0 ) - ( 0 )| = 0\n",
      "All |( 0 ) - ( 0 )| = 0\n",
      "' |( 0 ) - ( 0 )| = 0\n",
      "it |( 0 ) - ( 0 )| = 0\n",
      "he |( 0 ) - ( 0 )| = 0\n",
      "they |( 0 ) - ( 0 )| = 0\n",
      "I |( 0 ) - ( 0 )| = 0\n",
      "It |( 0 ) - ( 0 )| = 0\n",
      "its |( 0 ) - ( 0 )| = 0\n",
      "their |( 0 ) - ( 0 )| = 0\n",
      "his |( 0 ) - ( 0 )| = 0\n",
      "her |( 0 ) - ( 0 )| = 0\n",
      "our |( 0 ) - ( 0 )| = 0\n",
      "n't |( 0 ) - ( 0 )| = 0\n",
      "also |( 0 ) - ( 0 )| = 0\n",
      "not |( 0 ) - ( 0 )| = 0\n",
      "only |( 0 ) - ( 0 )| = 0\n",
      "even |( 0 ) - ( 0 )| = 0\n",
      "more |( 0 ) - ( -0.2 )| = 0.2\n",
      "earlier |( 0 ) - ( -0.2 )| = 0.2\n",
      "less |( 0 ) - ( -0.2 )| = 0.2\n",
      "better |( 0 ) - ( -0.2 )| = 0.2\n",
      "longer |( 0 ) - ( -0.2 )| = 0.2\n",
      "most |( 0 ) - ( -0.2 )| = 0.2\n",
      "Most |( 0 ) - ( -0.2 )| = 0.2\n",
      "up |( 0 ) - ( 0 )| = 0\n",
      "out |( 0 ) - ( 0 )| = 0\n",
      "off |( 0 ) - ( 0 )| = 0\n",
      "in |( 0 ) - ( 0 )| = 0\n",
      "down |( 0 ) - ( 0 )| = 0\n",
      "expected |( -0.7 ) - ( -0.6 )| = 0.1\n",
      "compared |( -0.7 ) - ( -0.6 )| = 0.1\n",
      "'re |( 0 ) - ( 0 )| = 0\n",
      "is |( 0 ) - ( 0 )| = 0\n",
      "has |( 0 ) - ( 0 )| = 0\n",
      "says |( 0 ) - ( 0 )| = 0\n",
      "'s |( 0 ) - ( 0 )| = 0\n",
      "does |( 0 ) - ( 0 )| = 0\n",
      "which |( 0 ) - ( 0 )| = 0\n",
      "that |( 0 ) - ( 0 )| = 0\n",
      "That |( 0 ) - ( 0 )| = 0\n",
      "THAT |( 0 ) - ( 0 )| = 0\n",
      "who |( 0 ) - ( 0 )| = 0\n",
      "what |( 0 ) - ( 0 )| = 0\n",
      "What |( 0 ) - ( 0 )| = 0\n",
      "whom |( 0 ) - ( 0 )| = 0\n",
      "Who |( 0 ) - ( 0 )| = 0\n",
      "whose |( 0 ) - ( 0 )| = 0\n",
      "when |( 0 ) - ( 0 )| = 0\n",
      "where |( 0 ) - ( 0 )| = 0\n",
      "how |( 0 ) - ( 0 )| = 0\n",
      "When |( 0 ) - ( 0 )| = 0\n",
      "why |( 0 ) - ( 0 )| = 0\n",
      "`` |( 0 ) - ( 0 )| = 0\n",
      "` |( 0 ) - ( 0 )| = 0\n",
      "Number of words with a difference of less than 0.25 (very confident):  282 of 383\n",
      "Percentage:  74 %\n"
     ]
    }
   ],
   "source": [
    "# surface words from axis_emb[0] that have a difference of less than 0.25\n",
    "len_b = 0\n",
    "for i in range(len(diff_run_list)):\n",
    "  if diff_run_list[i] < 0.25:\n",
    "    print(axis_emb[0][i], \"|(\", first_run[i], \")\", \"-\", \"(\", second_run[i], \")|\", \"=\", diff_run_list[i])\n",
    "    len_b += 1\n",
    "\n",
    "print(\"Number of words with a difference of less than 0.25 (very confident): \", len_b, \"of\", len(diff_run_list))\n",
    "print(\"Percentage: \", round(len_b/len(diff_run_list) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matte's notes:\n",
    "- This run is better than the previous one â€“ 74% compared to 57% confident."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6861",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
